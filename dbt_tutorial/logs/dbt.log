[0m00:35:26.785267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199BD277640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199BF7C3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199BF7C3100>]}


============================== 00:35:26.790269 | c3a2516f-ab53-46d8-8261-01ed83da241f ==============================
[0m00:35:26.790269 [info ] [MainThread]: Running with dbt=1.5.11
[0m00:35:26.790269 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m00:35:26.843851 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "dbt_tutorial", target "dev" invalid: 1234 is not of type 'string'
[0m00:35:26.844851 [debug] [MainThread]: Command `dbt run` failed at 00:35:26.844851 after 0.08 seconds
[0m00:35:26.844851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199BD277640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199BF8F40A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199BF8F40D0>]}
[0m00:35:26.845851 [debug] [MainThread]: Flushing usage events
[0m00:35:26.962239 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m00:36:44.040127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B2377640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B47C7250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B47C7100>]}


============================== 00:36:44.044160 | 1899c9e2-0460-4e54-9dcc-fed64dc4a97f ==============================
[0m00:36:44.044160 [info ] [MainThread]: Running with dbt=1.5.11
[0m00:36:44.044160 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m00:36:44.084800 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "dbt_tutorial", target "dev" invalid: 1234 is not of type 'string'
[0m00:36:44.085800 [debug] [MainThread]: Command `dbt run` failed at 00:36:44.085800 after 0.06 seconds
[0m00:36:44.086801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B2377640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B48E00A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A2B48E00D0>]}
[0m00:36:44.086801 [debug] [MainThread]: Flushing usage events
[0m00:36:55.460200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDF2E77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDF52C72E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDF52C7190>]}


============================== 00:36:55.463201 | a9d583fa-4672-495e-955c-0471709dd4f4 ==============================
[0m00:36:55.463201 [info ] [MainThread]: Running with dbt=1.5.11
[0m00:36:55.464201 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m00:36:55.505199 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "dbt_tutorial", target "dev" invalid: 1234 is not of type 'string'
[0m00:36:55.507201 [debug] [MainThread]: Command `dbt run` failed at 00:36:55.507201 after 0.06 seconds
[0m00:36:55.507201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDF2E77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDF53F6890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FDF53F6860>]}
[0m00:36:55.508203 [debug] [MainThread]: Flushing usage events
[0m00:37:32.477033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D72577640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D749C3280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D749C3130>]}


============================== 00:37:32.480032 | e8609023-36f4-4a2b-a290-a3609ef838fd ==============================
[0m00:37:32.480032 [info ] [MainThread]: Running with dbt=1.5.11
[0m00:37:32.481031 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m00:37:32.548773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D749C39D0>]}
[0m00:37:32.566728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D74B1CA90>]}
[0m00:37:32.567728 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m00:37:32.580761 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m00:37:32.581729 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m00:37:32.582761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D749C3790>]}
[0m00:37:33.213269 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
[0m00:37:33.225297 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
[0m00:37:33.229302 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m00:37:33.323074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D74BFA650>]}
[0m00:37:33.330047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D74EF5A80>]}
[0m00:37:33.331053 [info ] [MainThread]: Found 3 models, 4 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m00:37:33.332068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D74BEE410>]}
[0m00:37:33.334085 [info ] [MainThread]: 
[0m00:37:33.335052 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:37:33.337052 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m00:37:33.346054 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m00:37:33.346054 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m00:37:33.346054 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:37:33.519456 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m00:37:33.521458 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m00:37:33.523456 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_Adventureworks, now create_Adventureworks_warehouse)
[0m00:37:33.523456 [debug] [ThreadPool]: Creating schema "database: "Adventureworks"
schema: "warehouse"
"
[0m00:37:33.528457 [debug] [ThreadPool]: Using postgres connection "create_Adventureworks_warehouse"
[0m00:37:33.529456 [debug] [ThreadPool]: On create_Adventureworks_warehouse: BEGIN
[0m00:37:33.529456 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:37:33.550913 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:37:33.551428 [debug] [ThreadPool]: Using postgres connection "create_Adventureworks_warehouse"
[0m00:37:33.551428 [debug] [ThreadPool]: On create_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "create_Adventureworks_warehouse"} */
create schema if not exists "warehouse"
[0m00:37:33.567985 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m00:37:33.569024 [debug] [ThreadPool]: On create_Adventureworks_warehouse: COMMIT
[0m00:37:33.569024 [debug] [ThreadPool]: Using postgres connection "create_Adventureworks_warehouse"
[0m00:37:33.569546 [debug] [ThreadPool]: On create_Adventureworks_warehouse: COMMIT
[0m00:37:33.574450 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m00:37:33.574450 [debug] [ThreadPool]: On create_Adventureworks_warehouse: Close
[0m00:37:33.576453 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m00:37:33.581450 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m00:37:33.582450 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m00:37:33.582450 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:37:33.598963 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:37:33.599474 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m00:37:33.599474 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m00:37:33.626622 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m00:37:33.628625 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m00:37:33.629639 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m00:37:33.635622 [debug] [MainThread]: Using postgres connection "master"
[0m00:37:33.635622 [debug] [MainThread]: On master: BEGIN
[0m00:37:33.636623 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:37:33.653405 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:37:33.653923 [debug] [MainThread]: Using postgres connection "master"
[0m00:37:33.654444 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:37:34.030621 [debug] [MainThread]: SQL status: SELECT 146 in 0.0 seconds
[0m00:37:34.067617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D72AA2A10>]}
[0m00:37:34.068618 [debug] [MainThread]: On master: ROLLBACK
[0m00:37:34.069617 [debug] [MainThread]: Using postgres connection "master"
[0m00:37:34.069617 [debug] [MainThread]: On master: BEGIN
[0m00:37:34.071619 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:37:34.071619 [debug] [MainThread]: On master: COMMIT
[0m00:37:34.072618 [debug] [MainThread]: Using postgres connection "master"
[0m00:37:34.072618 [debug] [MainThread]: On master: COMMIT
[0m00:37:34.073618 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:37:34.073618 [debug] [MainThread]: On master: Close
[0m00:37:34.074618 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:37:34.075618 [info ] [MainThread]: 
[0m00:37:34.085725 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.my_first_dbt_model
[0m00:37:34.086246 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_header
[0m00:37:34.086767 [info ] [Thread-1 (]: 1 of 3 START sql table model warehouse.my_first_dbt_model ...................... [RUN]
[0m00:37:34.088855 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.my_first_dbt_model'
[0m00:37:34.087284 [info ] [Thread-2 (]: 2 of 3 START sql view model warehouse.sales_order_header ....................... [RUN]
[0m00:37:34.089388 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.my_first_dbt_model
[0m00:37:34.090430 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m00:37:34.097488 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.my_first_dbt_model"
[0m00:37:34.098485 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m00:37:34.101485 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m00:37:34.103486 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (compile): 00:37:34.090974 => 00:37:34.103486
[0m00:37:34.104487 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 00:37:34.099485 => 00:37:34.103486
[0m00:37:34.104487 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.my_first_dbt_model
[0m00:37:34.105485 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m00:37:34.146539 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_tutorial.my_first_dbt_model"
[0m00:37:34.166372 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m00:37:34.168371 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m00:37:34.169372 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m00:37:34.169372 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: BEGIN
[0m00:37:34.169372 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m00:37:34.170371 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m00:37:34.171372 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m00:37:34.187279 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:37:34.188278 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m00:37:34.189281 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */

  
    

  create  table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m00:37:34.191279 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m00:37:34.191279 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m00:37:34.192280 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  create view "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
    
    
  as (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
[0m00:37:34.219000 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m00:37:34.227005 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m00:37:34.227005 [debug] [Thread-2 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m00:37:34.228027 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m00:37:34.230570 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m00:37:34.231569 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m00:37:34.233571 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:37:34.233571 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:37:34.251604 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m00:37:34.253602 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m00:37:34.253602 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m00:37:34.254607 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m00:37:34.255572 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m00:37:34.255572 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m00:37:34.260060 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:37:34.260952 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m00:37:34.265895 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m00:37:34.268891 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m00:37:34.269871 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
drop table if exists "Adventureworks"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m00:37:34.270146 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop view if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m00:37:34.273899 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:37:34.274866 [debug] [Thread-2 (]: SQL status: DROP VIEW in 0.0 seconds
[0m00:37:34.275867 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (execute): 00:37:34.105485 => 00:37:34.275867
[0m00:37:34.277868 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 00:37:34.146539 => 00:37:34.277868
[0m00:37:34.278868 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: Close
[0m00:37:34.278868 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: Close
[0m00:37:34.279868 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D74E1ACB0>]}
[0m00:37:34.280868 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D73A32CE0>]}
[0m00:37:34.281867 [info ] [Thread-1 (]: 1 of 3 OK created sql table model warehouse.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.19s]
[0m00:37:34.283867 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.my_first_dbt_model
[0m00:37:34.282867 [info ] [Thread-2 (]: 2 of 3 OK created sql view model warehouse.sales_order_header .................. [[32mCREATE VIEW[0m in 0.19s]
[0m00:37:34.284765 [debug] [Thread-4 (]: Began running node model.dbt_tutorial.my_second_dbt_model
[0m00:37:34.285811 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m00:37:34.286333 [info ] [Thread-4 (]: 3 of 3 START sql view model warehouse.my_second_dbt_model ...................... [RUN]
[0m00:37:34.287377 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_tutorial.my_second_dbt_model'
[0m00:37:34.287901 [debug] [Thread-4 (]: Began compiling node model.dbt_tutorial.my_second_dbt_model
[0m00:37:34.290515 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_tutorial.my_second_dbt_model"
[0m00:37:34.291545 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (compile): 00:37:34.288405 => 00:37:34.291545
[0m00:37:34.292069 [debug] [Thread-4 (]: Began executing node model.dbt_tutorial.my_second_dbt_model
[0m00:37:34.297409 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_tutorial.my_second_dbt_model"
[0m00:37:34.298487 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m00:37:34.299534 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: BEGIN
[0m00:37:34.300071 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m00:37:34.319113 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m00:37:34.320110 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m00:37:34.321116 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */

  create view "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m00:37:34.326117 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m00:37:34.329110 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m00:37:34.329110 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m00:37:34.331110 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:37:34.333111 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m00:37:34.333111 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m00:37:34.334111 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m00:37:34.338124 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m00:37:34.341111 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m00:37:34.342110 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
drop view if exists "Adventureworks"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m00:37:34.343111 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m00:37:34.345110 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (execute): 00:37:34.292589 => 00:37:34.344110
[0m00:37:34.345110 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: Close
[0m00:37:34.346111 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e8609023-36f4-4a2b-a290-a3609ef838fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D6F83CA90>]}
[0m00:37:34.347112 [info ] [Thread-4 (]: 3 of 3 OK created sql view model warehouse.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.06s]
[0m00:37:34.348110 [debug] [Thread-4 (]: Finished running node model.dbt_tutorial.my_second_dbt_model
[0m00:37:34.350242 [debug] [MainThread]: Using postgres connection "master"
[0m00:37:34.350752 [debug] [MainThread]: On master: BEGIN
[0m00:37:34.350752 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:37:34.365186 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:37:34.365186 [debug] [MainThread]: On master: COMMIT
[0m00:37:34.366185 [debug] [MainThread]: Using postgres connection "master"
[0m00:37:34.366185 [debug] [MainThread]: On master: COMMIT
[0m00:37:34.367186 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:37:34.367186 [debug] [MainThread]: On master: Close
[0m00:37:34.368186 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:37:34.369186 [debug] [MainThread]: Connection 'create_Adventureworks_warehouse' was properly closed.
[0m00:37:34.369186 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m00:37:34.369186 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_first_dbt_model' was properly closed.
[0m00:37:34.370187 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m00:37:34.370187 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_second_dbt_model' was properly closed.
[0m00:37:34.371729 [info ] [MainThread]: 
[0m00:37:34.372825 [info ] [MainThread]: Finished running 1 table model, 2 view models in 0 hours 0 minutes and 1.04 seconds (1.04s).
[0m00:37:34.374417 [debug] [MainThread]: Command end result
[0m00:37:34.382738 [info ] [MainThread]: 
[0m00:37:34.383783 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:37:34.384365 [info ] [MainThread]: 
[0m00:37:34.385294 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m00:37:34.386294 [debug] [MainThread]: Command `dbt run` succeeded at 00:37:34.386294 after 1.93 seconds
[0m00:37:34.387294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D72577640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D74E57FA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017D74F91570>]}
[0m00:37:34.388298 [debug] [MainThread]: Flushing usage events
[0m01:06:32.827979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76AC83640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D1C32B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D1C3160>]}


============================== 01:06:32.831976 | ff5da059-a0ca-43ca-b6f7-6840cf9da0ee ==============================
[0m01:06:32.831976 [info ] [MainThread]: Running with dbt=1.5.11
[0m01:06:32.832978 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m01:06:32.910659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ff5da059-a0ca-43ca-b6f7-6840cf9da0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D1C3A00>]}
[0m01:06:32.928084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ff5da059-a0ca-43ca-b6f7-6840cf9da0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D31CAC0>]}
[0m01:06:32.929082 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m01:06:32.942049 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m01:06:32.983280 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m01:06:32.984281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ff5da059-a0ca-43ca-b6f7-6840cf9da0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D31CCA0>]}
[0m01:06:33.595654 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m01:06:33.657635 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_tutorial.example
[0m01:06:33.663634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff5da059-a0ca-43ca-b6f7-6840cf9da0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D3457B0>]}
[0m01:06:33.673273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ff5da059-a0ca-43ca-b6f7-6840cf9da0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D1C3070>]}
[0m01:06:33.673273 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m01:06:33.674273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff5da059-a0ca-43ca-b6f7-6840cf9da0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D1C30A0>]}
[0m01:06:33.676277 [info ] [MainThread]: 
[0m01:06:33.678273 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:06:33.679272 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m01:06:33.689273 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m01:06:33.690272 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m01:06:33.691274 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:06:33.801031 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m01:06:33.803030 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m01:06:33.804031 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m01:06:33.842640 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m01:06:33.842640 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m01:06:33.843640 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:06:33.876957 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:06:33.876957 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m01:06:33.877967 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m01:06:33.901448 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m01:06:33.902448 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m01:06:33.904453 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m01:06:33.910148 [debug] [MainThread]: Using postgres connection "master"
[0m01:06:33.910675 [debug] [MainThread]: On master: BEGIN
[0m01:06:33.911201 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:06:33.938972 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:06:33.938972 [debug] [MainThread]: Using postgres connection "master"
[0m01:06:33.939974 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:06:34.355190 [debug] [MainThread]: SQL status: SELECT 148 in 0.0 seconds
[0m01:06:34.359221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ff5da059-a0ca-43ca-b6f7-6840cf9da0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D34C370>]}
[0m01:06:34.360223 [debug] [MainThread]: On master: ROLLBACK
[0m01:06:34.361189 [debug] [MainThread]: Using postgres connection "master"
[0m01:06:34.362216 [debug] [MainThread]: On master: BEGIN
[0m01:06:34.364189 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:06:34.365189 [debug] [MainThread]: On master: COMMIT
[0m01:06:34.365189 [debug] [MainThread]: Using postgres connection "master"
[0m01:06:34.365189 [debug] [MainThread]: On master: COMMIT
[0m01:06:34.367089 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:06:34.367089 [debug] [MainThread]: On master: Close
[0m01:06:34.367905 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:06:34.368913 [info ] [MainThread]: 
[0m01:06:34.377741 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.sales_order_header
[0m01:06:34.378851 [info ] [Thread-1 (]: 1 of 1 START sql view model warehouse.sales_order_header ....................... [RUN]
[0m01:06:34.379890 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m01:06:34.380413 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m01:06:34.388877 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m01:06:34.389879 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 01:06:34.380933 => 01:06:34.389879
[0m01:06:34.391880 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m01:06:34.431817 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m01:06:34.432818 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:06:34.433834 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m01:06:34.433834 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m01:06:34.450374 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:06:34.451374 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:06:34.451374 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  create view "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
    
    
  as (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
[0m01:06:34.480035 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m01:06:34.487034 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:06:34.487034 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m01:06:34.490655 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:06:34.495642 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:06:34.495642 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m01:06:34.498643 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:06:34.516642 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m01:06:34.517643 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:06:34.517643 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m01:06:34.522673 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:06:34.527642 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:06:34.528642 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop view if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m01:06:34.545653 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m01:06:34.547647 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 01:06:34.391880 => 01:06:34.547647
[0m01:06:34.548643 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: Close
[0m01:06:34.549643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff5da059-a0ca-43ca-b6f7-6840cf9da0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D70AEF0>]}
[0m01:06:34.550643 [info ] [Thread-1 (]: 1 of 1 OK created sql view model warehouse.sales_order_header .................. [[32mCREATE VIEW[0m in 0.17s]
[0m01:06:34.551642 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m01:06:34.556172 [debug] [MainThread]: Using postgres connection "master"
[0m01:06:34.558369 [debug] [MainThread]: On master: BEGIN
[0m01:06:34.560005 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:06:34.576417 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:06:34.576417 [debug] [MainThread]: On master: COMMIT
[0m01:06:34.577419 [debug] [MainThread]: Using postgres connection "master"
[0m01:06:34.577939 [debug] [MainThread]: On master: COMMIT
[0m01:06:34.578931 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:06:34.578931 [debug] [MainThread]: On master: Close
[0m01:06:34.580933 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:06:34.581931 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m01:06:34.581931 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m01:06:34.582930 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m01:06:34.582930 [info ] [MainThread]: 
[0m01:06:34.583961 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.91 seconds (0.91s).
[0m01:06:34.585211 [debug] [MainThread]: Command end result
[0m01:06:34.591131 [info ] [MainThread]: 
[0m01:06:34.592181 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:06:34.592702 [info ] [MainThread]: 
[0m01:06:34.593749 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:06:34.594265 [debug] [MainThread]: Command `dbt run` succeeded at 01:06:34.594265 after 1.79 seconds
[0m01:06:34.594783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76AC83640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D1C3A00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B76D631570>]}
[0m01:06:34.595293 [debug] [MainThread]: Flushing usage events
[0m01:06:34.986539 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m01:19:05.784186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F42273640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F446C3280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F446C3130>]}


============================== 01:19:05.788501 | 697529e2-f5cd-42f9-8f8e-50326eedf18c ==============================
[0m01:19:05.788501 [info ] [MainThread]: Running with dbt=1.5.11
[0m01:19:05.789501 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m01:19:05.866500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '697529e2-f5cd-42f9-8f8e-50326eedf18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F446C39D0>]}
[0m01:19:05.886040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '697529e2-f5cd-42f9-8f8e-50326eedf18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F44A1CA90>]}
[0m01:19:05.887041 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m01:19:05.900040 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m01:19:05.958964 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m01:19:05.959960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '697529e2-f5cd-42f9-8f8e-50326eedf18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F44A1CD00>]}
[0m01:19:06.695488 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m01:19:06.769653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '697529e2-f5cd-42f9-8f8e-50326eedf18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F44A5BAC0>]}
[0m01:19:06.778620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '697529e2-f5cd-42f9-8f8e-50326eedf18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F446C3040>]}
[0m01:19:06.780632 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m01:19:06.782629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '697529e2-f5cd-42f9-8f8e-50326eedf18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F446C3070>]}
[0m01:19:06.783653 [info ] [MainThread]: 
[0m01:19:06.785644 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:19:06.786655 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m01:19:06.801623 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m01:19:06.802627 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m01:19:06.802627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:19:06.865619 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m01:19:06.866620 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m01:19:06.868624 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m01:19:06.927679 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m01:19:06.927679 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m01:19:06.928667 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:19:06.955605 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:19:06.955605 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m01:19:06.956606 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m01:19:06.966605 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m01:19:06.968607 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m01:19:06.970611 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m01:19:06.986607 [debug] [MainThread]: Using postgres connection "master"
[0m01:19:06.989631 [debug] [MainThread]: On master: BEGIN
[0m01:19:06.992299 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:19:07.043015 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:19:07.045130 [debug] [MainThread]: Using postgres connection "master"
[0m01:19:07.046146 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:19:07.419045 [debug] [MainThread]: SQL status: SELECT 148 in 0.0 seconds
[0m01:19:07.424232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '697529e2-f5cd-42f9-8f8e-50326eedf18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F431695A0>]}
[0m01:19:07.424232 [debug] [MainThread]: On master: ROLLBACK
[0m01:19:07.426232 [debug] [MainThread]: Using postgres connection "master"
[0m01:19:07.426232 [debug] [MainThread]: On master: BEGIN
[0m01:19:07.428232 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:19:07.428232 [debug] [MainThread]: On master: COMMIT
[0m01:19:07.428232 [debug] [MainThread]: Using postgres connection "master"
[0m01:19:07.429232 [debug] [MainThread]: On master: COMMIT
[0m01:19:07.430232 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:19:07.430232 [debug] [MainThread]: On master: Close
[0m01:19:07.431232 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:19:07.432232 [info ] [MainThread]: 
[0m01:19:07.440023 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.sales_order_header
[0m01:19:07.441643 [info ] [Thread-1 (]: 1 of 1 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m01:19:07.442691 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m01:19:07.443214 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m01:19:07.451324 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m01:19:07.452323 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 01:19:07.443734 => 01:19:07.451324
[0m01:19:07.452323 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m01:19:07.489305 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m01:19:07.489305 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:19:07.489305 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m01:19:07.489305 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m01:19:07.521060 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:19:07.522059 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:19:07.522059 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m01:19:07.682557 [debug] [Thread-1 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m01:19:07.687865 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:19:07.688896 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m01:19:07.691864 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:19:07.695862 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:19:07.695862 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m01:19:07.697864 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:19:07.715896 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m01:19:07.715896 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:19:07.716864 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m01:19:07.733779 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:19:07.738979 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m01:19:07.739599 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop view if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m01:19:07.746600 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m01:19:07.747598 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 01:19:07.452323 => 01:19:07.747598
[0m01:19:07.748597 [debug] [Thread-1 (]: On model.dbt_tutorial.sales_order_header: Close
[0m01:19:07.749599 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '697529e2-f5cd-42f9-8f8e-50326eedf18c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F44BBB610>]}
[0m01:19:07.750598 [info ] [Thread-1 (]: 1 of 1 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.31s]
[0m01:19:07.751607 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m01:19:07.754745 [debug] [MainThread]: Using postgres connection "master"
[0m01:19:07.755258 [debug] [MainThread]: On master: BEGIN
[0m01:19:07.755266 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:19:07.770545 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:19:07.771546 [debug] [MainThread]: On master: COMMIT
[0m01:19:07.771546 [debug] [MainThread]: Using postgres connection "master"
[0m01:19:07.772546 [debug] [MainThread]: On master: COMMIT
[0m01:19:07.773546 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:19:07.774545 [debug] [MainThread]: On master: Close
[0m01:19:07.775547 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:19:07.775547 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m01:19:07.775547 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m01:19:07.776546 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m01:19:07.776546 [info ] [MainThread]: 
[0m01:19:07.777760 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.99 seconds (0.99s).
[0m01:19:07.778304 [debug] [MainThread]: Command end result
[0m01:19:07.784107 [info ] [MainThread]: 
[0m01:19:07.785131 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:19:07.785343 [info ] [MainThread]: 
[0m01:19:07.786371 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:19:07.787429 [debug] [MainThread]: Command `dbt run` succeeded at 01:19:07.787429 after 2.03 seconds
[0m01:19:07.787956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F42273640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F44B02980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017F44A8CFD0>]}
[0m01:19:07.788467 [debug] [MainThread]: Flushing usage events
[0m10:50:41.239491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012F77477640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012F799C72E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012F799C7190>]}


============================== 10:50:41.242175 | 88f64cc0-d1e2-47be-b433-81a65e3a702a ==============================
[0m10:50:41.242175 [info ] [MainThread]: Running with dbt=1.5.11
[0m10:50:41.242175 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'D:\\cs\\dbt\\dbt_tutorial\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:50:41.475838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '88f64cc0-d1e2-47be-b433-81a65e3a702a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012F799C7A30>]}
[0m10:50:41.493652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '88f64cc0-d1e2-47be-b433-81a65e3a702a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012F79B1CAF0>]}
[0m10:50:41.499614 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m10:50:41.519410 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m10:50:41.534379 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m10:50:41.535759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '88f64cc0-d1e2-47be-b433-81a65e3a702a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012F79B1F730>]}
[0m10:50:42.681611 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
[0m10:50:42.694799 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
[0m10:50:42.698801 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m10:50:42.763273 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in models\warehouse\sales_order_header.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', [1, 2, 3, 4])] instead (2 keys)
  	@: UnparsedModelUpdate(original_file_path='mode...[])
[0m10:50:42.765318 [debug] [MainThread]: Command `dbt run` failed at 10:50:42.764275 after 1.55 seconds
[0m10:50:42.765410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012F77477640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012F79EAB490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012F79EB4940>]}
[0m10:50:42.765410 [debug] [MainThread]: Flushing usage events
[0m10:52:26.158916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE79573640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BAC32B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BAC3160>]}


============================== 10:52:26.161916 | 6218f354-96e7-4a10-a16e-128e80b70cb2 ==============================
[0m10:52:26.161916 [info ] [MainThread]: Running with dbt=1.5.11
[0m10:52:26.162915 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\cs\\dbt\\dbt_tutorial\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:52:26.238915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BAC3A00>]}
[0m10:52:26.258540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BE1CAC0>]}
[0m10:52:26.259541 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m10:52:26.274075 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m10:52:26.281076 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m10:52:26.283099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BE1D510>]}
[0m10:52:26.933965 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
[0m10:52:26.947803 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
[0m10:52:26.950802 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m10:52:27.107567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BF871C0>]}
[0m10:52:27.117569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BF87E50>]}
[0m10:52:27.118569 [info ] [MainThread]: Found 3 models, 7 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m10:52:27.119569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BF0FF70>]}
[0m10:52:27.121568 [info ] [MainThread]: 
[0m10:52:27.122568 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:52:27.124569 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m10:52:27.135569 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m10:52:27.136569 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m10:52:27.136569 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:52:27.283694 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m10:52:27.284693 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m10:52:27.286693 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m10:52:27.293693 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:52:27.294694 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m10:52:27.294694 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:52:27.327543 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:52:27.328063 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:52:27.328583 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m10:52:27.372913 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m10:52:27.373916 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m10:52:27.375913 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m10:52:27.380912 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:27.380912 [debug] [MainThread]: On master: BEGIN
[0m10:52:27.381912 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:52:27.404003 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:52:27.405046 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:27.405571 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:52:28.025920 [debug] [MainThread]: SQL status: SELECT 147 in 1.0 seconds
[0m10:52:28.030920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE765BCA90>]}
[0m10:52:28.031548 [debug] [MainThread]: On master: ROLLBACK
[0m10:52:28.033547 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:28.034545 [debug] [MainThread]: On master: BEGIN
[0m10:52:28.036544 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:52:28.036544 [debug] [MainThread]: On master: COMMIT
[0m10:52:28.037544 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:28.037544 [debug] [MainThread]: On master: COMMIT
[0m10:52:28.039545 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:52:28.039545 [debug] [MainThread]: On master: Close
[0m10:52:28.040544 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:52:28.041547 [info ] [MainThread]: 
[0m10:52:28.056050 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.my_first_dbt_model
[0m10:52:28.056569 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_header
[0m10:52:28.057081 [info ] [Thread-1 (]: 1 of 3 START sql table model warehouse.my_first_dbt_model ...................... [RUN]
[0m10:52:28.058080 [info ] [Thread-2 (]: 2 of 3 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m10:52:28.059081 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.my_first_dbt_model'
[0m10:52:28.060082 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m10:52:28.061082 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.my_first_dbt_model
[0m10:52:28.061082 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m10:52:28.071080 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.my_first_dbt_model"
[0m10:52:28.075081 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m10:52:28.077084 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 10:52:28.072080 => 10:52:28.076082
[0m10:52:28.077084 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m10:52:28.078081 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (compile): 10:52:28.062080 => 10:52:28.078081
[0m10:52:28.126244 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m10:52:28.127244 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.my_first_dbt_model
[0m10:52:28.132244 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_tutorial.my_first_dbt_model"
[0m10:52:28.133246 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:52:28.134211 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m10:52:28.134211 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:52:28.135209 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:52:28.135906 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: BEGIN
[0m10:52:28.136913 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:52:28.158912 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:52:28.159911 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:52:28.159911 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m10:52:28.173912 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:52:28.174912 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:52:28.175912 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */

  
    

  create  table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m10:52:28.203912 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m10:52:28.211911 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:52:28.212911 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m10:52:28.217912 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:52:28.221913 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:52:28.221913 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m10:52:28.224271 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:52:28.260267 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:52:28.260267 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */

    
  
  comment on table "Adventureworks"."warehouse"."my_first_dbt_model" is $dbt_comment_literal_block$A starter dbt model$dbt_comment_literal_block$;

  
[0m10:52:28.267267 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m10:52:28.268269 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m10:52:28.269267 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:52:28.269267 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m10:52:28.291267 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:52:28.297835 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:52:28.298835 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
drop table if exists "Adventureworks"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m10:52:28.335836 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m10:52:28.337835 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (execute): 10:52:28.128230 => 10:52:28.337835
[0m10:52:28.338834 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: Close
[0m10:52:28.339834 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BF68FD0>]}
[0m10:52:28.340833 [info ] [Thread-1 (]: 1 of 3 OK created sql table model warehouse.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.28s]
[0m10:52:28.341835 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.my_first_dbt_model
[0m10:52:28.342835 [debug] [Thread-4 (]: Began running node model.dbt_tutorial.my_second_dbt_model
[0m10:52:28.343835 [info ] [Thread-4 (]: 3 of 3 START sql view model warehouse.my_second_dbt_model ...................... [RUN]
[0m10:52:28.344836 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_tutorial.my_second_dbt_model'
[0m10:52:28.345835 [debug] [Thread-4 (]: Began compiling node model.dbt_tutorial.my_second_dbt_model
[0m10:52:28.348833 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_tutorial.my_second_dbt_model"
[0m10:52:28.350835 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (compile): 10:52:28.345835 => 10:52:28.349834
[0m10:52:28.350835 [debug] [Thread-4 (]: Began executing node model.dbt_tutorial.my_second_dbt_model
[0m10:52:28.375694 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_tutorial.my_second_dbt_model"
[0m10:52:28.376691 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:52:28.377692 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: BEGIN
[0m10:52:28.378692 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:52:28.380691 [debug] [Thread-2 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m10:52:28.385693 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:52:28.386693 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m10:52:28.388690 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:52:28.392691 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:52:28.392691 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m10:52:28.394692 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:52:28.397689 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:52:28.398691 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m10:52:28.399691 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m10:52:28.401692 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m10:52:28.401692 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:52:28.402691 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m10:52:28.410006 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:52:28.411043 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:52:28.411043 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */

  create view "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m10:52:28.423036 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m10:52:28.427036 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:52:28.428035 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m10:52:28.432035 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:52:28.433037 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m10:52:28.435034 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:52:28.438035 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:52:28.439035 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */

    
  
  comment on view "Adventureworks"."warehouse"."my_second_dbt_model" is $dbt_comment_literal_block$A starter dbt model$dbt_comment_literal_block$;

  
[0m10:52:28.440038 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m10:52:28.442038 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m10:52:28.444035 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m10:52:28.444035 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:52:28.445035 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m10:52:28.453091 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m10:52:28.457093 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:52:28.458091 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m10:52:28.458091 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
drop view if exists "Adventureworks"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m10:52:28.460091 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 10:52:28.078081 => 10:52:28.460091
[0m10:52:28.461091 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: Close
[0m10:52:28.462092 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BF03A60>]}
[0m10:52:28.463093 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m10:52:28.463093 [info ] [Thread-2 (]: 2 of 3 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.40s]
[0m10:52:28.465091 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (execute): 10:52:28.351834 => 10:52:28.465091
[0m10:52:28.466091 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m10:52:28.467091 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: Close
[0m10:52:28.469093 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6218f354-96e7-4a10-a16e-128e80b70cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE765BEDA0>]}
[0m10:52:28.470093 [info ] [Thread-4 (]: 3 of 3 OK created sql view model warehouse.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.12s]
[0m10:52:28.471095 [debug] [Thread-4 (]: Finished running node model.dbt_tutorial.my_second_dbt_model
[0m10:52:28.474095 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:28.474670 [debug] [MainThread]: On master: BEGIN
[0m10:52:28.475200 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:52:28.496852 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:52:28.497852 [debug] [MainThread]: On master: COMMIT
[0m10:52:28.498853 [debug] [MainThread]: Using postgres connection "master"
[0m10:52:28.498853 [debug] [MainThread]: On master: COMMIT
[0m10:52:28.500854 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:52:28.500854 [debug] [MainThread]: On master: Close
[0m10:52:28.501853 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:52:28.502853 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m10:52:28.502853 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m10:52:28.503853 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_first_dbt_model' was properly closed.
[0m10:52:28.503853 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m10:52:28.504867 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_second_dbt_model' was properly closed.
[0m10:52:28.505933 [info ] [MainThread]: 
[0m10:52:28.507002 [info ] [MainThread]: Finished running 2 table models, 1 view model in 0 hours 0 minutes and 1.38 seconds (1.38s).
[0m10:52:28.508588 [debug] [MainThread]: Command end result
[0m10:52:28.517674 [info ] [MainThread]: 
[0m10:52:28.518197 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:52:28.519189 [info ] [MainThread]: 
[0m10:52:28.520194 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m10:52:28.521189 [debug] [MainThread]: Command `dbt run` succeeded at 10:52:28.521189 after 2.38 seconds
[0m10:52:28.522188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE79573640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BAC3A00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FE7BF606A0>]}
[0m10:52:28.523189 [debug] [MainThread]: Flushing usage events
[0m10:55:49.250178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F932677640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F934BC71F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F934BC70A0>]}


============================== 10:55:49.256179 | e77e98f7-ff04-4de8-9955-3871a7621f8c ==============================
[0m10:55:49.256179 [info ] [MainThread]: Running with dbt=1.5.11
[0m10:55:49.257374 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\cs\\dbt\\dbt_tutorial\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:55:49.343372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e77e98f7-ff04-4de8-9955-3871a7621f8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F934BC7340>]}
[0m10:55:49.361508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e77e98f7-ff04-4de8-9955-3871a7621f8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F934D1CA30>]}
[0m10:55:49.362508 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m10:55:49.375607 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m10:55:49.470456 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:55:49.471457 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:55:49.476460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e77e98f7-ff04-4de8-9955-3871a7621f8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F935084DF0>]}
[0m10:55:49.482689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e77e98f7-ff04-4de8-9955-3871a7621f8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F93504DDB0>]}
[0m10:55:49.483690 [info ] [MainThread]: Found 3 models, 7 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m10:55:49.483690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e77e98f7-ff04-4de8-9955-3871a7621f8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F93504DE40>]}
[0m10:55:49.485725 [info ] [MainThread]: 
[0m10:55:49.486690 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:55:49.488167 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m10:55:49.498580 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:55:49.499579 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m10:55:49.499579 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:55:49.554042 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:55:49.554042 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:55:49.555042 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m10:55:49.560041 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m10:55:49.561042 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m10:55:49.562050 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m10:55:49.568262 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:49.568784 [debug] [MainThread]: On master: BEGIN
[0m10:55:49.568784 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:55:49.603412 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:55:49.603412 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:49.604413 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:55:49.795189 [debug] [MainThread]: SQL status: SELECT 147 in 0.0 seconds
[0m10:55:49.799188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e77e98f7-ff04-4de8-9955-3871a7621f8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F93504B700>]}
[0m10:55:49.800188 [debug] [MainThread]: On master: ROLLBACK
[0m10:55:49.801188 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:49.802187 [debug] [MainThread]: On master: BEGIN
[0m10:55:49.803189 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:55:49.804190 [debug] [MainThread]: On master: COMMIT
[0m10:55:49.804190 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:49.805189 [debug] [MainThread]: On master: COMMIT
[0m10:55:49.806204 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:55:49.806204 [debug] [MainThread]: On master: Close
[0m10:55:49.808200 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:55:49.809195 [info ] [MainThread]: 
[0m10:55:49.819245 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:55:49.819793 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:55:49.820315 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:55:49.820850 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:55:49.821373 [info ] [Thread-1 (]: 1 of 7 START test accepted_values_sales_order_header_status__1__2__3__4 ........ [RUN]
[0m10:55:49.821889 [info ] [Thread-2 (]: 2 of 7 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m10:55:49.822411 [info ] [Thread-3 (]: 3 of 7 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m10:55:49.824011 [info ] [Thread-4 (]: 4 of 7 START test not_null_sales_order_header_row_id ........................... [RUN]
[0m10:55:49.825005 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405'
[0m10:55:49.825005 [debug] [Thread-2 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710'
[0m10:55:49.826005 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778'
[0m10:55:49.827006 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438'
[0m10:55:49.828007 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:55:49.828007 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:55:49.829006 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:55:49.829006 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:55:49.848948 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:55:49.860091 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:55:49.865097 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:55:49.871090 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:55:49.872093 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (compile): 10:55:49.830005 => 10:55:49.872093
[0m10:55:49.874097 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:55:49.875103 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 10:55:49.849948 => 10:55:49.874097
[0m10:55:49.876092 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (compile): 10:55:49.861091 => 10:55:49.875103
[0m10:55:49.890251 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (compile): 10:55:49.865097 => 10:55:49.890251
[0m10:55:49.892348 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:55:49.893349 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:55:49.894348 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:55:49.894348 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:55:49.897347 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:55:49.900348 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:55:49.901349 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:55:49.904347 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:55:49.905348 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: BEGIN
[0m10:55:49.905348 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:55:49.906349 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:55:49.907351 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:55:49.907468 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:55:49.908348 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m10:55:49.908348 [debug] [Thread-2 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m10:55:49.909349 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: BEGIN
[0m10:55:49.910350 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:55:49.910350 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:55:49.911351 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:55:49.932913 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:55:49.933917 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:55:49.934918 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:55:49.935910 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:55:49.936914 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        status as value_field,
        count(*) as n_records

    from "Adventureworks"."warehouse"."sales_order_header"
    group by status

)

select *
from all_values
where value_field not in (
    '1','2','3','4'
)



      
    ) dbt_internal_test
[0m10:55:49.937911 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m10:55:49.945503 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:55:49.946499 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:55:49.946499 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:55:49.947500 [debug] [Thread-2 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m10:55:49.949499 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (execute): 10:55:49.898349 => 10:55:49.949499
[0m10:55:49.950498 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m10:55:49.951503 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:55:49.952499 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: Close
[0m10:55:49.952499 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:55:49.954498 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 10:55:49.895348 => 10:55:49.954498
[0m10:55:49.955499 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:55:49.956499 [info ] [Thread-3 (]: 3 of 7 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.13s]
[0m10:55:49.956499 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:55:49.957689 [debug] [Thread-2 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m10:55:49.959606 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (execute): 10:55:49.876092 => 10:55:49.959082
[0m10:55:49.960151 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:55:49.960662 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select row_id
from "Adventureworks"."warehouse"."sales_order_header"
where row_id is null



      
    ) dbt_internal_test
[0m10:55:49.961711 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: ROLLBACK
[0m10:55:49.962239 [debug] [Thread-2 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m10:55:49.962764 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:55:49.966286 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: Close
[0m10:55:49.965523 [error] [Thread-2 (]: 2 of 7 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.14s]
[0m10:55:49.966061 [info ] [Thread-3 (]: 5 of 7 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m10:55:49.968493 [error] [Thread-1 (]: 1 of 7 FAIL 1 accepted_values_sales_order_header_status__1__2__3__4 ............ [[31mFAIL 1[0m in 0.14s]
[0m10:55:49.969561 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:55:49.970098 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778, now test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321)
[0m10:55:49.971142 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:55:49.971672 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:55:49.972203 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:55:49.973264 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:55:49.973806 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:55:49.975366 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (execute): 10:55:49.901349 => 10:55:49.975366
[0m10:55:49.975884 [info ] [Thread-2 (]: 6 of 7 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m10:55:49.983164 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:55:49.983684 [info ] [Thread-1 (]: 7 of 7 START test unique_sales_order_header_row_id ............................. [RUN]
[0m10:55:49.984208 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: ROLLBACK
[0m10:55:49.984729 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710, now test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493)
[0m10:55:49.985768 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405, now test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e)
[0m10:55:49.986766 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (compile): 10:55:49.976404 => 10:55:49.985768
[0m10:55:49.986766 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:55:49.987767 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: Close
[0m10:55:49.987767 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:55:49.988767 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:55:49.994862 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:55:50.000214 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:55:49.995864 [info ] [Thread-4 (]: 4 of 7 PASS not_null_sales_order_header_row_id ................................. [[32mPASS[0m in 0.17s]
[0m10:55:50.003417 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:55:50.004460 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (compile): 10:55:49.988767 => 10:55:50.003935
[0m10:55:50.004981 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:55:50.006059 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (compile): 10:55:49.995864 => 10:55:50.005514
[0m10:55:50.007149 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:55:50.007663 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:55:50.008295 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:55:50.010876 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:55:50.011387 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m10:55:50.014393 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:55:50.015482 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:55:50.016483 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:55:50.017488 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:55:50.017488 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m10:55:50.018484 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: BEGIN
[0m10:55:50.018484 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:55:50.019486 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:55:50.033609 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:55:50.033609 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:55:50.034608 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:55:50.036609 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:55:50.037608 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (execute): 10:55:50.001272 => 10:55:50.037608
[0m10:55:50.038608 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m10:55:50.038608 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: Close
[0m10:55:50.039608 [info ] [Thread-3 (]: 5 of 7 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.07s]
[0m10:55:50.041236 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:55:50.057053 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:55:50.057053 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:55:50.058086 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:55:50.058581 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:55:50.059586 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:55:50.059586 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    row_id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."sales_order_header"
where row_id is not null
group by row_id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:55:50.060583 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:55:50.063582 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (execute): 10:55:50.008815 => 10:55:50.062592
[0m10:55:50.063582 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m10:55:50.065792 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m10:55:50.066875 [info ] [Thread-2 (]: 6 of 7 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.08s]
[0m10:55:50.067877 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:55:50.081172 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:55:50.082182 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (execute): 10:55:50.011387 => 10:55:50.082182
[0m10:55:50.083184 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: ROLLBACK
[0m10:55:50.084182 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: Close
[0m10:55:50.085180 [info ] [Thread-1 (]: 7 of 7 PASS unique_sales_order_header_row_id ................................... [[32mPASS[0m in 0.10s]
[0m10:55:50.086180 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:55:50.088366 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:50.088883 [debug] [MainThread]: On master: BEGIN
[0m10:55:50.089403 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:55:50.105333 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:55:50.106334 [debug] [MainThread]: On master: COMMIT
[0m10:55:50.106334 [debug] [MainThread]: Using postgres connection "master"
[0m10:55:50.106334 [debug] [MainThread]: On master: COMMIT
[0m10:55:50.107333 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:55:50.108429 [debug] [MainThread]: On master: Close
[0m10:55:50.108429 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:55:50.109431 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m10:55:50.109431 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e' was properly closed.
[0m10:55:50.110431 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m10:55:50.110431 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m10:55:50.111436 [debug] [MainThread]: Connection 'test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438' was properly closed.
[0m10:55:50.112432 [info ] [MainThread]: 
[0m10:55:50.113429 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 0.63 seconds (0.63s).
[0m10:55:50.115429 [debug] [MainThread]: Command end result
[0m10:55:50.122255 [info ] [MainThread]: 
[0m10:55:50.123330 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m10:55:50.123848 [info ] [MainThread]: 
[0m10:55:50.124370 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models\example\schema.yml)[0m
[0m10:55:50.125430 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:55:50.125950 [info ] [MainThread]: 
[0m10:55:50.126469 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\example\schema.yml\not_null_my_first_dbt_model_id.sql
[0m10:55:50.126989 [info ] [MainThread]: 
[0m10:55:50.127507 [error] [MainThread]: [31mFailure in test accepted_values_sales_order_header_status__1__2__3__4 (models\warehouse\sales_order_header.yml)[0m
[0m10:55:50.128026 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:55:50.128536 [info ] [MainThread]: 
[0m10:55:50.128536 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\warehouse\sales_order_header.yml\accepted_values_sales_order_header_status__1__2__3__4.sql
[0m10:55:50.129535 [info ] [MainThread]: 
[0m10:55:50.130535 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=2 SKIP=0 TOTAL=7
[0m10:55:50.130535 [debug] [MainThread]: Command `dbt test` failed at 10:55:50.130535 after 0.91 seconds
[0m10:55:50.131535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F932677640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F934BC6FE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F93504D360>]}
[0m10:55:50.131535 [debug] [MainThread]: Flushing usage events
[0m11:04:32.301517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280B473640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280D8D3310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280D8D31C0>]}


============================== 11:04:32.306516 | cc942e56-0112-4c5e-986f-17155a07bad7 ==============================
[0m11:04:32.306516 [info ] [MainThread]: Running with dbt=1.5.11
[0m11:04:32.306516 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'D:\\cs\\dbt\\dbt_tutorial\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:04:32.390377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cc942e56-0112-4c5e-986f-17155a07bad7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280D8D3A60>]}
[0m11:04:32.409471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cc942e56-0112-4c5e-986f-17155a07bad7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280DA3CB20>]}
[0m11:04:32.410470 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m11:04:32.422313 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m11:04:32.478141 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:04:32.478141 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:04:32.483342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cc942e56-0112-4c5e-986f-17155a07bad7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280DE84EE0>]}
[0m11:04:32.490511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cc942e56-0112-4c5e-986f-17155a07bad7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280DA89EA0>]}
[0m11:04:32.490511 [info ] [MainThread]: Found 3 models, 7 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m11:04:32.491512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cc942e56-0112-4c5e-986f-17155a07bad7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280DA89F30>]}
[0m11:04:32.493548 [info ] [MainThread]: 
[0m11:04:32.493548 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:04:32.495514 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m11:04:32.505514 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m11:04:32.505514 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m11:04:32.506514 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:04:32.543545 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m11:04:32.544552 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m11:04:32.546558 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m11:04:32.553516 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m11:04:32.554035 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m11:04:32.554035 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:04:32.572228 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:04:32.572228 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m11:04:32.573228 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m11:04:32.577370 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m11:04:32.578377 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m11:04:32.579377 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m11:04:32.585107 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:32.585624 [debug] [MainThread]: On master: BEGIN
[0m11:04:32.586143 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:04:32.600588 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:04:32.601588 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:32.601588 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:04:32.880198 [debug] [MainThread]: SQL status: SELECT 147 in 0.0 seconds
[0m11:04:32.884394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cc942e56-0112-4c5e-986f-17155a07bad7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280DEC1720>]}
[0m11:04:32.884394 [debug] [MainThread]: On master: ROLLBACK
[0m11:04:32.886393 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:32.886393 [debug] [MainThread]: On master: BEGIN
[0m11:04:32.889396 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:04:32.890450 [debug] [MainThread]: On master: COMMIT
[0m11:04:32.891623 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:32.891623 [debug] [MainThread]: On master: COMMIT
[0m11:04:32.893622 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:04:32.894619 [debug] [MainThread]: On master: Close
[0m11:04:32.894619 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:04:32.895621 [info ] [MainThread]: 
[0m11:04:32.904665 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.my_first_dbt_model
[0m11:04:32.905181 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_header
[0m11:04:32.905735 [info ] [Thread-1 (]: 1 of 3 START sql table model warehouse.my_first_dbt_model ...................... [RUN]
[0m11:04:32.906263 [info ] [Thread-2 (]: 2 of 3 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m11:04:32.907833 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.my_first_dbt_model'
[0m11:04:32.908353 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m11:04:32.908871 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.my_first_dbt_model
[0m11:04:32.909392 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m11:04:32.918875 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.my_first_dbt_model"
[0m11:04:32.920900 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m11:04:32.922880 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (compile): 11:04:32.909392 => 11:04:32.922880
[0m11:04:32.923875 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 11:04:32.918875 => 11:04:32.922880
[0m11:04:32.923875 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.my_first_dbt_model
[0m11:04:32.924876 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m11:04:32.965756 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_tutorial.my_first_dbt_model"
[0m11:04:32.969758 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m11:04:32.970790 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m11:04:32.971761 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: BEGIN
[0m11:04:32.971761 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m11:04:32.972758 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:04:32.973680 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m11:04:32.974327 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:04:33.011640 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m11:04:33.012638 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m11:04:33.013641 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:04:33.013641 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m11:04:33.014638 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m11:04:33.014638 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */

  
    

  create  table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m11:04:33.032799 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m11:04:33.040914 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m11:04:33.040914 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m11:04:33.044914 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:04:33.047916 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m11:04:33.048916 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m11:04:33.050918 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:04:33.081334 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m11:04:33.083053 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */

    
  
  comment on table "Adventureworks"."warehouse"."my_first_dbt_model" is $dbt_comment_literal_block$A starter dbt model$dbt_comment_literal_block$;

  
[0m11:04:33.086709 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m11:04:33.088285 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m11:04:33.088796 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m11:04:33.089332 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m11:04:33.099002 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:04:33.104003 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m11:04:33.105003 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
drop table if exists "Adventureworks"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m11:04:33.117209 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:04:33.119211 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (execute): 11:04:32.924876 => 11:04:33.119211
[0m11:04:33.119211 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: Close
[0m11:04:33.121211 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc942e56-0112-4c5e-986f-17155a07bad7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280DF718A0>]}
[0m11:04:33.122210 [info ] [Thread-1 (]: 1 of 3 OK created sql table model warehouse.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.21s]
[0m11:04:33.124210 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.my_first_dbt_model
[0m11:04:33.125210 [debug] [Thread-4 (]: Began running node model.dbt_tutorial.my_second_dbt_model
[0m11:04:33.126135 [info ] [Thread-4 (]: 3 of 3 START sql view model warehouse.my_second_dbt_model ...................... [RUN]
[0m11:04:33.127726 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_tutorial.my_second_dbt_model'
[0m11:04:33.128816 [debug] [Thread-4 (]: Began compiling node model.dbt_tutorial.my_second_dbt_model
[0m11:04:33.133141 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_tutorial.my_second_dbt_model"
[0m11:04:33.134718 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (compile): 11:04:33.129341 => 11:04:33.134190
[0m11:04:33.135340 [debug] [Thread-4 (]: Began executing node model.dbt_tutorial.my_second_dbt_model
[0m11:04:33.159255 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_tutorial.my_second_dbt_model"
[0m11:04:33.160257 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m11:04:33.161257 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: BEGIN
[0m11:04:33.162256 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:04:33.181392 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m11:04:33.182507 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m11:04:33.182507 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */

  create view "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m11:04:33.187507 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m11:04:33.190601 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m11:04:33.191602 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m11:04:33.192602 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:04:33.194601 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m11:04:33.195603 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */

    
  
  comment on view "Adventureworks"."warehouse"."my_second_dbt_model" is $dbt_comment_literal_block$A starter dbt model$dbt_comment_literal_block$;

  
[0m11:04:33.197167 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m11:04:33.199161 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m11:04:33.199161 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m11:04:33.200160 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m11:04:33.206166 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m11:04:33.209160 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m11:04:33.209160 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
drop view if exists "Adventureworks"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m11:04:33.211161 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m11:04:33.213160 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (execute): 11:04:33.135872 => 11:04:33.213160
[0m11:04:33.214175 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: Close
[0m11:04:33.215160 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc942e56-0112-4c5e-986f-17155a07bad7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280DEE0580>]}
[0m11:04:33.215160 [info ] [Thread-4 (]: 3 of 3 OK created sql view model warehouse.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.09s]
[0m11:04:33.217160 [debug] [Thread-4 (]: Finished running node model.dbt_tutorial.my_second_dbt_model
[0m11:04:33.236677 [debug] [Thread-2 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m11:04:33.240724 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m11:04:33.240804 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m11:04:33.243806 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:04:33.249804 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m11:04:33.249804 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m11:04:33.251808 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:04:33.254804 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m11:04:33.255804 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m11:04:33.256808 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m11:04:33.257979 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m11:04:33.258979 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m11:04:33.258979 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m11:04:33.261990 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m11:04:33.264980 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m11:04:33.264980 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m11:04:33.270093 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:04:33.272091 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 11:04:32.966794 => 11:04:33.272091
[0m11:04:33.272091 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_header: Close
[0m11:04:33.273091 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cc942e56-0112-4c5e-986f-17155a07bad7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280DF63F40>]}
[0m11:04:33.274092 [info ] [Thread-2 (]: 2 of 3 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.37s]
[0m11:04:33.275091 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m11:04:33.277626 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:33.278197 [debug] [MainThread]: On master: BEGIN
[0m11:04:33.278197 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:04:33.293483 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:04:33.294485 [debug] [MainThread]: On master: COMMIT
[0m11:04:33.294485 [debug] [MainThread]: Using postgres connection "master"
[0m11:04:33.294485 [debug] [MainThread]: On master: COMMIT
[0m11:04:33.295483 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:04:33.296484 [debug] [MainThread]: On master: Close
[0m11:04:33.296484 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:04:33.297485 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m11:04:33.297485 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m11:04:33.298485 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_first_dbt_model' was properly closed.
[0m11:04:33.298485 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m11:04:33.298485 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_second_dbt_model' was properly closed.
[0m11:04:33.299484 [info ] [MainThread]: 
[0m11:04:33.300487 [info ] [MainThread]: Finished running 2 table models, 1 view model in 0 hours 0 minutes and 0.81 seconds (0.81s).
[0m11:04:33.302068 [debug] [MainThread]: Command end result
[0m11:04:33.316187 [info ] [MainThread]: 
[0m11:04:33.316300 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:04:33.317303 [info ] [MainThread]: 
[0m11:04:33.317303 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m11:04:33.318301 [debug] [MainThread]: Command `dbt run` succeeded at 11:04:33.318301 after 1.03 seconds
[0m11:04:33.319303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280B473640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280D8D3A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002280DECD510>]}
[0m11:04:33.320306 [debug] [MainThread]: Flushing usage events
[0m11:28:36.405745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398B277640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398D6C3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398D6C3100>]}


============================== 11:28:36.419905 | 62f2500b-133b-4c9a-9031-917b2cf99ad9 ==============================
[0m11:28:36.419905 [info ] [MainThread]: Running with dbt=1.5.11
[0m11:28:36.420905 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:28:36.680806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62f2500b-133b-4c9a-9031-917b2cf99ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398D6C33A0>]}
[0m11:28:36.700058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '62f2500b-133b-4c9a-9031-917b2cf99ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398DA1CA90>]}
[0m11:28:36.708057 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m11:28:36.729047 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m11:28:37.422087 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:28:37.422607 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:28:37.428585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '62f2500b-133b-4c9a-9031-917b2cf99ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398DB84E50>]}
[0m11:28:37.453154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '62f2500b-133b-4c9a-9031-917b2cf99ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398DA69E10>]}
[0m11:28:37.453154 [info ] [MainThread]: Found 3 models, 7 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m11:28:37.454155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62f2500b-133b-4c9a-9031-917b2cf99ad9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398DA69EA0>]}
[0m11:28:37.456154 [info ] [MainThread]: 
[0m11:28:37.457448 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:28:37.461958 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m11:28:37.480792 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m11:28:37.481792 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m11:28:37.481792 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:28:41.565516 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

[0m11:28:45.640559 [debug] [ThreadPool]: Postgres adapter: Error running SQL: BEGIN
[0m11:28:45.641564 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m11:28:45.646789 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_relations_without_caching
[0m11:28:45.648562 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m11:28:45.650557 [debug] [ThreadPool]: On list_Adventureworks_warehouse: No close available on handle
[0m11:28:45.654674 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:28:45.654674 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m11:28:45.654674 [info ] [MainThread]: 
[0m11:28:45.654674 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 8.20 seconds (8.20s).
[0m11:28:45.664683 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  
[0m11:28:45.668553 [debug] [MainThread]: Command `dbt test` failed at 11:28:45.668553 after 9.33 seconds
[0m11:28:45.671561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398B277640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398DA69840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002398DBC9300>]}
[0m11:28:45.671561 [debug] [MainThread]: Flushing usage events
[0m11:29:11.842244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C20D83640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C232C3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C232C3100>]}


============================== 11:29:11.859032 | 203f5068-90a2-4b33-bbed-58f48b6f3ff9 ==============================
[0m11:29:11.859032 [info ] [MainThread]: Running with dbt=1.5.11
[0m11:29:11.860030 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m11:29:11.935518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '203f5068-90a2-4b33-bbed-58f48b6f3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C232C33A0>]}
[0m11:29:11.951143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '203f5068-90a2-4b33-bbed-58f48b6f3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C2361CA90>]}
[0m11:29:11.951143 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m11:29:11.966767 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m11:29:12.021164 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:29:12.021164 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:29:12.037398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '203f5068-90a2-4b33-bbed-58f48b6f3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C23784E50>]}
[0m11:29:12.037398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '203f5068-90a2-4b33-bbed-58f48b6f3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C2374DE10>]}
[0m11:29:12.037398 [info ] [MainThread]: Found 3 models, 7 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m11:29:12.037398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '203f5068-90a2-4b33-bbed-58f48b6f3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C2374DEA0>]}
[0m11:29:12.037398 [info ] [MainThread]: 
[0m11:29:12.037398 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:29:12.037398 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m11:29:12.053030 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m11:29:12.053030 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m11:29:12.053030 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:29:12.123743 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.128252 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m11:29:12.128252 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m11:29:12.145887 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m11:29:12.145887 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m11:29:12.161520 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m11:29:12.161520 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:12.161520 [debug] [MainThread]: On master: BEGIN
[0m11:29:12.161520 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:29:12.184915 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.184915 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:12.184915 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:29:12.328440 [debug] [MainThread]: SQL status: SELECT 147 in 0.0 seconds
[0m11:29:12.345583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '203f5068-90a2-4b33-bbed-58f48b6f3ff9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C233F4160>]}
[0m11:29:12.345583 [debug] [MainThread]: On master: ROLLBACK
[0m11:29:12.345583 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:12.345583 [debug] [MainThread]: On master: BEGIN
[0m11:29:12.345583 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.345583 [debug] [MainThread]: On master: COMMIT
[0m11:29:12.345583 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:12.345583 [debug] [MainThread]: On master: COMMIT
[0m11:29:12.345583 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:29:12.345583 [debug] [MainThread]: On master: Close
[0m11:29:12.345583 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:29:12.345583 [info ] [MainThread]: 
[0m11:29:12.364281 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m11:29:12.364802 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m11:29:12.365320 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m11:29:12.365842 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m11:29:12.366371 [info ] [Thread-1 (]: 1 of 7 START test accepted_values_sales_order_header_status__1__2__3__4 ........ [RUN]
[0m11:29:12.366896 [info ] [Thread-2 (]: 2 of 7 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m11:29:12.367424 [info ] [Thread-3 (]: 3 of 7 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m11:29:12.367953 [info ] [Thread-4 (]: 4 of 7 START test not_null_sales_order_header_row_id ........................... [RUN]
[0m11:29:12.369006 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405'
[0m11:29:12.369511 [debug] [Thread-2 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710'
[0m11:29:12.369511 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778'
[0m11:29:12.369511 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438'
[0m11:29:12.369511 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m11:29:12.369511 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m11:29:12.369511 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m11:29:12.369511 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m11:29:12.385170 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m11:29:12.385170 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m11:29:12.402989 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m11:29:12.407122 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m11:29:12.409088 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (compile): 11:29:12.385170 => 11:29:12.409088
[0m11:29:12.410094 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 11:29:12.385170 => 11:29:12.410094
[0m11:29:12.410094 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m11:29:12.411090 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m11:29:12.412094 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (compile): 11:29:12.404088 => 11:29:12.412094
[0m11:29:12.412094 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (compile): 11:29:12.369511 => 11:29:12.412094
[0m11:29:12.420125 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m11:29:12.420125 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m11:29:12.420125 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m11:29:12.420125 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m11:29:12.420125 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m11:29:12.420125 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m11:29:12.420125 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m11:29:12.420125 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m11:29:12.435752 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m11:29:12.435752 [debug] [Thread-2 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m11:29:12.435752 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m11:29:12.435752 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m11:29:12.435752 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m11:29:12.435752 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m11:29:12.435752 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: BEGIN
[0m11:29:12.435752 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: BEGIN
[0m11:29:12.435752 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:29:12.435752 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:29:12.451962 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.451962 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m11:29:12.451962 [debug] [Thread-2 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m11:29:12.451962 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.451962 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m11:29:12.451962 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m11:29:12.451962 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.451962 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m11:29:12.451962 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        status as value_field,
        count(*) as n_records

    from "Adventureworks"."warehouse"."sales_order_header"
    group by status

)

select *
from all_values
where value_field not in (
    '1','2','3','4'
)



      
    ) dbt_internal_test
[0m11:29:12.467599 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:29:12.467599 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:29:12.467599 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (execute): 11:29:12.413124 => 11:29:12.467599
[0m11:29:12.467599 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 11:29:12.420125 => 11:29:12.467599
[0m11:29:12.467599 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.467599 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m11:29:12.467599 [debug] [Thread-2 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m11:29:12.467599 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m11:29:12.467599 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select row_id
from "Adventureworks"."warehouse"."sales_order_header"
where row_id is null



      
    ) dbt_internal_test
[0m11:29:12.467599 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: Close
[0m11:29:12.467599 [debug] [Thread-2 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m11:29:12.467599 [info ] [Thread-3 (]: 3 of 7 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.10s]
[0m11:29:12.467599 [error] [Thread-2 (]: 2 of 7 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.10s]
[0m11:29:12.467599 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m11:29:12.482360 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m11:29:12.482952 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m11:29:12.484021 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m11:29:12.485668 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:29:12.486203 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:29:12.485142 [info ] [Thread-3 (]: 5 of 7 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m11:29:12.487256 [info ] [Thread-2 (]: 6 of 7 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m11:29:12.489345 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (execute): 11:29:12.420125 => 11:29:12.488826
[0m11:29:12.490383 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (execute): 11:29:12.420125 => 11:29:12.490383
[0m11:29:12.491434 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778, now test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321)
[0m11:29:12.491962 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710, now test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493)
[0m11:29:12.492486 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: ROLLBACK
[0m11:29:12.493007 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: ROLLBACK
[0m11:29:12.493524 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m11:29:12.494048 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m11:29:12.495614 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m11:29:12.495614 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: Close
[0m11:29:12.495614 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: Close
[0m11:29:12.495614 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m11:29:12.495614 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (compile): 11:29:12.495107 => 11:29:12.495614
[0m11:29:12.495614 [error] [Thread-1 (]: 1 of 7 FAIL 1 accepted_values_sales_order_header_status__1__2__3__4 ............ [[31mFAIL 1[0m in 0.13s]
[0m11:29:12.495614 [info ] [Thread-4 (]: 4 of 7 PASS not_null_sales_order_header_row_id ................................. [[32mPASS[0m in 0.13s]
[0m11:29:12.511607 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m11:29:12.513313 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (compile): 11:29:12.495614 => 11:29:12.512766
[0m11:29:12.513963 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m11:29:12.515000 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m11:29:12.517103 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m11:29:12.517629 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m11:29:12.518675 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m11:29:12.523001 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m11:29:12.523522 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m11:29:12.523522 [info ] [Thread-1 (]: 7 of 7 START test unique_sales_order_header_row_id ............................. [RUN]
[0m11:29:12.524557 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m11:29:12.524557 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m11:29:12.525565 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405, now test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e)
[0m11:29:12.525565 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:29:12.526567 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m11:29:12.527564 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m11:29:12.527564 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:29:12.529642 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m11:29:12.529642 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (compile): 11:29:12.528572 => 11:29:12.529642
[0m11:29:12.529642 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m11:29:12.529642 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m11:29:12.529642 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m11:29:12.529642 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: BEGIN
[0m11:29:12.529642 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:12.545272 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.545272 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m11:29:12.545272 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.545272 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m11:29:12.545272 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m11:29:12.545272 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m11:29:12.545272 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:29:12.545272 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (execute): 11:29:12.519198 => 11:29:12.545272
[0m11:29:12.545272 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:29:12.545272 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m11:29:12.545272 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (execute): 11:29:12.515000 => 11:29:12.545272
[0m11:29:12.545272 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.545272 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m11:29:12.560894 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m11:29:12.560894 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m11:29:12.560894 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: Close
[0m11:29:12.560894 [info ] [Thread-2 (]: 6 of 7 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.07s]
[0m11:29:12.560894 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    row_id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."sales_order_header"
where row_id is not null
group by row_id
having count(*) > 1



      
    ) dbt_internal_test
[0m11:29:12.565684 [info ] [Thread-3 (]: 5 of 7 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.07s]
[0m11:29:12.566745 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m11:29:12.568341 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m11:29:12.583438 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:29:12.583438 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (execute): 11:29:12.529642 => 11:29:12.583438
[0m11:29:12.583438 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: ROLLBACK
[0m11:29:12.583438 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: Close
[0m11:29:12.583438 [info ] [Thread-1 (]: 7 of 7 PASS unique_sales_order_header_row_id ................................... [[32mPASS[0m in 0.06s]
[0m11:29:12.588944 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m11:29:12.590917 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:12.591470 [debug] [MainThread]: On master: BEGIN
[0m11:29:12.591996 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:29:12.601446 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:29:12.601446 [debug] [MainThread]: On master: COMMIT
[0m11:29:12.601446 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:12.601446 [debug] [MainThread]: On master: COMMIT
[0m11:29:12.601446 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:29:12.601446 [debug] [MainThread]: On master: Close
[0m11:29:12.601446 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:29:12.601446 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m11:29:12.601446 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e' was properly closed.
[0m11:29:12.601446 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m11:29:12.601446 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m11:29:12.611906 [debug] [MainThread]: Connection 'test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438' was properly closed.
[0m11:29:12.612444 [info ] [MainThread]: 
[0m11:29:12.613510 [info ] [MainThread]: Finished running 7 tests in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m11:29:12.615066 [debug] [MainThread]: Command end result
[0m11:29:12.621256 [info ] [MainThread]: 
[0m11:29:12.621778 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m11:29:12.622297 [info ] [MainThread]: 
[0m11:29:12.623321 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models\example\schema.yml)[0m
[0m11:29:12.623321 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m11:29:12.623321 [info ] [MainThread]: 
[0m11:29:12.623321 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\example\schema.yml\not_null_my_first_dbt_model_id.sql
[0m11:29:12.623321 [info ] [MainThread]: 
[0m11:29:12.623321 [error] [MainThread]: [31mFailure in test accepted_values_sales_order_header_status__1__2__3__4 (models\warehouse\sales_order_header.yml)[0m
[0m11:29:12.623321 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m11:29:12.623321 [info ] [MainThread]: 
[0m11:29:12.627474 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\warehouse\sales_order_header.yml\accepted_values_sales_order_header_status__1__2__3__4.sql
[0m11:29:12.628507 [info ] [MainThread]: 
[0m11:29:12.629065 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=2 SKIP=0 TOTAL=7
[0m11:29:12.630113 [debug] [MainThread]: Command `dbt test` failed at 11:29:12.629585 after 0.80 seconds
[0m11:29:12.630638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C20D83640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C2374D8A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C2374D450>]}
[0m11:29:12.631163 [debug] [MainThread]: Flushing usage events
[0m09:57:54.047119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD30C77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD330C7280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD330C7130>]}


============================== 09:57:54.059684 | 43c7502f-539d-4d21-9be1-3ec5706600dc ==============================
[0m09:57:54.059684 [info ] [MainThread]: Running with dbt=1.5.11
[0m09:57:54.060683 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m09:57:54.252261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '43c7502f-539d-4d21-9be1-3ec5706600dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD330C73D0>]}
[0m09:57:54.271719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '43c7502f-539d-4d21-9be1-3ec5706600dc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD3341CAC0>]}
[0m09:57:54.277217 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m09:57:54.296124 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m09:57:54.991203 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 1 files changed.
[0m09:57:54.991203 [debug] [MainThread]: Partial parsing: added file: dbt_tutorial://tests\generic\test_greater_than_column.sql
[0m09:57:54.992204 [debug] [MainThread]: Partial parsing: added file: dbt_tutorial://tests\test_due_date_before_order_date.sql
[0m09:57:54.993204 [debug] [MainThread]: Partial parsing: updated file: dbt_tutorial://models\warehouse\sales_order_header.yml
[0m09:57:54.993204 [error] [MainThread]: Encountered an error:
Compilation Error
  Reached EOF without finding a close tag for test (searched from line 1)
[0m09:57:54.994206 [debug] [MainThread]: Command `dbt test` failed at 09:57:54.994206 after 0.98 seconds
[0m09:57:54.995206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD30C77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD334F03A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DD334F0370>]}
[0m09:57:54.995206 [debug] [MainThread]: Flushing usage events
[0m09:58:41.659390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F59FC77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A20C7280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A20C7130>]}


============================== 09:58:41.662963 | 53385ac5-57e1-4c53-a39d-93543e188b83 ==============================
[0m09:58:41.662963 [info ] [MainThread]: Running with dbt=1.5.11
[0m09:58:41.663962 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m09:58:41.730501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '53385ac5-57e1-4c53-a39d-93543e188b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A20C73D0>]}
[0m09:58:41.749502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '53385ac5-57e1-4c53-a39d-93543e188b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A241CAC0>]}
[0m09:58:41.750501 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m09:58:41.763277 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m09:58:41.819646 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 1 files changed.
[0m09:58:41.820637 [debug] [MainThread]: Partial parsing: added file: dbt_tutorial://tests\generic\test_greater_than_column.sql
[0m09:58:41.820637 [debug] [MainThread]: Partial parsing: added file: dbt_tutorial://tests\test_due_date_before_order_date.sql
[0m09:58:41.821637 [debug] [MainThread]: Partial parsing: updated file: dbt_tutorial://models\warehouse\sales_order_header.yml
[0m09:58:41.862638 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m09:58:41.960704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '53385ac5-57e1-4c53-a39d-93543e188b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A26640D0>]}
[0m09:58:41.969705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53385ac5-57e1-4c53-a39d-93543e188b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A25766E0>]}
[0m09:58:41.970705 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m09:58:41.971707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53385ac5-57e1-4c53-a39d-93543e188b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A2576A40>]}
[0m09:58:41.974138 [info ] [MainThread]: 
[0m09:58:41.974138 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m09:58:41.976137 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m09:58:41.988178 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m09:58:41.988178 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m09:58:41.989174 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:58:42.159259 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m09:58:42.160258 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m09:58:42.160258 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m09:58:42.256906 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m09:58:42.258904 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m09:58:42.261914 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m09:58:42.267911 [debug] [MainThread]: Using postgres connection "master"
[0m09:58:42.268906 [debug] [MainThread]: On master: BEGIN
[0m09:58:42.268906 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:58:42.290810 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m09:58:42.291810 [debug] [MainThread]: Using postgres connection "master"
[0m09:58:42.291810 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m09:58:42.966467 [debug] [MainThread]: SQL status: SELECT 147 in 1.0 seconds
[0m09:58:42.974501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53385ac5-57e1-4c53-a39d-93543e188b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A25A7460>]}
[0m09:58:42.976464 [debug] [MainThread]: On master: ROLLBACK
[0m09:58:42.980466 [debug] [MainThread]: Using postgres connection "master"
[0m09:58:42.981461 [debug] [MainThread]: On master: BEGIN
[0m09:58:42.984481 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m09:58:42.986472 [debug] [MainThread]: On master: COMMIT
[0m09:58:42.987474 [debug] [MainThread]: Using postgres connection "master"
[0m09:58:42.988468 [debug] [MainThread]: On master: COMMIT
[0m09:58:42.992463 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m09:58:42.993481 [debug] [MainThread]: On master: Close
[0m09:58:42.995462 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m09:58:42.998468 [info ] [MainThread]: 
[0m09:58:43.019832 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m09:58:43.021836 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m09:58:43.022829 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m09:58:43.022829 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m09:58:43.023830 [info ] [Thread-1 (]: 1 of 9 START test accepted_values_sales_order_header_status__1__2__3__4 ........ [RUN]
[0m09:58:43.024835 [info ] [Thread-2 (]: 2 of 9 START test greater_than_column_sales_order_header_duedate__orderdate .... [RUN]
[0m09:58:43.025834 [info ] [Thread-3 (]: 3 of 9 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m09:58:43.026834 [info ] [Thread-4 (]: 4 of 9 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m09:58:43.029830 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405'
[0m09:58:43.031830 [debug] [Thread-2 (]: Acquiring new postgres connection 'test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f'
[0m09:58:43.031830 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710'
[0m09:58:43.033850 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778'
[0m09:58:43.033850 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m09:58:43.035908 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m09:58:43.036919 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m09:58:43.038823 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m09:58:43.053174 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m09:58:43.070067 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m09:58:43.086168 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m09:58:43.095160 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m09:58:43.098596 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 09:58:43.071109 => 09:58:43.097968
[0m09:58:43.099594 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (compile): 09:58:43.038823 => 09:58:43.098596
[0m09:58:43.100595 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (compile): 09:58:43.087193 => 09:58:43.099594
[0m09:58:43.102048 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m09:58:43.103817 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f (compile): 09:58:43.054208 => 09:58:43.103044
[0m09:58:43.105759 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m09:58:43.107775 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m09:58:43.130879 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m09:58:43.131877 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m09:58:43.135979 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m09:58:43.141969 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m09:58:43.142959 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m09:58:43.144965 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m09:58:43.145936 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m09:58:43.145936 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m09:58:43.146936 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m09:58:43.147936 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m09:58:43.148937 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m09:58:43.148937 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: BEGIN
[0m09:58:43.150001 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m09:58:43.150534 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: BEGIN
[0m09:58:43.150534 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:58:43.151514 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m09:58:43.151514 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m09:58:43.182242 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.183242 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m09:58:43.183242 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m09:58:43.188241 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.188241 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.188241 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m09:58:43.189241 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m09:58:43.189241 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m09:58:43.190241 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        status as value_field,
        count(*) as n_records

    from "Adventureworks"."warehouse"."sales_order_header"
    group by status

)

select *
from all_values
where value_field not in (
    '1','2','3','4'
)



      
    ) dbt_internal_test
[0m09:58:43.196241 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.197241 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m09:58:43.197241 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

SELECT duedate, orderdate, count(1) as num_occurrences
FROM "Adventureworks"."warehouse"."sales_order_header"
WHERE duedate < 
GROUP BY 1,2


      
    ) dbt_internal_test
[0m09:58:43.199241 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m09:58:43.199241 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m09:58:43.202241 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 09:58:43.108745 => 09:58:43.202241
[0m09:58:43.202241 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near "GROUP"
LINE 12: GROUP BY 1,2
         ^

[0m09:58:43.204242 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (execute): 09:58:43.138943 => 09:58:43.203243
[0m09:58:43.204242 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m09:58:43.205242 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: ROLLBACK
[0m09:58:43.205242 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m09:58:43.207243 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f (execute): 09:58:43.142959 => 09:58:43.206240
[0m09:58:43.207243 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: Close
[0m09:58:43.207243 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m09:58:43.208241 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: Close
[0m09:58:43.209244 [info ] [Thread-4 (]: 4 of 9 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.18s]
[0m09:58:43.210241 [error] [Thread-3 (]: 3 of 9 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.18s]
[0m09:58:43.213242 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m09:58:43.214165 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m09:58:43.215778 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m09:58:43.216842 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.test_due_date_before_order_date
[0m09:58:43.217365 [info ] [Thread-4 (]: 5 of 9 START test not_null_sales_order_header_row_id ........................... [RUN]
[0m09:58:43.218412 [info ] [Thread-3 (]: 6 of 9 START test test_due_date_before_order_date .............................. [RUN]
[0m09:58:43.218935 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778, now test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438)
[0m09:58:43.219979 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710, now test.dbt_tutorial.test_due_date_before_order_date)
[0m09:58:43.220502 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m09:58:43.221027 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.test_due_date_before_order_date
[0m09:58:43.227459 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m09:58:43.229388 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m09:58:43.232711 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.test_due_date_before_order_date"
[0m09:58:43.235317 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (execute): 09:58:43.131877 => 09:58:43.234805
[0m09:58:43.236356 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (compile): 09:58:43.221027 => 09:58:43.236356
[0m09:58:43.236873 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: ROLLBACK
[0m09:58:43.237395 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.test_due_date_before_order_date (compile): 09:58:43.230384 => 09:58:43.237395
[0m09:58:43.237912 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m09:58:43.238434 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.test_due_date_before_order_date
[0m09:58:43.241029 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m09:58:43.241549 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: Close
[0m09:58:43.243583 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.test_due_date_before_order_date"
[0m09:58:43.246583 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m09:58:43.245584 [error] [Thread-1 (]: 1 of 9 FAIL 1 accepted_values_sales_order_header_status__1__2__3__4 ............ [[31mFAIL 1[0m in 0.22s]
[0m09:58:43.247582 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: BEGIN
[0m09:58:43.247582 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.test_due_date_before_order_date"
[0m09:58:43.248582 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m09:58:43.249582 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m09:58:43.249582 [debug] [Thread-3 (]: On test.dbt_tutorial.test_due_date_before_order_date: BEGIN
[0m09:58:43.250581 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m09:58:43.250581 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m09:58:43.251585 [info ] [Thread-1 (]: 7 of 9 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m09:58:43.253581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405, now test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321)
[0m09:58:43.253581 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m09:58:43.264739 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m09:58:43.266884 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (compile): 09:58:43.254580 => 09:58:43.266884
[0m09:58:43.267928 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m09:58:43.271145 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m09:58:43.272727 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m09:58:43.273787 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m09:58:43.274837 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:58:43.275878 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.276411 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.test_due_date_before_order_date"
[0m09:58:43.277675 [debug] [Thread-3 (]: On test.dbt_tutorial.test_due_date_before_order_date: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.test_due_date_before_order_date"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT duedate, orderdate, count(1) as occurences
FROM "Adventureworks"."warehouse"."sales_order_header"
WHERE duedate < orderdate
GROUP BY duedate, orderdate
      
    ) dbt_internal_test
[0m09:58:43.281867 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.282868 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m09:58:43.285884 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select row_id
from "Adventureworks"."warehouse"."sales_order_header"
where row_id is null



      
    ) dbt_internal_test
[0m09:58:43.303865 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m09:58:43.310867 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (execute): 09:58:43.238951 => 09:58:43.309871
[0m09:58:43.312870 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: ROLLBACK
[0m09:58:43.317957 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: Close
[0m09:58:43.321947 [info ] [Thread-4 (]: 5 of 9 PASS not_null_sales_order_header_row_id ................................. [[32mPASS[0m in 0.10s]
[0m09:58:43.323947 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m09:58:43.324949 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m09:58:43.325948 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m09:58:43.329516 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.test_due_date_before_order_date (execute): 09:58:43.241549 => 09:58:43.328993
[0m09:58:43.330059 [info ] [Thread-4 (]: 8 of 9 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m09:58:43.331121 [debug] [Thread-3 (]: On test.dbt_tutorial.test_due_date_before_order_date: ROLLBACK
[0m09:58:43.331660 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438, now test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493)
[0m09:58:43.332727 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m09:58:43.338030 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m09:58:43.338550 [debug] [Thread-3 (]: On test.dbt_tutorial.test_due_date_before_order_date: Close
[0m09:58:43.341065 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.340064 [info ] [Thread-3 (]: 6 of 9 PASS test_due_date_before_order_date .................................... [[32mPASS[0m in 0.12s]
[0m09:58:43.344069 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (compile): 09:58:43.333261 => 09:58:43.342063
[0m09:58:43.344069 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m09:58:43.346060 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.test_due_date_before_order_date
[0m09:58:43.347064 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m09:58:43.348065 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m09:58:43.351076 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m09:58:43.358061 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m09:58:43.360063 [info ] [Thread-3 (]: 9 of 9 START test unique_sales_order_header_row_id ............................. [RUN]
[0m09:58:43.363064 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.test_due_date_before_order_date, now test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e)
[0m09:58:43.364063 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m09:58:43.365063 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m09:58:43.366067 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m09:58:43.379190 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m09:58:43.382185 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m09:58:43.389676 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (execute): 09:58:43.268449 => 09:58:43.389676
[0m09:58:43.391912 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m09:58:43.396322 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m09:58:43.400167 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (compile): 09:58:43.367061 => 09:58:43.398331
[0m09:58:43.402053 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m09:58:43.404616 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: Close
[0m09:58:43.416087 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m09:58:43.423283 [info ] [Thread-1 (]: 7 of 9 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.17s]
[0m09:58:43.428073 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m09:58:43.430047 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m09:58:43.434568 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: BEGIN
[0m09:58:43.437478 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m09:58:43.443014 [debug] [Thread-2 (]: Database Error in test greater_than_column_sales_order_header_duedate__orderdate (models\warehouse\sales_order_header.yml)
  syntax error at or near "GROUP"
  LINE 12: GROUP BY 1,2
           ^
  compiled Code at target\run\dbt_tutorial\models\warehouse\sales_order_header.yml\greater_than_column_sales_order_header_duedate__orderdate.sql
[0m09:58:43.452658 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.450662 [error] [Thread-2 (]: 2 of 9 ERROR greater_than_column_sales_order_header_duedate__orderdate ......... [[31mERROR[0m in 0.42s]
[0m09:58:43.453667 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m09:58:43.454665 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m09:58:43.455679 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m09:58:43.458658 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m09:58:43.460655 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (execute): 09:58:43.352068 => 09:58:43.459657
[0m09:58:43.460655 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m09:58:43.461655 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m09:58:43.464664 [info ] [Thread-4 (]: 8 of 9 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.13s]
[0m09:58:43.470662 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m09:58:43.475657 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.475657 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m09:58:43.476656 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    row_id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."sales_order_header"
where row_id is not null
group by row_id
having count(*) > 1



      
    ) dbt_internal_test
[0m09:58:43.567998 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m09:58:43.569999 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (execute): 09:58:43.405600 => 09:58:43.569999
[0m09:58:43.569999 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: ROLLBACK
[0m09:58:43.570998 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: Close
[0m09:58:43.571999 [info ] [Thread-3 (]: 9 of 9 PASS unique_sales_order_header_row_id ................................... [[32mPASS[0m in 0.21s]
[0m09:58:43.573001 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m09:58:43.574999 [debug] [MainThread]: Using postgres connection "master"
[0m09:58:43.576825 [debug] [MainThread]: On master: BEGIN
[0m09:58:43.577340 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m09:58:43.592586 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m09:58:43.593587 [debug] [MainThread]: On master: COMMIT
[0m09:58:43.593587 [debug] [MainThread]: Using postgres connection "master"
[0m09:58:43.593587 [debug] [MainThread]: On master: COMMIT
[0m09:58:43.594586 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m09:58:43.595586 [debug] [MainThread]: On master: Close
[0m09:58:43.596587 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:58:43.596587 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m09:58:43.597588 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m09:58:43.597588 [debug] [MainThread]: Connection 'test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f' was properly closed.
[0m09:58:43.597588 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e' was properly closed.
[0m09:58:43.598586 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m09:58:43.599468 [info ] [MainThread]: 
[0m09:58:43.599985 [info ] [MainThread]: Finished running 9 tests in 0 hours 0 minutes and 1.62 seconds (1.62s).
[0m09:58:43.602069 [debug] [MainThread]: Command end result
[0m09:58:43.612478 [info ] [MainThread]: 
[0m09:58:43.613481 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m09:58:43.614480 [info ] [MainThread]: 
[0m09:58:43.614480 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models\example\schema.yml)[0m
[0m09:58:43.615486 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m09:58:43.617382 [info ] [MainThread]: 
[0m09:58:43.621386 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\example\schema.yml\not_null_my_first_dbt_model_id.sql
[0m09:58:43.624384 [info ] [MainThread]: 
[0m09:58:43.625378 [error] [MainThread]: [31mFailure in test accepted_values_sales_order_header_status__1__2__3__4 (models\warehouse\sales_order_header.yml)[0m
[0m09:58:43.626407 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m09:58:43.627383 [info ] [MainThread]: 
[0m09:58:43.628384 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\warehouse\sales_order_header.yml\accepted_values_sales_order_header_status__1__2__3__4.sql
[0m09:58:43.629375 [info ] [MainThread]: 
[0m09:58:43.629375 [error] [MainThread]: [33mDatabase Error in test greater_than_column_sales_order_header_duedate__orderdate (models\warehouse\sales_order_header.yml)[0m
[0m09:58:43.630376 [error] [MainThread]:   syntax error at or near "GROUP"
[0m09:58:43.630376 [error] [MainThread]:   LINE 12: GROUP BY 1,2
[0m09:58:43.631375 [error] [MainThread]:            ^
[0m09:58:43.631375 [error] [MainThread]:   compiled Code at target\run\dbt_tutorial\models\warehouse\sales_order_header.yml\greater_than_column_sales_order_header_duedate__orderdate.sql
[0m09:58:43.632377 [info ] [MainThread]: 
[0m09:58:43.632377 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=3 SKIP=0 TOTAL=9
[0m09:58:43.633377 [debug] [MainThread]: Command `dbt test` failed at 09:58:43.633377 after 1.99 seconds
[0m09:58:43.633377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F59FC77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A20C7070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F5A273A350>]}
[0m09:58:43.634377 [debug] [MainThread]: Flushing usage events
[0m10:00:28.589996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A11D677640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A11FAD3280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A11FAD3130>]}


============================== 10:00:28.592994 | 6b4ae762-98d4-490b-b627-8254735e0e5e ==============================
[0m10:00:28.592994 [info ] [MainThread]: Running with dbt=1.5.11
[0m10:00:28.593995 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:00:28.665511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6b4ae762-98d4-490b-b627-8254735e0e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A11FAD33D0>]}
[0m10:00:28.685754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6b4ae762-98d4-490b-b627-8254735e0e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A11FC3CAC0>]}
[0m10:00:28.687757 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m10:00:28.699720 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m10:00:28.763129 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:00:28.764130 [debug] [MainThread]: Partial parsing: updated file: dbt_tutorial://tests\generic\test_greater_than_column.sql
[0m10:00:28.788421 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m10:00:28.869256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6b4ae762-98d4-490b-b627-8254735e0e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A1201180D0>]}
[0m10:00:28.878256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6b4ae762-98d4-490b-b627-8254735e0e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A12004FFA0>]}
[0m10:00:28.879256 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m10:00:28.880256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b4ae762-98d4-490b-b627-8254735e0e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A120095960>]}
[0m10:00:28.881361 [info ] [MainThread]: 
[0m10:00:28.882363 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:00:28.884448 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m10:00:28.895448 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:00:28.895448 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m10:00:28.895448 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:00:28.918747 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:00:28.918747 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:00:28.919748 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m10:00:28.922748 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m10:00:28.923747 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m10:00:28.924747 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m10:00:28.930396 [debug] [MainThread]: Using postgres connection "master"
[0m10:00:28.931052 [debug] [MainThread]: On master: BEGIN
[0m10:00:28.931052 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:00:28.948785 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:00:28.949313 [debug] [MainThread]: Using postgres connection "master"
[0m10:00:28.949853 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:00:29.254766 [debug] [MainThread]: SQL status: SELECT 147 in 0.0 seconds
[0m10:00:29.258845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b4ae762-98d4-490b-b627-8254735e0e5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A12004FFD0>]}
[0m10:00:29.259955 [debug] [MainThread]: On master: ROLLBACK
[0m10:00:29.261468 [debug] [MainThread]: Using postgres connection "master"
[0m10:00:29.261468 [debug] [MainThread]: On master: BEGIN
[0m10:00:29.264467 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.264467 [debug] [MainThread]: On master: COMMIT
[0m10:00:29.265466 [debug] [MainThread]: Using postgres connection "master"
[0m10:00:29.265466 [debug] [MainThread]: On master: COMMIT
[0m10:00:29.266507 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:00:29.267467 [debug] [MainThread]: On master: Close
[0m10:00:29.268467 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:00:29.268467 [info ] [MainThread]: 
[0m10:00:29.273605 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:00:29.274129 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:00:29.274652 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:00:29.275209 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:00:29.275209 [info ] [Thread-1 (]: 1 of 9 START test accepted_values_sales_order_header_status__1__2__3__4 ........ [RUN]
[0m10:00:29.276256 [info ] [Thread-2 (]: 2 of 9 START test greater_than_column_sales_order_header_duedate__orderdate .... [RUN]
[0m10:00:29.276780 [info ] [Thread-3 (]: 3 of 9 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m10:00:29.277308 [info ] [Thread-4 (]: 4 of 9 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m10:00:29.278351 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405'
[0m10:00:29.278872 [debug] [Thread-2 (]: Acquiring new postgres connection 'test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f'
[0m10:00:29.279909 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710'
[0m10:00:29.280429 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778'
[0m10:00:29.281063 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:00:29.281585 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:00:29.282097 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:00:29.282097 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:00:29.290188 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:00:29.294184 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:00:29.303244 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:00:29.307506 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:00:29.308555 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (compile): 10:00:29.282097 => 10:00:29.308555
[0m10:00:29.308555 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f (compile): 10:00:29.291186 => 10:00:29.308555
[0m10:00:29.308555 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:00:29.308555 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 10:00:29.295184 => 10:00:29.308555
[0m10:00:29.308555 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (compile): 10:00:29.304196 => 10:00:29.308555
[0m10:00:29.308555 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:00:29.321092 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:00:29.321092 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:00:29.326306 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:00:29.329342 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:00:29.332423 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:00:29.332423 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:00:29.334683 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:00:29.335650 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:00:29.336651 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: BEGIN
[0m10:00:29.336651 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:00:29.337668 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:00:29.338653 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: BEGIN
[0m10:00:29.338653 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:00:29.339623 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m10:00:29.340140 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m10:00:29.340140 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:00:29.341185 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:00:29.342146 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:00:29.358810 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.360322 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.360322 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:00:29.360322 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:00:29.360322 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m10:00:29.360322 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m10:00:29.360322 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:00:29.364334 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:00:29.365856 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (execute): 10:00:29.333535 => 10:00:29.365856
[0m10:00:29.365856 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.365856 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 10:00:29.330329 => 10:00:29.365856
[0m10:00:29.365856 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.365856 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m10:00:29.365856 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:00:29.365856 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m10:00:29.365856 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:00:29.365856 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

SELECT duedate, orderdate, count(1) as num_occurrences
FROM "Adventureworks"."warehouse"."sales_order_header"
WHERE duedate < 
GROUP BY duedate, orderdate


      
    ) dbt_internal_test
[0m10:00:29.365856 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: Close
[0m10:00:29.365856 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        status as value_field,
        count(*) as n_records

    from "Adventureworks"."warehouse"."sales_order_header"
    group by status

)

select *
from all_values
where value_field not in (
    '1','2','3','4'
)



      
    ) dbt_internal_test
[0m10:00:29.365856 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m10:00:29.365856 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near "GROUP"
LINE 12: GROUP BY duedate, orderdate
         ^

[0m10:00:29.365856 [info ] [Thread-4 (]: 4 of 9 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.09s]
[0m10:00:29.376878 [error] [Thread-3 (]: 3 of 9 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.10s]
[0m10:00:29.377933 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: ROLLBACK
[0m10:00:29.378975 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:00:29.379499 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:00:29.380538 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:00:29.381061 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f (execute): 10:00:29.326306 => 10:00:29.380538
[0m10:00:29.381664 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.test_due_date_before_order_date
[0m10:00:29.382183 [info ] [Thread-4 (]: 5 of 9 START test not_null_sales_order_header_row_id ........................... [RUN]
[0m10:00:29.382767 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: Close
[0m10:00:29.383289 [info ] [Thread-3 (]: 6 of 9 START test test_due_date_before_order_date .............................. [RUN]
[0m10:00:29.384327 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778, now test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438)
[0m10:00:29.385360 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:00:29.386392 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710, now test.dbt_tutorial.test_due_date_before_order_date)
[0m10:00:29.386945 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:00:29.389026 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (execute): 10:00:29.308555 => 10:00:29.388508
[0m10:00:29.389547 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.test_due_date_before_order_date
[0m10:00:29.393574 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:00:29.394575 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: ROLLBACK
[0m10:00:29.397643 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:00:29.399198 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (compile): 10:00:29.390067 => 10:00:29.398680
[0m10:00:29.399728 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: Close
[0m10:00:29.400767 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:00:29.401290 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.test_due_date_before_order_date (compile): 10:00:29.394575 => 10:00:29.400767
[0m10:00:29.402865 [error] [Thread-1 (]: 1 of 9 FAIL 1 accepted_values_sales_order_header_status__1__2__3__4 ............ [[31mFAIL 1[0m in 0.12s]
[0m10:00:29.403388 [debug] [Thread-2 (]: Database Error in test greater_than_column_sales_order_header_duedate__orderdate (models\warehouse\sales_order_header.yml)
  syntax error at or near "GROUP"
  LINE 12: GROUP BY duedate, orderdate
           ^
  compiled Code at target\run\dbt_tutorial\models\warehouse\sales_order_header.yml\greater_than_column_sales_order_header_duedate__orderdate.sql
[0m10:00:29.406069 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:00:29.406613 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.test_due_date_before_order_date
[0m10:00:29.408257 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:00:29.408994 [error] [Thread-2 (]: 2 of 9 ERROR greater_than_column_sales_order_header_duedate__orderdate ......... [[31mERROR[0m in 0.13s]
[0m10:00:29.411063 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:00:29.411580 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:00:29.412102 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:00:29.412622 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:00:29.413660 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: BEGIN
[0m10:00:29.414185 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:00:29.414706 [info ] [Thread-1 (]: 7 of 9 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m10:00:29.415226 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:00:29.415737 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:00:29.416254 [debug] [Thread-3 (]: On test.dbt_tutorial.test_due_date_before_order_date: BEGIN
[0m10:00:29.416254 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405, now test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321)
[0m10:00:29.417248 [info ] [Thread-2 (]: 8 of 9 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m10:00:29.418247 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:00:29.418247 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:00:29.419247 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f, now test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493)
[0m10:00:29.428246 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:00:29.429246 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:00:29.433340 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:00:29.434068 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (compile): 10:00:29.420250 => 10:00:29.433912
[0m10:00:29.434068 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:00:29.435069 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (compile): 10:00:29.429246 => 10:00:29.435069
[0m10:00:29.436073 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.436073 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.440069 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:00:29.441068 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:00:29.441068 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:00:29.442069 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:00:29.446069 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:00:29.447069 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select row_id
from "Adventureworks"."warehouse"."sales_order_header"
where row_id is null



      
    ) dbt_internal_test
[0m10:00:29.447069 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:00:29.448071 [debug] [Thread-3 (]: On test.dbt_tutorial.test_due_date_before_order_date: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.test_due_date_before_order_date"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT duedate, orderdate, count(1) as occurences
FROM "Adventureworks"."warehouse"."sales_order_header"
WHERE duedate < orderdate
GROUP BY duedate, orderdate
      
    ) dbt_internal_test
[0m10:00:29.449086 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:00:29.449086 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m10:00:29.450069 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m10:00:29.451069 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:00:29.451069 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:00:29.453068 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:00:29.454183 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:00:29.456777 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (execute): 10:00:29.403912 => 10:00:29.456777
[0m10:00:29.456777 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.test_due_date_before_order_date (execute): 10:00:29.409514 => 10:00:29.456777
[0m10:00:29.456777 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: ROLLBACK
[0m10:00:29.456777 [debug] [Thread-3 (]: On test.dbt_tutorial.test_due_date_before_order_date: ROLLBACK
[0m10:00:29.456777 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: Close
[0m10:00:29.456777 [debug] [Thread-3 (]: On test.dbt_tutorial.test_due_date_before_order_date: Close
[0m10:00:29.456777 [info ] [Thread-4 (]: 5 of 9 PASS not_null_sales_order_header_row_id ................................. [[32mPASS[0m in 0.07s]
[0m10:00:29.466081 [info ] [Thread-3 (]: 6 of 9 PASS test_due_date_before_order_date .................................... [[32mPASS[0m in 0.08s]
[0m10:00:29.469721 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:00:29.470249 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.test_due_date_before_order_date
[0m10:00:29.471339 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:00:29.472394 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.472394 [info ] [Thread-4 (]: 9 of 9 START test unique_sales_order_header_row_id ............................. [RUN]
[0m10:00:29.473437 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:00:29.473963 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438, now test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e)
[0m10:00:29.474890 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:00:29.475981 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:00:29.477054 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.481299 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:00:29.481815 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:00:29.482331 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:00:29.485119 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (execute): 10:00:29.437072 => 10:00:29.484616
[0m10:00:29.485781 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (compile): 10:00:29.477579 => 10:00:29.485781
[0m10:00:29.486310 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:00:29.486833 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m10:00:29.487861 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:00:29.490981 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:00:29.492982 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: Close
[0m10:00:29.492982 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:00:29.493980 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:00:29.494982 [info ] [Thread-1 (]: 7 of 9 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.08s]
[0m10:00:29.498382 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (execute): 10:00:29.443069 => 10:00:29.497827
[0m10:00:29.499951 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: BEGIN
[0m10:00:29.501222 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:00:29.501740 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m10:00:29.502257 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:00:29.504331 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m10:00:29.507742 [info ] [Thread-2 (]: 8 of 9 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.09s]
[0m10:00:29.509839 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:00:29.522908 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.523428 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:00:29.523947 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    row_id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."sales_order_header"
where row_id is not null
group by row_id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:00:29.538226 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:00:29.540223 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (execute): 10:00:29.488399 => 10:00:29.539224
[0m10:00:29.540223 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: ROLLBACK
[0m10:00:29.542225 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: Close
[0m10:00:29.543226 [info ] [Thread-4 (]: 9 of 9 PASS unique_sales_order_header_row_id ................................... [[32mPASS[0m in 0.07s]
[0m10:00:29.544224 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:00:29.546820 [debug] [MainThread]: Using postgres connection "master"
[0m10:00:29.547348 [debug] [MainThread]: On master: BEGIN
[0m10:00:29.547870 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:00:29.560382 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:00:29.561383 [debug] [MainThread]: On master: COMMIT
[0m10:00:29.561383 [debug] [MainThread]: Using postgres connection "master"
[0m10:00:29.562383 [debug] [MainThread]: On master: COMMIT
[0m10:00:29.563383 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:00:29.563383 [debug] [MainThread]: On master: Close
[0m10:00:29.564383 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:00:29.565383 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m10:00:29.565383 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m10:00:29.566385 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m10:00:29.566385 [debug] [MainThread]: Connection 'test.dbt_tutorial.test_due_date_before_order_date' was properly closed.
[0m10:00:29.567418 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e' was properly closed.
[0m10:00:29.567956 [info ] [MainThread]: 
[0m10:00:29.569000 [info ] [MainThread]: Finished running 9 tests in 0 hours 0 minutes and 0.69 seconds (0.69s).
[0m10:00:29.571067 [debug] [MainThread]: Command end result
[0m10:00:29.577270 [info ] [MainThread]: 
[0m10:00:29.578407 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m10:00:29.578921 [info ] [MainThread]: 
[0m10:00:29.579918 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models\example\schema.yml)[0m
[0m10:00:29.579918 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:00:29.580918 [info ] [MainThread]: 
[0m10:00:29.580918 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\example\schema.yml\not_null_my_first_dbt_model_id.sql
[0m10:00:29.582009 [info ] [MainThread]: 
[0m10:00:29.582232 [error] [MainThread]: [31mFailure in test accepted_values_sales_order_header_status__1__2__3__4 (models\warehouse\sales_order_header.yml)[0m
[0m10:00:29.582232 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:00:29.583282 [info ] [MainThread]: 
[0m10:00:29.583282 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\warehouse\sales_order_header.yml\accepted_values_sales_order_header_status__1__2__3__4.sql
[0m10:00:29.584283 [info ] [MainThread]: 
[0m10:00:29.584283 [error] [MainThread]: [33mDatabase Error in test greater_than_column_sales_order_header_duedate__orderdate (models\warehouse\sales_order_header.yml)[0m
[0m10:00:29.585282 [error] [MainThread]:   syntax error at or near "GROUP"
[0m10:00:29.585282 [error] [MainThread]:   LINE 12: GROUP BY duedate, orderdate
[0m10:00:29.586282 [error] [MainThread]:            ^
[0m10:00:29.587297 [error] [MainThread]:   compiled Code at target\run\dbt_tutorial\models\warehouse\sales_order_header.yml\greater_than_column_sales_order_header_duedate__orderdate.sql
[0m10:00:29.587297 [info ] [MainThread]: 
[0m10:00:29.588282 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=3 SKIP=0 TOTAL=9
[0m10:00:29.589290 [debug] [MainThread]: Command `dbt test` failed at 10:00:29.589290 after 1.01 seconds
[0m10:00:29.589290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A11D677640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A11FC04130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A1202136D0>]}
[0m10:00:29.590284 [debug] [MainThread]: Flushing usage events
[0m10:17:15.461033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A068E87640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06B3C7280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06B3C7130>]}


============================== 10:17:15.461033 | 301c63e0-9931-499a-8c28-ae1b228cf0cc ==============================
[0m10:17:15.461033 [info ] [MainThread]: Running with dbt=1.5.11
[0m10:17:15.461033 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:17:15.548738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '301c63e0-9931-499a-8c28-ae1b228cf0cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06B3C73D0>]}
[0m10:17:15.565976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '301c63e0-9931-499a-8c28-ae1b228cf0cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06B51CAC0>]}
[0m10:17:15.567974 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m10:17:15.579939 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m10:17:15.681254 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:17:15.682500 [debug] [MainThread]: Partial parsing: updated file: dbt_tutorial://tests\generic\test_greater_than_column.sql
[0m10:17:15.708431 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m10:17:15.783211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '301c63e0-9931-499a-8c28-ae1b228cf0cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06B9180D0>]}
[0m10:17:15.790213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '301c63e0-9931-499a-8c28-ae1b228cf0cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06B853FA0>]}
[0m10:17:15.791213 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m10:17:15.791213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '301c63e0-9931-499a-8c28-ae1b228cf0cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06B895960>]}
[0m10:17:15.793213 [info ] [MainThread]: 
[0m10:17:15.794213 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:17:15.796213 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m10:17:15.806306 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:17:15.806306 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m10:17:15.807310 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:17:15.851342 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:17:15.851342 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:17:15.852341 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m10:17:15.859491 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m10:17:15.860492 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m10:17:15.861491 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m10:17:15.867559 [debug] [MainThread]: Using postgres connection "master"
[0m10:17:15.868073 [debug] [MainThread]: On master: BEGIN
[0m10:17:15.868073 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:17:15.887540 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:17:15.887540 [debug] [MainThread]: Using postgres connection "master"
[0m10:17:15.888538 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:17:16.144499 [debug] [MainThread]: SQL status: SELECT 147 in 0.0 seconds
[0m10:17:16.148496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '301c63e0-9931-499a-8c28-ae1b228cf0cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06B853FD0>]}
[0m10:17:16.149496 [debug] [MainThread]: On master: ROLLBACK
[0m10:17:16.150497 [debug] [MainThread]: Using postgres connection "master"
[0m10:17:16.150497 [debug] [MainThread]: On master: BEGIN
[0m10:17:16.152498 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.152498 [debug] [MainThread]: On master: COMMIT
[0m10:17:16.153497 [debug] [MainThread]: Using postgres connection "master"
[0m10:17:16.153497 [debug] [MainThread]: On master: COMMIT
[0m10:17:16.154497 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:17:16.154497 [debug] [MainThread]: On master: Close
[0m10:17:16.155496 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:17:16.156500 [info ] [MainThread]: 
[0m10:17:16.165270 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:17:16.165794 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:17:16.166314 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:17:16.166835 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:17:16.167354 [info ] [Thread-1 (]: 1 of 9 START test accepted_values_sales_order_header_status__1__2__3__4 ........ [RUN]
[0m10:17:16.167874 [info ] [Thread-2 (]: 2 of 9 START test greater_than_column_sales_order_header_duedate__orderdate .... [RUN]
[0m10:17:16.168398 [info ] [Thread-3 (]: 3 of 9 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m10:17:16.169431 [info ] [Thread-4 (]: 4 of 9 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m10:17:16.170428 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405'
[0m10:17:16.170428 [debug] [Thread-2 (]: Acquiring new postgres connection 'test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f'
[0m10:17:16.171429 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710'
[0m10:17:16.172431 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778'
[0m10:17:16.172431 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:17:16.173429 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:17:16.173429 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:17:16.174430 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:17:16.183819 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:17:16.188821 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:17:16.198820 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:17:16.203821 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:17:16.206254 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (compile): 10:17:16.174430 => 10:17:16.204821
[0m10:17:16.207255 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f (compile): 10:17:16.184823 => 10:17:16.206254
[0m10:17:16.208247 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 10:17:16.189822 => 10:17:16.207255
[0m10:17:16.208247 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (compile): 10:17:16.199825 => 10:17:16.208247
[0m10:17:16.208247 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:17:16.209257 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:17:16.209257 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:17:16.209257 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:17:16.222661 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:17:16.225658 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:17:16.228662 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:17:16.231371 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:17:16.232361 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:17:16.233406 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:17:16.233406 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:17:16.233406 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: BEGIN
[0m10:17:16.233406 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:17:16.233406 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: BEGIN
[0m10:17:16.233406 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m10:17:16.233406 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:17:16.233406 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m10:17:16.233406 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:17:16.233406 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:17:16.238785 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:17:16.252950 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.253979 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:17:16.254621 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        status as value_field,
        count(*) as n_records

    from "Adventureworks"."warehouse"."sales_order_header"
    group by status

)

select *
from all_values
where value_field not in (
    '1','2','3','4'
)



      
    ) dbt_internal_test
[0m10:17:16.261668 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.262668 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:17:16.263669 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m10:17:16.264668 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.264668 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:17:16.265667 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m10:17:16.265667 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:17:16.268668 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 10:17:16.226699 => 10:17:16.268668
[0m10:17:16.268668 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:17:16.269670 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m10:17:16.271670 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (execute): 10:17:16.228662 => 10:17:16.271670
[0m10:17:16.272673 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m10:17:16.273668 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m10:17:16.273668 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.276670 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: Close
[0m10:17:16.275670 [error] [Thread-3 (]: 3 of 9 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.10s]
[0m10:17:16.277670 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:17:16.279494 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:17:16.280616 [info ] [Thread-4 (]: 4 of 9 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.11s]
[0m10:17:16.281884 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

SELECT duedate, orderdate, count(1) as num_occurrences
FROM "Adventureworks"."warehouse"."sales_order_header"
WHERE duedate < orderdate
GROUP BY duedate, orderdate


      
    ) dbt_internal_test
[0m10:17:16.282998 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:17:16.284250 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:17:16.284774 [info ] [Thread-3 (]: 5 of 9 START test not_null_sales_order_header_row_id ........................... [RUN]
[0m10:17:16.287035 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.test_due_date_before_order_date
[0m10:17:16.288673 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710, now test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438)
[0m10:17:16.289205 [info ] [Thread-4 (]: 6 of 9 START test test_due_date_before_order_date .............................. [RUN]
[0m10:17:16.290261 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:17:16.291304 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778, now test.dbt_tutorial.test_due_date_before_order_date)
[0m10:17:16.297962 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:17:16.298962 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.test_due_date_before_order_date
[0m10:17:16.306068 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:17:16.307173 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:17:16.307699 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:17:16.308262 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (compile): 10:17:16.291833 => 10:17:16.308262
[0m10:17:16.312064 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f (execute): 10:17:16.222661 => 10:17:16.311548
[0m10:17:16.317462 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (execute): 10:17:16.209257 => 10:17:16.316683
[0m10:17:16.319623 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.test_due_date_before_order_date (compile): 10:17:16.299959 => 10:17:16.319076
[0m10:17:16.321431 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:17:16.322582 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: ROLLBACK
[0m10:17:16.323167 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: ROLLBACK
[0m10:17:16.324226 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.test_due_date_before_order_date
[0m10:17:16.327725 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:17:16.334190 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:17:16.334736 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: Close
[0m10:17:16.335282 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: Close
[0m10:17:16.336351 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:17:16.337402 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:17:16.338475 [error] [Thread-1 (]: 1 of 9 FAIL 1 accepted_values_sales_order_header_status__1__2__3__4 ............ [[31mFAIL 1[0m in 0.17s]
[0m10:17:16.340085 [info ] [Thread-2 (]: 2 of 9 PASS greater_than_column_sales_order_header_duedate__orderdate .......... [[32mPASS[0m in 0.17s]
[0m10:17:16.341133 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: BEGIN
[0m10:17:16.342181 [debug] [Thread-4 (]: On test.dbt_tutorial.test_due_date_before_order_date: BEGIN
[0m10:17:16.343235 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:17:16.343758 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:17:16.344280 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:17:16.344804 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:17:16.345328 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:17:16.345852 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:17:16.347703 [info ] [Thread-1 (]: 7 of 9 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m10:17:16.349387 [info ] [Thread-2 (]: 8 of 9 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m10:17:16.350439 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405, now test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321)
[0m10:17:16.351431 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f, now test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493)
[0m10:17:16.351431 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:17:16.353094 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:17:16.363750 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:17:16.371165 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:17:16.372235 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.373825 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (compile): 10:17:16.354169 => 10:17:16.373300
[0m10:17:16.374351 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.374868 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:17:16.375901 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (compile): 10:17:16.365371 => 10:17:16.375396
[0m10:17:16.375920 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:17:16.377030 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:17:16.377558 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select row_id
from "Adventureworks"."warehouse"."sales_order_header"
where row_id is null



      
    ) dbt_internal_test
[0m10:17:16.378630 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:17:16.382356 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:17:16.382941 [debug] [Thread-4 (]: On test.dbt_tutorial.test_due_date_before_order_date: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.test_due_date_before_order_date"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT duedate, orderdate, count(1) as occurences
FROM "Adventureworks"."warehouse"."sales_order_header"
WHERE duedate < orderdate
GROUP BY duedate, orderdate
      
    ) dbt_internal_test
[0m10:17:16.385557 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:17:16.387169 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:17:16.387687 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m10:17:16.388688 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:17:16.389696 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:17:16.389696 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:17:16.390696 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m10:17:16.392690 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (execute): 10:17:16.324755 => 10:17:16.392690
[0m10:17:16.393690 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:17:16.393690 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:17:16.394687 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: ROLLBACK
[0m10:17:16.396686 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.test_due_date_before_order_date (execute): 10:17:16.328799 => 10:17:16.396686
[0m10:17:16.397685 [debug] [Thread-4 (]: On test.dbt_tutorial.test_due_date_before_order_date: ROLLBACK
[0m10:17:16.397685 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: Close
[0m10:17:16.399685 [debug] [Thread-4 (]: On test.dbt_tutorial.test_due_date_before_order_date: Close
[0m10:17:16.399685 [info ] [Thread-3 (]: 5 of 9 PASS not_null_sales_order_header_row_id ................................. [[32mPASS[0m in 0.11s]
[0m10:17:16.401685 [info ] [Thread-4 (]: 6 of 9 PASS test_due_date_before_order_date .................................... [[32mPASS[0m in 0.11s]
[0m10:17:16.402685 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:17:16.402685 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.test_due_date_before_order_date
[0m10:17:16.403686 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:17:16.404686 [info ] [Thread-3 (]: 9 of 9 START test unique_sales_order_header_row_id ............................. [RUN]
[0m10:17:16.405687 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438, now test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e)
[0m10:17:16.405687 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:17:16.411058 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:17:16.411586 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.412663 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:17:16.413729 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:17:16.414258 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (compile): 10:17:16.405687 => 10:17:16.413729
[0m10:17:16.414784 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.415297 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:17:16.415297 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:17:16.415297 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:17:16.415297 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:17:16.415297 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:17:16.421320 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (execute): 10:17:16.379146 => 10:17:16.415297
[0m10:17:16.421320 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:17:16.421320 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m10:17:16.421320 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: BEGIN
[0m10:17:16.421320 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:17:16.421320 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:17:16.421320 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: Close
[0m10:17:16.425895 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (execute): 10:17:16.383464 => 10:17:16.421320
[0m10:17:16.428780 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m10:17:16.429777 [info ] [Thread-1 (]: 7 of 9 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.08s]
[0m10:17:16.430776 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:17:16.430776 [debug] [Thread-2 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m10:17:16.433068 [info ] [Thread-2 (]: 8 of 9 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.08s]
[0m10:17:16.434128 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:17:16.451451 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.452451 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:17:16.452451 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    row_id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."sales_order_header"
where row_id is not null
group by row_id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:17:16.473875 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:17:16.475867 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (execute): 10:17:16.415297 => 10:17:16.474839
[0m10:17:16.475867 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: ROLLBACK
[0m10:17:16.476867 [debug] [Thread-3 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: Close
[0m10:17:16.478853 [info ] [Thread-3 (]: 9 of 9 PASS unique_sales_order_header_row_id ................................... [[32mPASS[0m in 0.07s]
[0m10:17:16.479842 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:17:16.481781 [debug] [MainThread]: Using postgres connection "master"
[0m10:17:16.482301 [debug] [MainThread]: On master: BEGIN
[0m10:17:16.482301 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:17:16.492736 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:17:16.492736 [debug] [MainThread]: On master: COMMIT
[0m10:17:16.492736 [debug] [MainThread]: Using postgres connection "master"
[0m10:17:16.492736 [debug] [MainThread]: On master: COMMIT
[0m10:17:16.492736 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:17:16.492736 [debug] [MainThread]: On master: Close
[0m10:17:16.492736 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:17:16.501616 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m10:17:16.501616 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m10:17:16.501616 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
[0m10:17:16.502622 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e' was properly closed.
[0m10:17:16.503290 [debug] [MainThread]: Connection 'test.dbt_tutorial.test_due_date_before_order_date' was properly closed.
[0m10:17:16.503814 [info ] [MainThread]: 
[0m10:17:16.504336 [info ] [MainThread]: Finished running 9 tests in 0 hours 0 minutes and 0.71 seconds (0.71s).
[0m10:17:16.506504 [debug] [MainThread]: Command end result
[0m10:17:16.514862 [info ] [MainThread]: 
[0m10:17:16.514862 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m10:17:16.514862 [info ] [MainThread]: 
[0m10:17:16.514862 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models\example\schema.yml)[0m
[0m10:17:16.514862 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:17:16.514862 [info ] [MainThread]: 
[0m10:17:16.514862 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\example\schema.yml\not_null_my_first_dbt_model_id.sql
[0m10:17:16.514862 [info ] [MainThread]: 
[0m10:17:16.514862 [error] [MainThread]: [31mFailure in test accepted_values_sales_order_header_status__1__2__3__4 (models\warehouse\sales_order_header.yml)[0m
[0m10:17:16.521430 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:17:16.521840 [info ] [MainThread]: 
[0m10:17:16.521840 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\warehouse\sales_order_header.yml\accepted_values_sales_order_header_status__1__2__3__4.sql
[0m10:17:16.522845 [info ] [MainThread]: 
[0m10:17:16.523844 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=2 SKIP=0 TOTAL=9
[0m10:17:16.524845 [debug] [MainThread]: Command `dbt test` failed at 10:17:16.524845 after 1.08 seconds
[0m10:17:16.524845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A068E87640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06BC0F550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A06B3C73D0>]}
[0m10:17:16.525845 [debug] [MainThread]: Flushing usage events
[0m10:21:29.858500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070A477640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070C8C31F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070C8C30A0>]}


============================== 10:21:29.866630 | b9724f22-157e-4ed1-991d-33377e51f6b5 ==============================
[0m10:21:29.866630 [info ] [MainThread]: Running with dbt=1.5.11
[0m10:21:29.866630 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:21:29.936461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b9724f22-157e-4ed1-991d-33377e51f6b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070C8C3340>]}
[0m10:21:29.962596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b9724f22-157e-4ed1-991d-33377e51f6b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070CC1CA30>]}
[0m10:21:29.963594 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m10:21:29.974595 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m10:21:30.069560 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:21:30.069560 [debug] [MainThread]: Partial parsing: updated file: dbt_tutorial://tests\generic\test_greater_than_column.sql
[0m10:21:30.094767 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m10:21:30.169904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b9724f22-157e-4ed1-991d-33377e51f6b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070CE180D0>]}
[0m10:21:30.176904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b9724f22-157e-4ed1-991d-33377e51f6b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070CD4FF40>]}
[0m10:21:30.177872 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m10:21:30.178871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9724f22-157e-4ed1-991d-33377e51f6b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070CD958D0>]}
[0m10:21:30.179871 [info ] [MainThread]: 
[0m10:21:30.181019 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:21:30.183153 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m10:21:30.194189 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:21:30.195183 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m10:21:30.195183 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:21:30.230100 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.231188 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:21:30.231188 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m10:21:30.234296 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m10:21:30.235297 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m10:21:30.236305 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m10:21:30.242849 [debug] [MainThread]: Using postgres connection "master"
[0m10:21:30.243378 [debug] [MainThread]: On master: BEGIN
[0m10:21:30.243378 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:21:30.281419 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.281480 [debug] [MainThread]: Using postgres connection "master"
[0m10:21:30.282481 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:21:30.453688 [debug] [MainThread]: SQL status: SELECT 147 in 0.0 seconds
[0m10:21:30.457687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9724f22-157e-4ed1-991d-33377e51f6b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070CD4FFD0>]}
[0m10:21:30.458797 [debug] [MainThread]: On master: ROLLBACK
[0m10:21:30.459798 [debug] [MainThread]: Using postgres connection "master"
[0m10:21:30.459798 [debug] [MainThread]: On master: BEGIN
[0m10:21:30.460799 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.461799 [debug] [MainThread]: On master: COMMIT
[0m10:21:30.461799 [debug] [MainThread]: Using postgres connection "master"
[0m10:21:30.461799 [debug] [MainThread]: On master: COMMIT
[0m10:21:30.462799 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:21:30.463799 [debug] [MainThread]: On master: Close
[0m10:21:30.464802 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:21:30.464802 [info ] [MainThread]: 
[0m10:21:30.472475 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:21:30.472998 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:21:30.472998 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:21:30.473518 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:21:30.474041 [info ] [Thread-1 (]: 1 of 9 START test accepted_values_sales_order_header_status__1__2__3__4 ........ [RUN]
[0m10:21:30.475089 [info ] [Thread-2 (]: 2 of 9 START test greater_than_column_sales_order_header_duedate__orderdate .... [RUN]
[0m10:21:30.475611 [info ] [Thread-3 (]: 3 of 9 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m10:21:30.476124 [info ] [Thread-4 (]: 4 of 9 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m10:21:30.477163 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405'
[0m10:21:30.477683 [debug] [Thread-2 (]: Acquiring new postgres connection 'test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f'
[0m10:21:30.478714 [debug] [Thread-3 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710'
[0m10:21:30.478714 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778'
[0m10:21:30.479713 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:21:30.479713 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:21:30.480713 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:21:30.480713 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:21:30.489898 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:21:30.494897 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:21:30.506004 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:21:30.508540 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:21:30.508540 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (compile): 10:21:30.481740 => 10:21:30.508540
[0m10:21:30.508540 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f (compile): 10:21:30.490896 => 10:21:30.508540
[0m10:21:30.508540 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 10:21:30.494897 => 10:21:30.508540
[0m10:21:30.508540 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:21:30.508540 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (compile): 10:21:30.506530 => 10:21:30.508540
[0m10:21:30.508540 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:21:30.508540 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:21:30.528835 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:21:30.529835 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:21:30.533038 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:21:30.535039 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:21:30.537963 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:21:30.537963 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:21:30.538961 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:21:30.539962 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:21:30.539962 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: BEGIN
[0m10:21:30.540962 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:21:30.540962 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: BEGIN
[0m10:21:30.541963 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m10:21:30.541963 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:21:30.542962 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: BEGIN
[0m10:21:30.542962 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:21:30.543960 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:21:30.543960 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:21:30.558112 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.559116 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"
[0m10:21:30.559116 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        status as value_field,
        count(*) as n_records

    from "Adventureworks"."warehouse"."sales_order_header"
    group by status

)

select *
from all_values
where value_field not in (
    '1','2','3','4'
)



      
    ) dbt_internal_test
[0m10:21:30.561114 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.561114 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.562114 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"
[0m10:21:30.562114 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"
[0m10:21:30.563116 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.563116 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      

SELECT duedate, orderdate, count(1) as num_occurrences
FROM "Adventureworks"."warehouse"."sales_order_header"
WHERE duedate < orderdate
GROUP BY 1, 2


      
    ) dbt_internal_test
[0m10:21:30.564113 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m10:21:30.564113 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"
[0m10:21:30.565113 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m10:21:30.565113 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:21:30.568115 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 10:21:30.533038 => 10:21:30.568115
[0m10:21:30.569114 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:21:30.569114 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:21:30.570114 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:21:30.570114 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m10:21:30.572112 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778 (execute): 10:21:30.536038 => 10:21:30.571114
[0m10:21:30.573112 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f (execute): 10:21:30.529835 => 10:21:30.573112
[0m10:21:30.574113 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405 (execute): 10:21:30.508540 => 10:21:30.574113
[0m10:21:30.575113 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
[0m10:21:30.575113 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: ROLLBACK
[0m10:21:30.576114 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m10:21:30.576114 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: ROLLBACK
[0m10:21:30.578113 [debug] [Thread-2 (]: On test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f: Close
[0m10:21:30.578113 [debug] [Thread-4 (]: On test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778: Close
[0m10:21:30.578113 [error] [Thread-3 (]: 3 of 9 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.10s]
[0m10:21:30.580654 [debug] [Thread-1 (]: On test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405: Close
[0m10:21:30.580115 [info ] [Thread-2 (]: 2 of 9 PASS greater_than_column_sales_order_header_duedate__orderdate .......... [[32mPASS[0m in 0.10s]
[0m10:21:30.582011 [info ] [Thread-4 (]: 4 of 9 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.10s]
[0m10:21:30.583709 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710
[0m10:21:30.585801 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f
[0m10:21:30.584760 [error] [Thread-1 (]: 1 of 9 FAIL 1 accepted_values_sales_order_header_status__1__2__3__4 ............ [[31mFAIL 1[0m in 0.11s]
[0m10:21:30.586836 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778
[0m10:21:30.587907 [debug] [Thread-3 (]: Began running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:21:30.588432 [debug] [Thread-2 (]: Began running node test.dbt_tutorial.test_due_date_before_order_date
[0m10:21:30.589473 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405
[0m10:21:30.589994 [debug] [Thread-4 (]: Began running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:21:30.590514 [info ] [Thread-3 (]: 5 of 9 START test not_null_sales_order_header_row_id ........................... [RUN]
[0m10:21:30.591033 [info ] [Thread-2 (]: 6 of 9 START test test_due_date_before_order_date .............................. [RUN]
[0m10:21:30.591551 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:21:30.592072 [info ] [Thread-4 (]: 7 of 9 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m10:21:30.592591 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_first_dbt_model_id.5fb22c2710, now test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438)
[0m10:21:30.593631 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.greater_than_column_sales_order_header_duedate__orderdate.2d27c1e37f, now test.dbt_tutorial.test_due_date_before_order_date)
[0m10:21:30.594163 [info ] [Thread-1 (]: 8 of 9 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m10:21:30.595200 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.not_null_my_second_dbt_model_id.151b76d778, now test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321)
[0m10:21:30.595718 [debug] [Thread-3 (]: Began compiling node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:21:30.596227 [debug] [Thread-2 (]: Began compiling node test.dbt_tutorial.test_due_date_before_order_date
[0m10:21:30.596745 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.accepted_values_sales_order_header_status__1__2__3__4.d21bbba405, now test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493)
[0m10:21:30.597313 [debug] [Thread-4 (]: Began compiling node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:21:30.600864 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:21:30.603863 [debug] [Thread-2 (]: Writing injected SQL for node "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:21:30.603863 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:21:30.611613 [debug] [Thread-4 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:21:30.611613 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (compile): 10:21:30.597313 => 10:21:30.611613
[0m10:21:30.617182 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.test_due_date_before_order_date (compile): 10:21:30.601863 => 10:21:30.616960
[0m10:21:30.618200 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:21:30.619197 [debug] [Thread-3 (]: Began executing node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:21:30.620195 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (compile): 10:21:30.604864 => 10:21:30.619197
[0m10:21:30.620195 [debug] [Thread-2 (]: Began executing node test.dbt_tutorial.test_due_date_before_order_date
[0m10:21:30.623196 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:21:30.624182 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (compile): 10:21:30.611613 => 10:21:30.624182
[0m10:21:30.625184 [debug] [Thread-4 (]: Began executing node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:21:30.628182 [debug] [Thread-2 (]: Writing runtime sql for node "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:21:30.629184 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:21:30.630183 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:21:30.633526 [debug] [Thread-4 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:21:30.636137 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:21:30.636137 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:21:30.637103 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: BEGIN
[0m10:21:30.638113 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:21:30.639102 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:21:30.639102 [debug] [Thread-2 (]: On test.dbt_tutorial.test_due_date_before_order_date: BEGIN
[0m10:21:30.639102 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m10:21:30.640104 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m10:21:30.640104 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
[0m10:21:30.641104 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m10:21:30.641881 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m10:21:30.642886 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:21:30.657477 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.658665 [debug] [Thread-2 (]: Using postgres connection "test.dbt_tutorial.test_due_date_before_order_date"
[0m10:21:30.658665 [debug] [Thread-2 (]: On test.dbt_tutorial.test_due_date_before_order_date: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.test_due_date_before_order_date"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      SELECT duedate, orderdate, count(1) as occurences
FROM "Adventureworks"."warehouse"."sales_order_header"
WHERE duedate < orderdate
GROUP BY duedate, orderdate
      
    ) dbt_internal_test
[0m10:21:30.658665 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.659666 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.659666 [debug] [Thread-4 (]: Using postgres connection "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"
[0m10:21:30.660666 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"
[0m10:21:30.660666 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:21:30.661666 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:21:30.662666 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:21:30.663666 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:21:30.663666 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:21:30.665666 [debug] [Thread-4 (]: Timing info for test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321 (execute): 10:21:30.630183 => 10:21:30.664666
[0m10:21:30.666664 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493 (execute): 10:21:30.634098 => 10:21:30.666664
[0m10:21:30.667664 [debug] [Thread-2 (]: Timing info for test.dbt_tutorial.test_due_date_before_order_date (execute): 10:21:30.625184 => 10:21:30.667664
[0m10:21:30.668664 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m10:21:30.668664 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
[0m10:21:30.669664 [debug] [Thread-2 (]: On test.dbt_tutorial.test_due_date_before_order_date: ROLLBACK
[0m10:21:30.670664 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m10:21:30.670664 [debug] [Thread-4 (]: On test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321: Close
[0m10:21:30.671664 [debug] [Thread-2 (]: On test.dbt_tutorial.test_due_date_before_order_date: Close
[0m10:21:30.672669 [info ] [Thread-1 (]: 8 of 9 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.08s]
[0m10:21:30.673669 [info ] [Thread-4 (]: 7 of 9 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.08s]
[0m10:21:30.675856 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.675339 [info ] [Thread-2 (]: 6 of 9 PASS test_due_date_before_order_date .................................... [[32mPASS[0m in 0.08s]
[0m10:21:30.676911 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493
[0m10:21:30.677953 [debug] [Thread-4 (]: Finished running node test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321
[0m10:21:30.678513 [debug] [Thread-3 (]: Using postgres connection "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"
[0m10:21:30.679037 [debug] [Thread-2 (]: Finished running node test.dbt_tutorial.test_due_date_before_order_date
[0m10:21:30.679557 [debug] [Thread-1 (]: Began running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:21:30.680601 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select row_id
from "Adventureworks"."warehouse"."sales_order_header"
where row_id is null



      
    ) dbt_internal_test
[0m10:21:30.681225 [info ] [Thread-1 (]: 9 of 9 START test unique_sales_order_header_row_id ............................. [RUN]
[0m10:21:30.682803 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_tutorial.unique_my_second_dbt_model_id.57a0f8c493, now test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e)
[0m10:21:30.683603 [debug] [Thread-1 (]: Began compiling node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:21:30.688805 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:21:30.688805 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:21:30.689805 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (compile): 10:21:30.684135 => 10:21:30.689805
[0m10:21:30.691806 [debug] [Thread-3 (]: Timing info for test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438 (execute): 10:21:30.621182 => 10:21:30.691806
[0m10:21:30.692805 [debug] [Thread-1 (]: Began executing node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:21:30.692805 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: ROLLBACK
[0m10:21:30.695803 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:21:30.696693 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:21:30.696693 [debug] [Thread-3 (]: On test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438: Close
[0m10:21:30.697687 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: BEGIN
[0m10:21:30.698699 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:21:30.699690 [info ] [Thread-3 (]: 5 of 9 PASS not_null_sales_order_header_row_id ................................. [[32mPASS[0m in 0.11s]
[0m10:21:30.700688 [debug] [Thread-3 (]: Finished running node test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438
[0m10:21:30.716012 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.717051 [debug] [Thread-1 (]: Using postgres connection "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"
[0m10:21:30.717562 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    row_id as unique_field,
    count(*) as n_records

from "Adventureworks"."warehouse"."sales_order_header"
where row_id is not null
group by row_id
having count(*) > 1



      
    ) dbt_internal_test
[0m10:21:30.749356 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m10:21:30.750357 [debug] [Thread-1 (]: Timing info for test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e (execute): 10:21:30.693804 => 10:21:30.750357
[0m10:21:30.751357 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: ROLLBACK
[0m10:21:30.753357 [debug] [Thread-1 (]: On test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e: Close
[0m10:21:30.754356 [info ] [Thread-1 (]: 9 of 9 PASS unique_sales_order_header_row_id ................................... [[32mPASS[0m in 0.07s]
[0m10:21:30.756373 [debug] [Thread-1 (]: Finished running node test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e
[0m10:21:30.760171 [debug] [MainThread]: Using postgres connection "master"
[0m10:21:30.760690 [debug] [MainThread]: On master: BEGIN
[0m10:21:30.761206 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:21:30.778165 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:21:30.778165 [debug] [MainThread]: On master: COMMIT
[0m10:21:30.779156 [debug] [MainThread]: Using postgres connection "master"
[0m10:21:30.779156 [debug] [MainThread]: On master: COMMIT
[0m10:21:30.780155 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:21:30.780155 [debug] [MainThread]: On master: Close
[0m10:21:30.781244 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:21:30.782251 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m10:21:30.783470 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_sales_order_header_row_id.71dca2b08e' was properly closed.
[0m10:21:30.783739 [debug] [MainThread]: Connection 'test.dbt_tutorial.test_due_date_before_order_date' was properly closed.
[0m10:21:30.783739 [debug] [MainThread]: Connection 'test.dbt_tutorial.not_null_sales_order_header_row_id.4bffe69438' was properly closed.
[0m10:21:30.784740 [debug] [MainThread]: Connection 'test.dbt_tutorial.unique_my_first_dbt_model_id.16e066b321' was properly closed.
[0m10:21:30.785021 [info ] [MainThread]: 
[0m10:21:30.785542 [info ] [MainThread]: Finished running 9 tests in 0 hours 0 minutes and 0.60 seconds (0.60s).
[0m10:21:30.787608 [debug] [MainThread]: Command end result
[0m10:21:30.797357 [info ] [MainThread]: 
[0m10:21:30.798354 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m10:21:30.798354 [info ] [MainThread]: 
[0m10:21:30.799355 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models\example\schema.yml)[0m
[0m10:21:30.800354 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:21:30.800354 [info ] [MainThread]: 
[0m10:21:30.801354 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\example\schema.yml\not_null_my_first_dbt_model_id.sql
[0m10:21:30.801354 [info ] [MainThread]: 
[0m10:21:30.802354 [error] [MainThread]: [31mFailure in test accepted_values_sales_order_header_status__1__2__3__4 (models\warehouse\sales_order_header.yml)[0m
[0m10:21:30.803354 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m10:21:30.803354 [info ] [MainThread]: 
[0m10:21:30.804355 [info ] [MainThread]:   compiled Code at target\compiled\dbt_tutorial\models\warehouse\sales_order_header.yml\accepted_values_sales_order_header_status__1__2__3__4.sql
[0m10:21:30.804355 [info ] [MainThread]: 
[0m10:21:30.805355 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=2 SKIP=0 TOTAL=9
[0m10:21:30.806981 [debug] [MainThread]: Command `dbt test` failed at 10:21:30.806981 after 0.96 seconds
[0m10:21:30.808051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070A477640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070C9E01C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002070C8C3340>]}
[0m10:21:30.808051 [debug] [MainThread]: Flushing usage events
[0m10:53:42.190924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D2877640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D4CC7250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D4CC7100>]}


============================== 10:53:42.195869 | 0d9d8245-ee96-4e87-bfbd-5bdf39b5adad ==============================
[0m10:53:42.195869 [info ] [MainThread]: Running with dbt=1.5.11
[0m10:53:42.196869 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m10:53:42.279814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D4CC79A0>]}
[0m10:53:42.299995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D501CA60>]}
[0m10:53:42.301018 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m10:53:42.313759 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m10:53:42.388023 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m10:53:42.388023 [debug] [MainThread]: Partial parsing: added file: dbt_tutorial://models\warehouse\sales_oder_detail.yml
[0m10:53:42.389024 [debug] [MainThread]: Partial parsing: added file: dbt_tutorial://models\warehouse\sales_order_detail.sql
[0m10:53:42.414876 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_detail.sql
[0m10:53:42.477466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D525E170>]}
[0m10:53:42.485430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D514BEE0>]}
[0m10:53:42.485430 [info ] [MainThread]: Found 4 models, 11 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m10:53:42.486945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D514BFA0>]}
[0m10:53:42.488807 [info ] [MainThread]: 
[0m10:53:42.489807 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m10:53:42.491807 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m10:53:42.501176 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m10:53:42.502180 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m10:53:42.502180 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:42.609824 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m10:53:42.610823 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m10:53:42.613198 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m10:53:42.619271 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:53:42.620273 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m10:53:42.620273 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:53:42.645718 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m10:53:42.646233 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m10:53:42.646448 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m10:53:42.657808 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.0 seconds
[0m10:53:42.658807 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m10:53:42.660494 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m10:53:42.664970 [debug] [MainThread]: Using postgres connection "master"
[0m10:53:42.665970 [debug] [MainThread]: On master: BEGIN
[0m10:53:42.665970 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:53:42.684175 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:53:42.684689 [debug] [MainThread]: Using postgres connection "master"
[0m10:53:42.685206 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m10:53:43.233096 [debug] [MainThread]: SQL status: SELECT 147 in 1.0 seconds
[0m10:53:43.237222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D5260BE0>]}
[0m10:53:43.238223 [debug] [MainThread]: On master: ROLLBACK
[0m10:53:43.239223 [debug] [MainThread]: Using postgres connection "master"
[0m10:53:43.239223 [debug] [MainThread]: On master: BEGIN
[0m10:53:43.241228 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:53:43.241228 [debug] [MainThread]: On master: COMMIT
[0m10:53:43.242222 [debug] [MainThread]: Using postgres connection "master"
[0m10:53:43.242222 [debug] [MainThread]: On master: COMMIT
[0m10:53:43.243672 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:53:43.244222 [debug] [MainThread]: On master: Close
[0m10:53:43.245223 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m10:53:43.245223 [info ] [MainThread]: 
[0m10:53:43.252889 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.my_first_dbt_model
[0m10:53:43.253409 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_detail
[0m10:53:43.253409 [debug] [Thread-3 (]: Began running node model.dbt_tutorial.sales_order_header
[0m10:53:43.253927 [info ] [Thread-1 (]: 1 of 4 START sql table model warehouse.my_first_dbt_model ...................... [RUN]
[0m10:53:43.254955 [info ] [Thread-2 (]: 2 of 4 START sql table model warehouse.sales_order_detail ...................... [RUN]
[0m10:53:43.255476 [info ] [Thread-3 (]: 3 of 4 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m10:53:43.256515 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.my_first_dbt_model'
[0m10:53:43.257032 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_detail'
[0m10:53:43.258118 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m10:53:43.258715 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.my_first_dbt_model
[0m10:53:43.258715 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_detail
[0m10:53:43.258715 [debug] [Thread-3 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m10:53:43.267130 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.my_first_dbt_model"
[0m10:53:43.269132 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_detail"
[0m10:53:43.272178 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m10:53:43.273179 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (compile): 10:53:43.259721 => 10:53:43.273179
[0m10:53:43.274180 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (compile): 10:53:43.267130 => 10:53:43.274180
[0m10:53:43.274180 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.my_first_dbt_model
[0m10:53:43.275179 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 10:53:43.270130 => 10:53:43.275179
[0m10:53:43.275179 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_detail
[0m10:53:43.299228 [debug] [Thread-3 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m10:53:43.312565 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_tutorial.my_first_dbt_model"
[0m10:53:43.317519 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_detail"
[0m10:53:43.320611 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m10:53:43.322612 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:53:43.322612 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m10:53:43.323612 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: BEGIN
[0m10:53:43.323612 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:53:43.324612 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: BEGIN
[0m10:53:43.324612 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:53:43.325611 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m10:53:43.325611 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m10:53:43.327077 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:53:43.352385 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m10:53:43.352385 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m10:53:43.353384 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:53:43.353384 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m10:53:43.354383 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m10:53:43.354812 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */

  
    

  create  table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m10:53:43.355354 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid
    ,salesorderdetailid
    ,carriertrackingnumber
    ,orderqty
    ,productid
    ,specialofferid
    ,unitprice
    ,unitpricediscount
    ,rowguid as row_id
    ,modifieddate
FROM "Adventureworks"."sales"."salesorderdetail"
  );
  
[0m10:53:43.355354 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:53:43.356355 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m10:53:43.391974 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m10:53:43.398106 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:53:43.399105 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m10:53:43.404129 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:53:43.407130 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:53:43.407130 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m10:53:43.408131 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:53:43.435265 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:53:43.436265 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */

    
  
  comment on table "Adventureworks"."warehouse"."my_first_dbt_model" is $dbt_comment_literal_block$A starter dbt model$dbt_comment_literal_block$;

  
[0m10:53:43.445600 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m10:53:43.446601 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m10:53:43.446601 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:53:43.447602 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m10:53:43.492030 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m10:53:43.497345 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m10:53:43.498343 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
drop table if exists "Adventureworks"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m10:53:43.551795 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m10:53:43.553795 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (execute): 10:53:43.276180 => 10:53:43.553795
[0m10:53:43.554795 [debug] [Thread-1 (]: On model.dbt_tutorial.my_first_dbt_model: Close
[0m10:53:43.555797 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D53030A0>]}
[0m10:53:43.556885 [info ] [Thread-1 (]: 1 of 4 OK created sql table model warehouse.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.30s]
[0m10:53:43.556885 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.my_first_dbt_model
[0m10:53:43.557885 [debug] [Thread-4 (]: Began running node model.dbt_tutorial.my_second_dbt_model
[0m10:53:43.558886 [info ] [Thread-4 (]: 4 of 4 START sql view model warehouse.my_second_dbt_model ...................... [RUN]
[0m10:53:43.559886 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_tutorial.my_second_dbt_model'
[0m10:53:43.559886 [debug] [Thread-4 (]: Began compiling node model.dbt_tutorial.my_second_dbt_model
[0m10:53:43.564299 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_tutorial.my_second_dbt_model"
[0m10:53:43.565655 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (compile): 10:53:43.560884 => 10:53:43.565133
[0m10:53:43.566183 [debug] [Thread-4 (]: Began executing node model.dbt_tutorial.my_second_dbt_model
[0m10:53:43.590134 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_tutorial.my_second_dbt_model"
[0m10:53:43.591161 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:53:43.592423 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: BEGIN
[0m10:53:43.592423 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m10:53:43.609789 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m10:53:43.610787 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:53:43.611721 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */

  create view "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m10:53:43.615413 [debug] [Thread-4 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m10:53:43.619243 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:53:43.619252 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m10:53:43.621254 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:53:43.622253 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:53:43.623254 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */

    
  
  comment on view "Adventureworks"."warehouse"."my_second_dbt_model" is $dbt_comment_literal_block$A starter dbt model$dbt_comment_literal_block$;

  
[0m10:53:43.624255 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m10:53:43.625639 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m10:53:43.626276 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:53:43.626276 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m10:53:43.639871 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m10:53:43.642872 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m10:53:43.642872 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
drop view if exists "Adventureworks"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m10:53:43.644884 [debug] [Thread-4 (]: SQL status: DROP VIEW in 0.0 seconds
[0m10:53:43.646499 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (execute): 10:53:43.566183 => 10:53:43.646405
[0m10:53:43.647033 [debug] [Thread-4 (]: On model.dbt_tutorial.my_second_dbt_model: Close
[0m10:53:43.648035 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D52CEE30>]}
[0m10:53:43.648035 [info ] [Thread-4 (]: 4 of 4 OK created sql view model warehouse.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.09s]
[0m10:53:43.650037 [debug] [Thread-4 (]: Finished running node model.dbt_tutorial.my_second_dbt_model
[0m10:53:43.934494 [debug] [Thread-3 (]: SQL status: SELECT 31465 in 1.0 seconds
[0m10:53:43.938178 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:53:43.938919 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m10:53:43.939994 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:53:43.942994 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:53:43.942994 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m10:53:43.945770 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:53:43.947772 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:53:43.947772 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m10:53:43.949771 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m10:53:43.950771 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m10:53:43.951779 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:53:43.952108 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m10:53:43.972763 [debug] [Thread-2 (]: SQL status: SELECT 121317 in 1.0 seconds
[0m10:53:43.975330 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m10:53:43.976357 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp" rename to "sales_order_detail"
[0m10:53:43.977344 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m10:53:43.979906 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m10:53:43.980539 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_detail" is $dbt_comment_literal_block$Intermediate sales order detail table$dbt_comment_literal_block$;

  
[0m10:53:43.981541 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m10:53:43.983541 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m10:53:43.983541 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m10:53:43.984542 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m10:53:44.004366 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m10:53:44.007685 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m10:53:44.008228 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m10:53:44.021538 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m10:53:44.024465 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m10:53:44.024465 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_detail__dbt_backup" cascade
[0m10:53:44.026465 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m10:53:44.026465 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m10:53:44.028978 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 10:53:43.317519 => 10:53:44.028452
[0m10:53:44.029979 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (execute): 10:53:43.313519 => 10:53:44.029979
[0m10:53:44.029979 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: Close
[0m10:53:44.030980 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: Close
[0m10:53:44.031980 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D501EEC0>]}
[0m10:53:44.032982 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d9d8245-ee96-4e87-bfbd-5bdf39b5adad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D5337700>]}
[0m10:53:44.033981 [info ] [Thread-3 (]: 3 of 4 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.77s]
[0m10:53:44.034978 [info ] [Thread-2 (]: 2 of 4 OK created sql table model warehouse.sales_order_detail ................. [[32mSELECT 121317[0m in 0.78s]
[0m10:53:44.035494 [debug] [Thread-3 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m10:53:44.036431 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_detail
[0m10:53:44.039434 [debug] [MainThread]: Using postgres connection "master"
[0m10:53:44.040430 [debug] [MainThread]: On master: BEGIN
[0m10:53:44.040430 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m10:53:44.071783 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m10:53:44.072784 [debug] [MainThread]: On master: COMMIT
[0m10:53:44.072784 [debug] [MainThread]: Using postgres connection "master"
[0m10:53:44.073784 [debug] [MainThread]: On master: COMMIT
[0m10:53:44.074786 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m10:53:44.074786 [debug] [MainThread]: On master: Close
[0m10:53:44.075784 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:53:44.075784 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m10:53:44.076964 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m10:53:44.077049 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_first_dbt_model' was properly closed.
[0m10:53:44.077800 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_detail' was properly closed.
[0m10:53:44.077819 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m10:53:44.077819 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_second_dbt_model' was properly closed.
[0m10:53:44.079419 [info ] [MainThread]: 
[0m10:53:44.079947 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 1.59 seconds (1.59s).
[0m10:53:44.081507 [debug] [MainThread]: Command end result
[0m10:53:44.089253 [info ] [MainThread]: 
[0m10:53:44.089773 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:53:44.090293 [info ] [MainThread]: 
[0m10:53:44.090924 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m10:53:44.091664 [debug] [MainThread]: Command `dbt run` succeeded at 10:53:44.091664 after 1.92 seconds
[0m10:53:44.092666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D2877640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D4DF57E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299D4CC7040>]}
[0m10:53:44.092666 [debug] [MainThread]: Flushing usage events
[0m10:53:44.168511 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m19:40:40.813508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A0B73640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A30C31F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A30C30A0>]}


============================== 19:40:40.817796 | 288da8a5-d55c-466e-bb9d-d709e403088b ==============================
[0m19:40:40.817796 [info ] [MainThread]: Running with dbt=1.5.11
[0m19:40:40.817796 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m19:40:40.884793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A30C3940>]}
[0m19:40:40.903198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A341CA00>]}
[0m19:40:40.904198 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m19:40:40.914313 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m19:40:40.923242 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:40:40.924230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A341CBB0>]}
[0m19:40:41.522885 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
[0m19:40:41.534886 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
[0m19:40:41.538885 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\dim_product.sql
[0m19:40:41.542070 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_detail.sql
[0m19:40:41.545229 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m19:40:41.754843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A361B220>]}
[0m19:40:41.762885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A361B250>]}
[0m19:40:41.763877 [info ] [MainThread]: Found 5 models, 13 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m19:40:41.764038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A1B351B0>]}
[0m19:40:41.766132 [info ] [MainThread]: 
[0m19:40:41.767040 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:40:41.768039 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m19:40:41.779768 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m19:40:41.780818 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m19:40:41.780818 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:40:41.803948 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m19:40:41.804927 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m19:40:41.810931 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m19:40:41.817738 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m19:40:41.818289 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m19:40:41.818814 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:40:41.832357 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:40:41.833358 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m19:40:41.833358 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m19:40:41.836355 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.0 seconds
[0m19:40:41.837357 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m19:40:41.838356 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m19:40:41.844293 [debug] [MainThread]: Using postgres connection "master"
[0m19:40:41.844816 [debug] [MainThread]: On master: BEGIN
[0m19:40:41.845333 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:40:41.859587 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:40:41.859587 [debug] [MainThread]: Using postgres connection "master"
[0m19:40:41.860588 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:40:41.995143 [debug] [MainThread]: SQL status: SELECT 147 in 0.0 seconds
[0m19:40:41.999143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A3546AA0>]}
[0m19:40:42.000143 [debug] [MainThread]: On master: ROLLBACK
[0m19:40:42.001175 [debug] [MainThread]: Using postgres connection "master"
[0m19:40:42.002144 [debug] [MainThread]: On master: BEGIN
[0m19:40:42.004142 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:40:42.004142 [debug] [MainThread]: On master: COMMIT
[0m19:40:42.005144 [debug] [MainThread]: Using postgres connection "master"
[0m19:40:42.005144 [debug] [MainThread]: On master: COMMIT
[0m19:40:42.006143 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:40:42.006143 [debug] [MainThread]: On master: Close
[0m19:40:42.007144 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:40:42.008145 [info ] [MainThread]: 
[0m19:40:42.013926 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.dim_product
[0m19:40:42.014566 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.my_first_dbt_model
[0m19:40:42.014566 [debug] [Thread-3 (]: Began running node model.dbt_tutorial.sales_order_detail
[0m19:40:42.015089 [debug] [Thread-4 (]: Began running node model.dbt_tutorial.sales_order_header
[0m19:40:42.016131 [info ] [Thread-1 (]: 1 of 5 START sql table model warehouse.dim_product ............................. [RUN]
[0m19:40:42.016697 [info ] [Thread-2 (]: 2 of 5 START sql table model warehouse.my_first_dbt_model ...................... [RUN]
[0m19:40:42.017574 [info ] [Thread-3 (]: 3 of 5 START sql table model warehouse.sales_order_detail ...................... [RUN]
[0m19:40:42.018093 [info ] [Thread-4 (]: 4 of 5 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m19:40:42.019135 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.dim_product'
[0m19:40:42.020190 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.my_first_dbt_model'
[0m19:40:42.020711 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_detail'
[0m19:40:42.021750 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m19:40:42.022260 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.dim_product
[0m19:40:42.022260 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.my_first_dbt_model
[0m19:40:42.022260 [debug] [Thread-3 (]: Began compiling node model.dbt_tutorial.sales_order_detail
[0m19:40:42.023261 [debug] [Thread-4 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m19:40:42.031828 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.dim_product"
[0m19:40:42.035827 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.my_first_dbt_model"
[0m19:40:42.038858 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_detail"
[0m19:40:42.042222 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m19:40:42.044237 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (compile): 19:40:42.023261 => 19:40:42.043224
[0m19:40:42.044237 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (compile): 19:40:42.031828 => 19:40:42.044237
[0m19:40:42.045225 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_detail (compile): 19:40:42.035827 => 19:40:42.045225
[0m19:40:42.046225 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.dim_product
[0m19:40:42.046225 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 19:40:42.038858 => 19:40:42.046225
[0m19:40:42.047223 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.my_first_dbt_model
[0m19:40:42.048223 [debug] [Thread-3 (]: Began executing node model.dbt_tutorial.sales_order_detail
[0m19:40:42.089194 [debug] [Thread-4 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m19:40:42.099349 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.dim_product"
[0m19:40:42.102318 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.my_first_dbt_model"
[0m19:40:42.106992 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_detail"
[0m19:40:42.110988 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m19:40:42.111989 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.dim_product"} */
select * from (
        SELECT 
    productid, 
    "name", 
    productnumber, 
    makeflag, 
    finishedgoodsflag, 
    color, 
    safetystocklevel, 
    reorderpoint, 
    standardcost, 
    listprice, 
    "size", 
    sizeunitmeasurecode, 
    weightunitmeasurecode, 
    "weight", 
    daystomanufacture, 
    productline, 
    "class", 
    "style", 
    productsubcategoryid, 
    productmodelid, 
    sellstartdate, 
    sellenddate, 
    discontinueddate, 
    rowguid as row_id, 
    modifieddate
FROM 
    "Adventureworks"."production"."product"
    ) as __dbt_sbq
    where false
    limit 0

[0m19:40:42.113011 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m19:40:42.113954 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m19:40:42.113954 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:40:42.115061 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m19:40:42.115061 [debug] [Thread-2 (]: On model.dbt_tutorial.my_first_dbt_model: BEGIN
[0m19:40:42.116143 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_detail: BEGIN
[0m19:40:42.117068 [debug] [Thread-4 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m19:40:42.117068 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m19:40:42.117068 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m19:40:42.117068 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m19:40:42.131169 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m19:40:42.132169 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m19:40:42.132169 [debug] [Thread-2 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */

  
    

  create  table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m19:40:42.134170 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m19:40:42.135171 [debug] [Thread-2 (]: SQL status: SELECT 2 in 0.0 seconds
[0m19:40:42.135171 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m19:40:42.141342 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m19:40:42.141342 [debug] [Thread-4 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m19:40:42.142342 [debug] [Thread-2 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m19:40:42.143345 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:40:42.146342 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m19:40:42.147342 [debug] [Thread-2 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m19:40:42.148343 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:40:42.173969 [debug] [Thread-4 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m19:40:42.173969 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m19:40:42.176969 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m19:40:42.176969 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m19:40:42.179999 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m19:40:42.179999 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m19:40:42.180968 [debug] [Thread-2 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */

    
  
  comment on table "Adventureworks"."warehouse"."my_first_dbt_model" is $dbt_comment_literal_block$A starter dbt model$dbt_comment_literal_block$;

  
[0m19:40:42.181983 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (execute): 19:40:42.048223 => 19:40:42.181983
[0m19:40:42.181983 [debug] [Thread-4 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m19:40:42.183002 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid
    ,salesorderdetailid
    ,carriertrackingnumber
    ,orderqty
    ,productid
    ,specialofferid
    ,unitprice
    ,unitpricediscount
    ,rowguid as row_id
    ,modifieddate
FROM "Adventureworks"."sales"."salesorderdetail"
  );
  
[0m19:40:42.183969 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: Close
[0m19:40:42.184985 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m19:40:42.185969 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:40:42.185969 [error] [Thread-1 (]: [31mUnhandled error while executing [0m
2950
[0m19:40:42.187970 [debug] [Thread-2 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m19:40:42.191944 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m19:40:42.192986 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m19:40:42.193512 [debug] [Thread-4 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m19:40:42.194035 [debug] [Thread-2 (]: On model.dbt_tutorial.my_first_dbt_model: COMMIT
[0m19:40:42.197162 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 388, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 337, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 436, in run
    return self.execute(compiled_node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\run.py", line 291, in execute
    result = MacroGenerator(
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 82, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 42, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 78, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 23, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 24, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 62, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 20, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 36, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 295, in get_column_schema_from_query
    columns = [
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 297, in <listcomp>
    column_name, self.connections.data_type_code_to_name(column_type_code)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\postgres\connections.py", line 197, in data_type_code_to_name
    return string_types[type_code].name
KeyError: 2950

[0m19:40:42.198202 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A3617EE0>]}
[0m19:40:42.199243 [error] [Thread-1 (]: 1 of 5 ERROR creating sql table model warehouse.dim_product .................... [[31mERROR[0m in 0.18s]
[0m19:40:42.199765 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.dim_product
[0m19:40:42.210365 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m19:40:42.210365 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:40:42.216832 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.my_first_dbt_model"
[0m19:40:42.216832 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m19:40:42.216832 [debug] [Thread-2 (]: On model.dbt_tutorial.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_first_dbt_model"} */
drop table if exists "Adventureworks"."warehouse"."my_first_dbt_model__dbt_backup" cascade
[0m19:40:42.216832 [debug] [Thread-4 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m19:40:42.221865 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m19:40:42.221865 [debug] [Thread-4 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m19:40:42.221865 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m19:40:42.221865 [debug] [Thread-4 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m19:40:42.230660 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:40:42.232663 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.my_first_dbt_model (execute): 19:40:42.099349 => 19:40:42.232663
[0m19:40:42.233662 [debug] [Thread-2 (]: On model.dbt_tutorial.my_first_dbt_model: Close
[0m19:40:42.233662 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m19:40:42.234663 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A35847F0>]}
[0m19:40:42.239609 [debug] [Thread-4 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m19:40:42.240649 [info ] [Thread-2 (]: 2 of 5 OK created sql table model warehouse.my_first_dbt_model ................. [[32mSELECT 2[0m in 0.22s]
[0m19:40:42.241252 [debug] [Thread-4 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m19:40:42.242504 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.my_first_dbt_model
[0m19:40:42.243551 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.my_second_dbt_model
[0m19:40:42.244072 [info ] [Thread-1 (]: 5 of 5 START sql view model warehouse.my_second_dbt_model ...................... [RUN]
[0m19:40:42.244596 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_tutorial.dim_product, now model.dbt_tutorial.my_second_dbt_model)
[0m19:40:42.245119 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.my_second_dbt_model
[0m19:40:42.248740 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.my_second_dbt_model"
[0m19:40:42.249793 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (compile): 19:40:42.245633 => 19:40:42.249793
[0m19:40:42.250308 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.my_second_dbt_model
[0m19:40:42.250308 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:40:42.272101 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_tutorial.my_second_dbt_model"
[0m19:40:42.274100 [debug] [Thread-4 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 19:40:42.107966 => 19:40:42.274100
[0m19:40:42.275101 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m19:40:42.275101 [debug] [Thread-4 (]: On model.dbt_tutorial.sales_order_header: Close
[0m19:40:42.276102 [debug] [Thread-1 (]: On model.dbt_tutorial.my_second_dbt_model: BEGIN
[0m19:40:42.277201 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:40:42.279102 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A352AEF0>]}
[0m19:40:42.282100 [info ] [Thread-4 (]: 4 of 5 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.26s]
[0m19:40:42.283103 [debug] [Thread-4 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m19:40:42.299594 [debug] [Thread-3 (]: SQL status: SELECT 121317 in 0.0 seconds
[0m19:40:42.303591 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m19:40:42.303591 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:40:42.304611 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail" rename to "sales_order_detail__dbt_backup"
[0m19:40:42.304611 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m19:40:42.305592 [debug] [Thread-1 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */

  create view "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "Adventureworks"."warehouse"."my_first_dbt_model"
where id = 1
  );
[0m19:40:42.306592 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:40:42.311592 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m19:40:42.311592 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m19:40:42.312592 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp" rename to "sales_order_detail"
[0m19:40:42.314672 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m19:40:42.315672 [debug] [Thread-1 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
alter table "Adventureworks"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m19:40:42.316706 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:40:42.319450 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m19:40:42.319450 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:40:42.319450 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_detail" is $dbt_comment_literal_block$Intermediate sales order detail table$dbt_comment_literal_block$;

  
[0m19:40:42.321449 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m19:40:42.322449 [debug] [Thread-1 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */

    
  
  comment on view "Adventureworks"."warehouse"."my_second_dbt_model" is $dbt_comment_literal_block$A starter dbt model$dbt_comment_literal_block$;

  
[0m19:40:42.323450 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m19:40:42.323450 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m19:40:42.324450 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m19:40:42.326449 [debug] [Thread-1 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m19:40:42.326449 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m19:40:42.327451 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m19:40:42.327451 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m19:40:42.328450 [debug] [Thread-1 (]: On model.dbt_tutorial.my_second_dbt_model: COMMIT
[0m19:40:42.345584 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:40:42.348584 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.my_second_dbt_model"
[0m19:40:42.348584 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m19:40:42.348584 [debug] [Thread-1 (]: On model.dbt_tutorial.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.my_second_dbt_model"} */
drop view if exists "Adventureworks"."warehouse"."my_second_dbt_model__dbt_backup" cascade
[0m19:40:42.351583 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m19:40:42.352583 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_detail__dbt_backup" cascade
[0m19:40:42.353583 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m19:40:42.354583 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.my_second_dbt_model (execute): 19:40:42.251307 => 19:40:42.354583
[0m19:40:42.355583 [debug] [Thread-1 (]: On model.dbt_tutorial.my_second_dbt_model: Close
[0m19:40:42.356583 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A28FAA70>]}
[0m19:40:42.356583 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:40:42.357583 [info ] [Thread-1 (]: 5 of 5 OK created sql view model warehouse.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.11s]
[0m19:40:42.359584 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_detail (execute): 19:40:42.103318 => 19:40:42.358584
[0m19:40:42.359584 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.my_second_dbt_model
[0m19:40:42.360583 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_detail: Close
[0m19:40:42.361583 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '288da8a5-d55c-466e-bb9d-d709e403088b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A37DAB60>]}
[0m19:40:42.363058 [info ] [Thread-3 (]: 3 of 5 OK created sql table model warehouse.sales_order_detail ................. [[32mSELECT 121317[0m in 0.34s]
[0m19:40:42.364243 [debug] [Thread-3 (]: Finished running node model.dbt_tutorial.sales_order_detail
[0m19:40:42.366789 [debug] [MainThread]: Using postgres connection "master"
[0m19:40:42.367311 [debug] [MainThread]: On master: BEGIN
[0m19:40:42.367831 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:40:42.382209 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:40:42.383212 [debug] [MainThread]: On master: COMMIT
[0m19:40:42.383212 [debug] [MainThread]: Using postgres connection "master"
[0m19:40:42.383212 [debug] [MainThread]: On master: COMMIT
[0m19:40:42.384211 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:40:42.385211 [debug] [MainThread]: On master: Close
[0m19:40:42.385211 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:40:42.386211 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m19:40:42.386211 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m19:40:42.387209 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_second_dbt_model' was properly closed.
[0m19:40:42.388218 [debug] [MainThread]: Connection 'model.dbt_tutorial.my_first_dbt_model' was properly closed.
[0m19:40:42.388218 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_detail' was properly closed.
[0m19:40:42.389301 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m19:40:42.390257 [info ] [MainThread]: 
[0m19:40:42.390805 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 0.62 seconds (0.62s).
[0m19:40:42.391977 [debug] [MainThread]: Command end result
[0m19:40:42.400375 [info ] [MainThread]: 
[0m19:40:42.401375 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:40:42.402374 [info ] [MainThread]: 
[0m19:40:42.402374 [error] [MainThread]: [33m2950[0m
[0m19:40:42.403374 [info ] [MainThread]: 
[0m19:40:42.403374 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m19:40:42.405394 [debug] [MainThread]: Command `dbt run` failed at 19:40:42.405394 after 1.61 seconds
[0m19:40:42.406387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A0B73640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A312E950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5A37D9300>]}
[0m19:40:42.407377 [debug] [MainThread]: Flushing usage events
[0m19:40:42.467338 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m19:56:43.633210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012716373640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000127188C3760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000127188C3340>]}


============================== 19:56:43.638209 | 201c02e4-ab6d-4777-bf60-16b3accf3493 ==============================
[0m19:56:43.638209 [info ] [MainThread]: Running with dbt=1.5.11
[0m19:56:43.639209 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m19:56:43.667732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '201c02e4-ab6d-4777-bf60-16b3accf3493', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000127188C38B0>]}
[0m19:56:43.682732 [debug] [MainThread]: Command `dbt clean` succeeded at 19:56:43.682732 after 0.07 seconds
[0m19:56:43.683731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000012716373640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000127188C33A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000127188C3970>]}
[0m19:56:43.683731 [debug] [MainThread]: Flushing usage events
[0m20:09:11.516540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF3973640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF5EC3280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF5EC3130>]}


============================== 20:09:11.520553 | 6f6f5762-9ad7-485c-aacf-a7b52a544c2e ==============================
[0m20:09:11.520553 [info ] [MainThread]: Running with dbt=1.5.11
[0m20:09:11.521552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m20:09:11.605514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF5EC39D0>]}
[0m20:09:11.623772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF621CA90>]}
[0m20:09:11.624775 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m20:09:11.635772 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m20:09:11.636780 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m20:09:11.637772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF5EC3790>]}
[0m20:09:12.260934 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\dim_product.sql
[0m20:09:12.269525 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_detail.sql
[0m20:09:12.269525 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m20:09:12.472088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF637C0D0>]}
[0m20:09:12.479634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF637C100>]}
[0m20:09:12.479634 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m20:09:12.482488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF637C1F0>]}
[0m20:09:12.485312 [info ] [MainThread]: 
[0m20:09:12.489422 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:09:12.504529 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m20:09:12.518017 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m20:09:12.519034 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m20:09:12.520022 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:09:12.657040 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m20:09:12.659037 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m20:09:12.662040 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m20:09:12.669253 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:09:12.669270 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m20:09:12.669270 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:09:12.687412 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:09:12.687929 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:09:12.688438 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m20:09:12.715670 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m20:09:12.716701 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m20:09:12.719222 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m20:09:12.719222 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:12.719222 [debug] [MainThread]: On master: BEGIN
[0m20:09:12.719222 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:09:12.810503 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:09:12.811504 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:12.811504 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:09:13.338484 [debug] [MainThread]: SQL status: SELECT 146 in 1.0 seconds
[0m20:09:13.343370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF4F30880>]}
[0m20:09:13.344398 [debug] [MainThread]: On master: ROLLBACK
[0m20:09:13.345367 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:13.346367 [debug] [MainThread]: On master: BEGIN
[0m20:09:13.347368 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:09:13.347368 [debug] [MainThread]: On master: COMMIT
[0m20:09:13.348371 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:13.348371 [debug] [MainThread]: On master: COMMIT
[0m20:09:13.352367 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:09:13.352367 [debug] [MainThread]: On master: Close
[0m20:09:13.353367 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:09:13.354369 [info ] [MainThread]: 
[0m20:09:13.366254 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.dim_product
[0m20:09:13.366779 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_detail
[0m20:09:13.367302 [debug] [Thread-3 (]: Began running node model.dbt_tutorial.sales_order_header
[0m20:09:13.368884 [info ] [Thread-1 (]: 1 of 3 START sql table model warehouse.dim_product ............................. [RUN]
[0m20:09:13.370680 [info ] [Thread-2 (]: 2 of 3 START sql table model warehouse.sales_order_detail ...................... [RUN]
[0m20:09:13.370680 [info ] [Thread-3 (]: 3 of 3 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m20:09:13.374193 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.dim_product'
[0m20:09:13.374193 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_detail'
[0m20:09:13.376503 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m20:09:13.377506 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.dim_product
[0m20:09:13.377506 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_detail
[0m20:09:13.378507 [debug] [Thread-3 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m20:09:13.388504 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.dim_product"
[0m20:09:13.398110 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_detail"
[0m20:09:13.403109 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m20:09:13.409114 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (compile): 20:09:13.379500 => 20:09:13.408118
[0m20:09:13.411113 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (compile): 20:09:13.390925 => 20:09:13.410112
[0m20:09:13.412114 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 20:09:13.400112 => 20:09:13.412114
[0m20:09:13.413112 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.dim_product
[0m20:09:13.414257 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_detail
[0m20:09:13.416632 [debug] [Thread-3 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m20:09:13.519873 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_detail"
[0m20:09:13.529871 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.dim_product"
[0m20:09:13.534871 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m20:09:13.535873 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.dim_product"} */
select * from (
        SELECT 
    productid, 
    "name", 
    productnumber, 
    makeflag, 
    finishedgoodsflag, 
    color, 
    safetystocklevel, 
    reorderpoint, 
    standardcost, 
    listprice, 
    "size", 
    sizeunitmeasurecode, 
    weightunitmeasurecode, 
    "weight", 
    daystomanufacture, 
    productline, 
    "class", 
    "style", 
    productsubcategoryid, 
    productmodelid, 
    sellstartdate, 
    sellenddate, 
    discontinueddate, 
    rowguid as row_id, 
    modifieddate
FROM 
    "Adventureworks"."production"."product"
    ) as __dbt_sbq
    where false
    limit 0

[0m20:09:13.536872 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:09:13.537876 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:09:13.537876 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:09:13.539445 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: BEGIN
[0m20:09:13.540405 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m20:09:13.540405 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:09:13.541550 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:09:13.574851 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m20:09:13.575846 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (execute): 20:09:13.417634 => 20:09:13.574851
[0m20:09:13.575846 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: Close
[0m20:09:13.576850 [error] [Thread-1 (]: [31mUnhandled error while executing [0m
2950
[0m20:09:13.579848 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m20:09:13.581097 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:09:13.581736 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m20:09:13.593654 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 388, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 337, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 436, in run
    return self.execute(compiled_node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\run.py", line 291, in execute
    result = MacroGenerator(
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 82, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 42, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 78, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 23, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 24, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 62, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 20, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 36, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 295, in get_column_schema_from_query
    columns = [
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 297, in <listcomp>
    column_name, self.connections.data_type_code_to_name(column_type_code)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\postgres\connections.py", line 197, in data_type_code_to_name
    return string_types[type_code].name
KeyError: 2950

[0m20:09:13.595648 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF62E2E30>]}
[0m20:09:13.596645 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model warehouse.dim_product .................... [[31mERROR[0m in 0.22s]
[0m20:09:13.598651 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.dim_product
[0m20:09:13.609656 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m20:09:13.610648 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:09:13.611653 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid
    ,salesorderdetailid
    ,carriertrackingnumber
    ,orderqty
    ,productid
    ,specialofferid
    ,unitprice
    ,unitpricediscount
    ,rowguid as row_id
    ,modifieddate
FROM "Adventureworks"."sales"."salesorderdetail"
  );
  
[0m20:09:13.988339 [debug] [Thread-3 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m20:09:13.995340 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:09:13.996340 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m20:09:14.009904 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:09:14.061488 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:09:14.061488 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m20:09:14.064653 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m20:09:14.065653 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:09:14.066697 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:09:14.066697 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:09:14.077426 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m20:09:14.084603 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:09:14.085602 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m20:09:14.087603 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:09:14.090172 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 20:09:13.529871 => 20:09:14.090172
[0m20:09:14.091171 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: Close
[0m20:09:14.093019 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF56FB8B0>]}
[0m20:09:14.093536 [info ] [Thread-3 (]: 3 of 3 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.72s]
[0m20:09:14.093536 [debug] [Thread-3 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m20:09:14.339203 [debug] [Thread-2 (]: SQL status: SELECT 121317 in 1.0 seconds
[0m20:09:14.342237 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:09:14.343242 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp" rename to "sales_order_detail"
[0m20:09:14.346237 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:09:14.348234 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:09:14.348234 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_detail" is $dbt_comment_literal_block$Intermediate sales order detail table$dbt_comment_literal_block$;

  
[0m20:09:14.350250 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m20:09:14.351237 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:09:14.352236 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:09:14.352236 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:09:14.408272 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m20:09:14.411252 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:09:14.412261 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_detail__dbt_backup" cascade
[0m20:09:14.414513 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:09:14.415596 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (execute): 20:09:13.489494 => 20:09:14.415596
[0m20:09:14.416596 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: Close
[0m20:09:14.416618 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f6f5762-9ad7-485c-aacf-a7b52a544c2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF642A470>]}
[0m20:09:14.416618 [info ] [Thread-2 (]: 2 of 3 OK created sql table model warehouse.sales_order_detail ................. [[32mSELECT 121317[0m in 1.04s]
[0m20:09:14.419765 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_detail
[0m20:09:14.419765 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:14.419765 [debug] [MainThread]: On master: BEGIN
[0m20:09:14.419765 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:09:14.442394 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:09:14.442394 [debug] [MainThread]: On master: COMMIT
[0m20:09:14.443394 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:14.443394 [debug] [MainThread]: On master: COMMIT
[0m20:09:14.444393 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:09:14.445393 [debug] [MainThread]: On master: Close
[0m20:09:14.446393 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:09:14.446393 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m20:09:14.447392 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m20:09:14.447392 [debug] [MainThread]: Connection 'model.dbt_tutorial.dim_product' was properly closed.
[0m20:09:14.448393 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_detail' was properly closed.
[0m20:09:14.448393 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m20:09:14.449628 [info ] [MainThread]: 
[0m20:09:14.450151 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.96 seconds (1.96s).
[0m20:09:14.451193 [debug] [MainThread]: Command end result
[0m20:09:14.462739 [info ] [MainThread]: 
[0m20:09:14.463735 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:09:14.464881 [info ] [MainThread]: 
[0m20:09:14.465882 [error] [MainThread]: [33m2950[0m
[0m20:09:14.465882 [info ] [MainThread]: 
[0m20:09:14.466995 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m20:09:14.469556 [debug] [MainThread]: Command `dbt run` failed at 20:09:14.466995 after 2.97 seconds
[0m20:09:14.469556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF3973640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF5EC3040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019DF634D3F0>]}
[0m20:09:14.469556 [debug] [MainThread]: Flushing usage events
[0m20:09:53.869546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A37A73640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A39EC36D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A39EC32B0>]}


============================== 20:09:53.869546 | ca1fc839-8dd4-4fe4-af80-9ce4bd845c4b ==============================
[0m20:09:53.869546 [info ] [MainThread]: Running with dbt=1.5.11
[0m20:09:53.869546 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m20:09:53.869546 [info ] [MainThread]: dbt version: 1.5.11
[0m20:09:53.869546 [info ] [MainThread]: python version: 3.10.11
[0m20:09:53.869546 [info ] [MainThread]: python path: D:\CS\dbt\.venv\Scripts\python.exe
[0m20:09:53.869546 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m20:09:53.879872 [info ] [MainThread]: Using profiles.yml file at C:\Users\mtri0\.dbt\profiles.yml
[0m20:09:53.879872 [info ] [MainThread]: Using dbt_project.yml file at D:\CS\dbt\dbt_tutorial\dbt_project.yml
[0m20:09:53.880875 [info ] [MainThread]: Configuration:
[0m20:09:53.946856 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:09:53.969706 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:09:53.969706 [info ] [MainThread]: Required dependencies:
[0m20:09:53.969706 [debug] [MainThread]: Executing "git --help"
[0m20:09:54.015423 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:09:54.015423 [debug] [MainThread]: STDERR: "b''"
[0m20:09:54.016485 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:09:54.016485 [info ] [MainThread]: Connection:
[0m20:09:54.016485 [info ] [MainThread]:   host: localhost
[0m20:09:54.016485 [info ] [MainThread]:   port: 5432
[0m20:09:54.016485 [info ] [MainThread]:   user: postgres
[0m20:09:54.019501 [info ] [MainThread]:   database: Adventureworks
[0m20:09:54.019501 [info ] [MainThread]:   schema: warehouse
[0m20:09:54.019501 [info ] [MainThread]:   search_path: None
[0m20:09:54.019501 [info ] [MainThread]:   keepalives_idle: 0
[0m20:09:54.019501 [info ] [MainThread]:   sslmode: None
[0m20:09:54.019501 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m20:09:54.019501 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:09:54.019501 [debug] [MainThread]: Using postgres connection "debug"
[0m20:09:54.019501 [debug] [MainThread]: On debug: select 1 as id
[0m20:09:54.019501 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:09:54.048152 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m20:09:54.051152 [debug] [MainThread]: On debug: Close
[0m20:09:54.051152 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m20:09:54.053156 [info ] [MainThread]: [32mAll checks passed![0m
[0m20:09:54.054152 [debug] [MainThread]: Command `dbt debug` succeeded at 20:09:54.053156 after 0.20 seconds
[0m20:09:54.054152 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:09:54.054152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A37A73640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A39FDF9D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020A39FD9690>]}
[0m20:09:54.055153 [debug] [MainThread]: Flushing usage events
[0m20:13:51.542888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6C8773640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CABC32E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CABC3190>]}


============================== 20:13:51.542888 | 6550526b-92a6-4e73-a7fb-ed099cfbc180 ==============================
[0m20:13:51.542888 [info ] [MainThread]: Running with dbt=1.5.11
[0m20:13:51.542888 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'debug': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m20:13:51.623910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6550526b-92a6-4e73-a7fb-ed099cfbc180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CABC3A30>]}
[0m20:13:51.643203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6550526b-92a6-4e73-a7fb-ed099cfbc180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CAD1CAF0>]}
[0m20:13:51.647199 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m20:13:51.662198 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m20:13:51.774909 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:13:51.774909 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:13:51.782911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6550526b-92a6-4e73-a7fb-ed099cfbc180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CB09DE10>]}
[0m20:13:51.791432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6550526b-92a6-4e73-a7fb-ed099cfbc180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CAD6EDA0>]}
[0m20:13:51.792433 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m20:13:51.792433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6550526b-92a6-4e73-a7fb-ed099cfbc180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CAD6C700>]}
[0m20:13:51.795454 [info ] [MainThread]: 
[0m20:13:51.796434 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:13:51.798435 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m20:13:51.808433 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m20:13:51.810433 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m20:13:51.810433 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:13:51.837126 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m20:13:51.839125 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m20:13:51.841493 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m20:13:51.850140 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:13:51.850655 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m20:13:51.851713 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:13:51.886794 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:13:51.887807 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:13:51.887807 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m20:13:51.890891 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m20:13:51.892890 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m20:13:51.893891 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m20:13:51.900752 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:51.901269 [debug] [MainThread]: On master: BEGIN
[0m20:13:51.901787 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:13:51.916296 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:13:51.916296 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:51.916296 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:13:52.304498 [debug] [MainThread]: SQL status: SELECT 146 in 0.0 seconds
[0m20:13:52.308516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6550526b-92a6-4e73-a7fb-ed099cfbc180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CB0E6470>]}
[0m20:13:52.309514 [debug] [MainThread]: On master: ROLLBACK
[0m20:13:52.311482 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:52.311482 [debug] [MainThread]: On master: BEGIN
[0m20:13:52.314959 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:13:52.315960 [debug] [MainThread]: On master: COMMIT
[0m20:13:52.315960 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:52.316984 [debug] [MainThread]: On master: COMMIT
[0m20:13:52.316984 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:13:52.316984 [debug] [MainThread]: On master: Close
[0m20:13:52.316984 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:13:52.316984 [info ] [MainThread]: 
[0m20:13:52.328737 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.dim_product
[0m20:13:52.329258 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_detail
[0m20:13:52.329786 [debug] [Thread-3 (]: Began running node model.dbt_tutorial.sales_order_header
[0m20:13:52.330825 [info ] [Thread-1 (]: 1 of 3 START sql table model warehouse.dim_product ............................. [RUN]
[0m20:13:52.331345 [info ] [Thread-2 (]: 2 of 3 START sql table model warehouse.sales_order_detail ...................... [RUN]
[0m20:13:52.331862 [info ] [Thread-3 (]: 3 of 3 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m20:13:52.332891 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.dim_product'
[0m20:13:52.333410 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_detail'
[0m20:13:52.334448 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m20:13:52.334964 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.dim_product
[0m20:13:52.334964 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_detail
[0m20:13:52.335962 [debug] [Thread-3 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m20:13:52.342601 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.dim_product"
[0m20:13:52.342601 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_detail"
[0m20:13:52.342601 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m20:13:52.352634 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (compile): 20:13:52.335962 => 20:13:52.342601
[0m20:13:52.352634 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (compile): 20:13:52.342601 => 20:13:52.352634
[0m20:13:52.352634 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 20:13:52.342601 => 20:13:52.352634
[0m20:13:52.352634 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.dim_product
[0m20:13:52.352634 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_detail
[0m20:13:52.352634 [debug] [Thread-3 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m20:13:52.414666 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.dim_product"
[0m20:13:52.416722 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_detail"
[0m20:13:52.422769 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m20:13:52.422769 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.dim_product"} */
select * from (
        SELECT 
    productid, 
    "name", 
    productnumber, 
    makeflag, 
    finishedgoodsflag, 
    color, 
    safetystocklevel, 
    reorderpoint, 
    standardcost, 
    listprice, 
    "size", 
    sizeunitmeasurecode, 
    weightunitmeasurecode, 
    "weight", 
    daystomanufacture, 
    productline, 
    "class", 
    "style", 
    productsubcategoryid, 
    productmodelid, 
    sellstartdate, 
    sellenddate, 
    discontinueddate, 
    rowguid as row_id, 
    modifieddate
FROM 
    "Adventureworks"."production"."product"
    ) as __dbt_sbq
    where false
    limit 0

[0m20:13:52.422769 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:13:52.422769 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:13:52.422769 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:13:52.422769 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: BEGIN
[0m20:13:52.422769 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m20:13:52.422769 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:13:52.422769 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:13:52.454579 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m20:13:52.455571 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:13:52.457573 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid
    ,salesorderdetailid
    ,carriertrackingnumber
    ,orderqty
    ,productid
    ,specialofferid
    ,unitprice
    ,unitpricediscount
    ,rowguid as row_id
    ,modifieddate
FROM "Adventureworks"."sales"."salesorderdetail"
  );
  
[0m20:13:52.457573 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m20:13:52.458569 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:13:52.459573 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m20:13:52.542948 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m20:13:52.543950 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (execute): 20:13:52.352634 => 20:13:52.543950
[0m20:13:52.544951 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: Close
[0m20:13:52.546951 [error] [Thread-1 (]: [31mUnhandled error while executing [0m
2950
[0m20:13:52.554930 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 388, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 337, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 436, in run
    return self.execute(compiled_node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\run.py", line 291, in execute
    result = MacroGenerator(
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 82, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 42, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 78, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 23, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 24, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 62, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 20, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 36, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 295, in get_column_schema_from_query
    columns = [
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 297, in <listcomp>
    column_name, self.connections.data_type_code_to_name(column_type_code)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\postgres\connections.py", line 197, in data_type_code_to_name
    return string_types[type_code].name
KeyError: 2950

[0m20:13:52.558074 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6550526b-92a6-4e73-a7fb-ed099cfbc180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CB154340>]}
[0m20:13:52.559123 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model warehouse.dim_product .................... [[31mERROR[0m in 0.23s]
[0m20:13:52.559643 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.dim_product
[0m20:13:52.649202 [debug] [Thread-3 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m20:13:52.656201 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:13:52.657200 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m20:13:52.660766 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:13:52.665818 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:13:52.667021 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m20:13:52.671924 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:13:52.703462 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:13:52.705461 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m20:13:52.707461 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m20:13:52.708476 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:13:52.709462 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:13:52.710461 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:13:52.722974 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m20:13:52.736249 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:13:52.737252 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m20:13:52.792576 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:13:52.794577 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 20:13:52.416722 => 20:13:52.794577
[0m20:13:52.795577 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: Close
[0m20:13:52.796576 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6550526b-92a6-4e73-a7fb-ed099cfbc180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CB0F0E80>]}
[0m20:13:52.797581 [info ] [Thread-3 (]: 3 of 3 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.46s]
[0m20:13:52.798577 [debug] [Thread-3 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m20:13:52.926818 [debug] [Thread-2 (]: SQL status: SELECT 121317 in 0.0 seconds
[0m20:13:52.930807 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:13:52.931807 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail" rename to "sales_order_detail__dbt_backup"
[0m20:13:52.933807 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:13:52.938864 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:13:52.938950 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp" rename to "sales_order_detail"
[0m20:13:52.940967 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:13:52.943630 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:13:52.944724 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_detail" is $dbt_comment_literal_block$Intermediate sales order detail table$dbt_comment_literal_block$;

  
[0m20:13:52.946737 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m20:13:52.948728 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:13:52.948728 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:13:52.949728 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:13:52.962994 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m20:13:52.966236 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:13:52.967239 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_detail__dbt_backup" cascade
[0m20:13:52.973243 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:13:52.976242 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (execute): 20:13:52.414666 => 20:13:52.976242
[0m20:13:52.977273 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: Close
[0m20:13:52.978973 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6550526b-92a6-4e73-a7fb-ed099cfbc180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CB0F1780>]}
[0m20:13:52.979983 [info ] [Thread-2 (]: 2 of 3 OK created sql table model warehouse.sales_order_detail ................. [[32mSELECT 121317[0m in 0.64s]
[0m20:13:52.980971 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_detail
[0m20:13:52.983520 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:52.984612 [debug] [MainThread]: On master: BEGIN
[0m20:13:52.985134 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:13:53.032736 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:13:53.032736 [debug] [MainThread]: On master: COMMIT
[0m20:13:53.037945 [debug] [MainThread]: Using postgres connection "master"
[0m20:13:53.037945 [debug] [MainThread]: On master: COMMIT
[0m20:13:53.039403 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:13:53.040404 [debug] [MainThread]: On master: Close
[0m20:13:53.041520 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:13:53.041520 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m20:13:53.042522 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m20:13:53.042522 [debug] [MainThread]: Connection 'model.dbt_tutorial.dim_product' was properly closed.
[0m20:13:53.043521 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_detail' was properly closed.
[0m20:13:53.043521 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m20:13:53.044521 [info ] [MainThread]: 
[0m20:13:53.044521 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.25 seconds (1.25s).
[0m20:13:53.046525 [debug] [MainThread]: Command end result
[0m20:13:53.053522 [info ] [MainThread]: 
[0m20:13:53.054522 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:13:53.055522 [info ] [MainThread]: 
[0m20:13:53.056522 [error] [MainThread]: [33m2950[0m
[0m20:13:53.056522 [info ] [MainThread]: 
[0m20:13:53.057522 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m20:13:53.059525 [debug] [MainThread]: Command `dbt run` failed at 20:13:53.059525 after 1.53 seconds
[0m20:13:53.060523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6C8773640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CB1C2DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A6CB1C3FD0>]}
[0m20:13:53.060523 [debug] [MainThread]: Flushing usage events
[0m20:24:33.198237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029454587640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029456AC7730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029456AC7310>]}


============================== 20:24:33.204234 | 327497bb-3119-46ad-b7eb-e3da64fdef64 ==============================
[0m20:24:33.204234 [info ] [MainThread]: Running with dbt=1.5.11
[0m20:24:33.205234 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m20:24:33.246296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '327497bb-3119-46ad-b7eb-e3da64fdef64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029456AC7880>]}
[0m20:24:33.252298 [debug] [MainThread]: Command `dbt clean` succeeded at 20:24:33.251298 after 0.07 seconds
[0m20:24:33.252298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029454587640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029456AC7370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029456AC7940>]}
[0m20:24:33.253297 [debug] [MainThread]: Flushing usage events
[0m20:25:58.366239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA5C73640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA80C32B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA80C3160>]}


============================== 20:25:58.370239 | 5253030d-03af-4acd-84ec-fa03d7e01d99 ==============================
[0m20:25:58.370239 [info ] [MainThread]: Running with dbt=1.5.11
[0m20:25:58.370239 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m20:25:58.449345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA80C3A00>]}
[0m20:25:58.467063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA841CAC0>]}
[0m20:25:58.468065 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m20:25:58.482063 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m20:25:58.483063 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m20:25:58.483063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA80C37C0>]}
[0m20:25:59.089667 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\dim_product.sql
[0m20:25:59.100897 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_detail.sql
[0m20:25:59.103900 [debug] [MainThread]: 1699: static parser successfully parsed warehouse\sales_order_header.sql
[0m20:25:59.298673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA857C130>]}
[0m20:25:59.309005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA857C1F0>]}
[0m20:25:59.309005 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m20:25:59.310044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA857C100>]}
[0m20:25:59.312005 [info ] [MainThread]: 
[0m20:25:59.313005 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:25:59.315136 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m20:25:59.324237 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m20:25:59.325221 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m20:25:59.325221 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:25:59.380394 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m20:25:59.381392 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m20:25:59.383392 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m20:25:59.389488 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:25:59.389488 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m20:25:59.390489 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:25:59.407790 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:25:59.408789 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:25:59.408789 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m20:25:59.422393 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m20:25:59.423382 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m20:25:59.425382 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m20:25:59.430385 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:59.431385 [debug] [MainThread]: On master: BEGIN
[0m20:25:59.431385 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:25:59.465594 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:25:59.466672 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:59.466672 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:25:59.629625 [debug] [MainThread]: SQL status: SELECT 146 in 0.0 seconds
[0m20:25:59.633623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA85E8E20>]}
[0m20:25:59.634623 [debug] [MainThread]: On master: ROLLBACK
[0m20:25:59.635623 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:59.635623 [debug] [MainThread]: On master: BEGIN
[0m20:25:59.636625 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:25:59.637624 [debug] [MainThread]: On master: COMMIT
[0m20:25:59.637624 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:59.638624 [debug] [MainThread]: On master: COMMIT
[0m20:25:59.639623 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:25:59.639774 [debug] [MainThread]: On master: Close
[0m20:25:59.640785 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:25:59.641818 [info ] [MainThread]: 
[0m20:25:59.652598 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.dim_product
[0m20:25:59.653120 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_detail
[0m20:25:59.653645 [debug] [Thread-3 (]: Began running node model.dbt_tutorial.sales_order_header
[0m20:25:59.654168 [info ] [Thread-1 (]: 1 of 3 START sql table model warehouse.dim_product ............................. [RUN]
[0m20:25:59.654691 [info ] [Thread-2 (]: 2 of 3 START sql table model warehouse.sales_order_detail ...................... [RUN]
[0m20:25:59.655867 [info ] [Thread-3 (]: 3 of 3 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m20:25:59.656842 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.dim_product'
[0m20:25:59.657843 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_detail'
[0m20:25:59.658844 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m20:25:59.659847 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.dim_product
[0m20:25:59.660842 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_detail
[0m20:25:59.661844 [debug] [Thread-3 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m20:25:59.670162 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.dim_product"
[0m20:25:59.675160 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_detail"
[0m20:25:59.678161 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m20:25:59.681164 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (compile): 20:25:59.661844 => 20:25:59.680166
[0m20:25:59.682162 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 20:25:59.676160 => 20:25:59.681164
[0m20:25:59.682162 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (compile): 20:25:59.671161 => 20:25:59.682162
[0m20:25:59.682162 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.dim_product
[0m20:25:59.683161 [debug] [Thread-3 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m20:25:59.683161 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_detail
[0m20:25:59.734897 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.dim_product"
[0m20:25:59.739047 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m20:25:59.742256 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_detail"
[0m20:25:59.743262 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.dim_product"} */
select * from (
        SELECT 
    productid, 
    "name", 
    productnumber, 
    makeflag, 
    finishedgoodsflag, 
    color, 
    safetystocklevel, 
    reorderpoint, 
    standardcost, 
    listprice, 
    "size", 
    sizeunitmeasurecode, 
    weightunitmeasurecode, 
    "weight", 
    daystomanufacture, 
    productline, 
    "class", 
    "style", 
    productsubcategoryid, 
    productmodelid, 
    sellstartdate, 
    sellenddate, 
    discontinueddate, 
    rowguid as row_id, 
    modifieddate
FROM 
    "Adventureworks"."production"."product"
    ) as __dbt_sbq
    where false
    limit 0

[0m20:25:59.744223 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:25:59.746235 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:25:59.746235 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:25:59.747224 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: BEGIN
[0m20:25:59.748224 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m20:25:59.748224 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:25:59.749244 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:25:59.762225 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m20:25:59.763223 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (execute): 20:25:59.684161 => 20:25:59.763223
[0m20:25:59.764223 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: Close
[0m20:25:59.765224 [error] [Thread-1 (]: [31mUnhandled error while executing [0m
2950
[0m20:25:59.769114 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m20:25:59.769160 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:25:59.770122 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid
    ,salesorderdetailid
    ,carriertrackingnumber
    ,orderqty
    ,productid
    ,specialofferid
    ,unitprice
    ,unitpricediscount
    ,rowguid as row_id
    ,modifieddate
FROM "Adventureworks"."sales"."salesorderdetail"
  );
  
[0m20:25:59.771881 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m20:25:59.772405 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:25:59.772930 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m20:25:59.775062 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 388, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 337, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 436, in run
    return self.execute(compiled_node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\run.py", line 291, in execute
    result = MacroGenerator(
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 82, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 42, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 78, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 23, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 24, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 62, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 20, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 36, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 295, in get_column_schema_from_query
    columns = [
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 297, in <listcomp>
    column_name, self.connections.data_type_code_to_name(column_type_code)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\postgres\connections.py", line 197, in data_type_code_to_name
    return string_types[type_code].name
KeyError: 2950

[0m20:25:59.776637 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA85C3670>]}
[0m20:25:59.780505 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model warehouse.dim_product .................... [[31mERROR[0m in 0.12s]
[0m20:25:59.783144 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.dim_product
[0m20:26:00.088084 [debug] [Thread-3 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m20:26:00.091295 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:26:00.091295 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m20:26:00.091295 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:26:00.098346 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:26:00.098346 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m20:26:00.098346 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:26:00.123519 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:26:00.123519 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m20:26:00.131421 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m20:26:00.132461 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:26:00.133427 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:26:00.133427 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:26:00.145760 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m20:26:00.150748 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:26:00.151748 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m20:26:00.161602 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:26:00.163625 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 20:25:59.734897 => 20:26:00.162596
[0m20:26:00.163625 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: Close
[0m20:26:00.164763 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA87350C0>]}
[0m20:26:00.166764 [info ] [Thread-3 (]: 3 of 3 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.51s]
[0m20:26:00.167916 [debug] [Thread-3 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m20:26:00.262618 [debug] [Thread-2 (]: SQL status: SELECT 121317 in 0.0 seconds
[0m20:26:00.265694 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:26:00.265694 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail" rename to "sales_order_detail__dbt_backup"
[0m20:26:00.266788 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:26:00.268355 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:26:00.268355 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp" rename to "sales_order_detail"
[0m20:26:00.268355 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:26:00.274749 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:26:00.275748 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_detail" is $dbt_comment_literal_block$Intermediate sales order detail table$dbt_comment_literal_block$;

  
[0m20:26:00.279752 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m20:26:00.283749 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:26:00.283749 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:26:00.284749 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:26:00.296992 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m20:26:00.298561 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:26:00.298561 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_detail__dbt_backup" cascade
[0m20:26:00.315407 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:26:00.316810 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (execute): 20:25:59.740081 => 20:26:00.316810
[0m20:26:00.316810 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: Close
[0m20:26:00.318835 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5253030d-03af-4acd-84ec-fa03d7e01d99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA7132530>]}
[0m20:26:00.318835 [info ] [Thread-2 (]: 2 of 3 OK created sql table model warehouse.sales_order_detail ................. [[32mSELECT 121317[0m in 0.66s]
[0m20:26:00.323921 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_detail
[0m20:26:00.328203 [debug] [MainThread]: Using postgres connection "master"
[0m20:26:00.329481 [debug] [MainThread]: On master: BEGIN
[0m20:26:00.329987 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:26:00.385347 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:26:00.386347 [debug] [MainThread]: On master: COMMIT
[0m20:26:00.386347 [debug] [MainThread]: Using postgres connection "master"
[0m20:26:00.387348 [debug] [MainThread]: On master: COMMIT
[0m20:26:00.389789 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:26:00.389789 [debug] [MainThread]: On master: Close
[0m20:26:00.390789 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:26:00.391824 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m20:26:00.391824 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m20:26:00.391824 [debug] [MainThread]: Connection 'model.dbt_tutorial.dim_product' was properly closed.
[0m20:26:00.391824 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_detail' was properly closed.
[0m20:26:00.391824 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m20:26:00.394463 [info ] [MainThread]: 
[0m20:26:00.395166 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.08 seconds (1.08s).
[0m20:26:00.396171 [debug] [MainThread]: Command end result
[0m20:26:00.406094 [info ] [MainThread]: 
[0m20:26:00.406628 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:26:00.407716 [info ] [MainThread]: 
[0m20:26:00.408775 [error] [MainThread]: [33m2950[0m
[0m20:26:00.409312 [info ] [MainThread]: 
[0m20:26:00.410844 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m20:26:00.412840 [debug] [MainThread]: Command `dbt run` failed at 20:26:00.411838 after 2.06 seconds
[0m20:26:00.413841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA5C73640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA7132530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017EA7133790>]}
[0m20:26:00.414841 [debug] [MainThread]: Flushing usage events
[0m20:30:12.167032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029231C77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292340C32B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292340C3160>]}


============================== 20:30:12.172032 | 0484dd1d-383e-4ca9-b880-5f9bfb8a33ad ==============================
[0m20:30:12.172032 [info ] [MainThread]: Running with dbt=1.5.11
[0m20:30:12.172032 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m20:30:12.257193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0484dd1d-383e-4ca9-b880-5f9bfb8a33ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292340C3A00>]}
[0m20:30:12.273776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0484dd1d-383e-4ca9-b880-5f9bfb8a33ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002923441CAC0>]}
[0m20:30:12.279735 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m20:30:12.291918 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m20:30:12.371693 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:30:12.372693 [debug] [MainThread]: Partial parsing: updated file: dbt_tutorial://models\warehouse\dim_product.yml
[0m20:30:12.385692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0484dd1d-383e-4ca9-b880-5f9bfb8a33ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292345E1A20>]}
[0m20:30:12.391851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0484dd1d-383e-4ca9-b880-5f9bfb8a33ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002923458BA90>]}
[0m20:30:12.391851 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m20:30:12.391851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0484dd1d-383e-4ca9-b880-5f9bfb8a33ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002923458B4F0>]}
[0m20:30:12.391851 [info ] [MainThread]: 
[0m20:30:12.398871 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:30:12.398871 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m20:30:12.411085 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m20:30:12.412083 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m20:30:12.412083 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:30:12.461202 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m20:30:12.463206 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m20:30:12.466546 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m20:30:12.479546 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:30:12.480547 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m20:30:12.480547 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:30:12.498894 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:30:12.498894 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:30:12.498894 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m20:30:12.498894 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m20:30:12.504332 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m20:30:12.506332 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m20:30:12.511330 [debug] [MainThread]: Using postgres connection "master"
[0m20:30:12.512330 [debug] [MainThread]: On master: BEGIN
[0m20:30:12.512330 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:30:12.526700 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:30:12.527742 [debug] [MainThread]: Using postgres connection "master"
[0m20:30:12.528256 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:30:12.681850 [debug] [MainThread]: SQL status: SELECT 146 in 0.0 seconds
[0m20:30:12.685850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0484dd1d-383e-4ca9-b880-5f9bfb8a33ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292345BB460>]}
[0m20:30:12.685850 [debug] [MainThread]: On master: ROLLBACK
[0m20:30:12.687850 [debug] [MainThread]: Using postgres connection "master"
[0m20:30:12.687850 [debug] [MainThread]: On master: BEGIN
[0m20:30:12.689890 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:30:12.689981 [debug] [MainThread]: On master: COMMIT
[0m20:30:12.689981 [debug] [MainThread]: Using postgres connection "master"
[0m20:30:12.690982 [debug] [MainThread]: On master: COMMIT
[0m20:30:12.692011 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:30:12.692011 [debug] [MainThread]: On master: Close
[0m20:30:12.692011 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:30:12.692011 [info ] [MainThread]: 
[0m20:30:12.702842 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.dim_product
[0m20:30:12.703365 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_detail
[0m20:30:12.703891 [debug] [Thread-3 (]: Began running node model.dbt_tutorial.sales_order_header
[0m20:30:12.704417 [info ] [Thread-1 (]: 1 of 3 START sql table model warehouse.dim_product ............................. [RUN]
[0m20:30:12.705471 [info ] [Thread-2 (]: 2 of 3 START sql table model warehouse.sales_order_detail ...................... [RUN]
[0m20:30:12.705996 [info ] [Thread-3 (]: 3 of 3 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m20:30:12.707300 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.dim_product'
[0m20:30:12.707817 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_detail'
[0m20:30:12.708816 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m20:30:12.709818 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.dim_product
[0m20:30:12.710816 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_detail
[0m20:30:12.710816 [debug] [Thread-3 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m20:30:12.719491 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.dim_product"
[0m20:30:12.724062 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_detail"
[0m20:30:12.729061 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m20:30:12.731064 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (compile): 20:30:12.711816 => 20:30:12.731064
[0m20:30:12.732061 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (compile): 20:30:12.720491 => 20:30:12.732061
[0m20:30:12.733063 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.dim_product
[0m20:30:12.733063 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 20:30:12.725061 => 20:30:12.733063
[0m20:30:12.734061 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_detail
[0m20:30:12.783669 [debug] [Thread-3 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m20:30:12.786668 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.dim_product"
[0m20:30:12.789834 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_detail"
[0m20:30:12.791838 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m20:30:12.791838 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.dim_product"} */
select * from (
        SELECT 
    productid, 
    "name", 
    productnumber, 
    makeflag, 
    finishedgoodsflag, 
    color, 
    safetystocklevel, 
    reorderpoint, 
    standardcost, 
    listprice, 
    "size", 
    sizeunitmeasurecode, 
    weightunitmeasurecode, 
    "weight", 
    daystomanufacture, 
    productline, 
    "class", 
    "style", 
    productsubcategoryid, 
    productmodelid, 
    sellstartdate, 
    sellenddate, 
    discontinueddate, 
    rowguid as row_id, 
    modifieddate
FROM 
    "Adventureworks"."production"."product"
    ) as __dbt_sbq
    where false
    limit 0

[0m20:30:12.791838 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:30:12.791838 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:30:12.791838 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:30:12.791838 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: BEGIN
[0m20:30:12.791838 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m20:30:12.798875 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:30:12.799195 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:30:12.816438 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m20:30:12.818491 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (execute): 20:30:12.734061 => 20:30:12.818491
[0m20:30:12.818491 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: Close
[0m20:30:12.818491 [error] [Thread-1 (]: [31mUnhandled error while executing [0m
2950
[0m20:30:12.826475 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m20:30:12.827517 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m20:30:12.828550 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:30:12.829069 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:30:12.829641 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m20:30:12.830261 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid
    ,salesorderdetailid
    ,carriertrackingnumber
    ,orderqty
    ,productid
    ,specialofferid
    ,unitprice
    ,unitpricediscount
    ,rowguid as row_id
    ,modifieddate
FROM "Adventureworks"."sales"."salesorderdetail"
  );
  
[0m20:30:12.831304 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 388, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 337, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 436, in run
    return self.execute(compiled_node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\run.py", line 291, in execute
    result = MacroGenerator(
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 82, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 42, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 78, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 23, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 24, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 62, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 20, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 36, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 295, in get_column_schema_from_query
    columns = [
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 297, in <listcomp>
    column_name, self.connections.data_type_code_to_name(column_type_code)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\postgres\connections.py", line 197, in data_type_code_to_name
    return string_types[type_code].name
KeyError: 2950

[0m20:30:12.832356 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0484dd1d-383e-4ca9-b880-5f9bfb8a33ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002923466FD00>]}
[0m20:30:12.832879 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model warehouse.dim_product .................... [[31mERROR[0m in 0.13s]
[0m20:30:12.833920 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.dim_product
[0m20:30:13.012867 [debug] [Thread-3 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m20:30:13.020580 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:30:13.020580 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m20:30:13.024580 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:30:13.027581 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:30:13.028578 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m20:30:13.030580 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:30:13.065015 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:30:13.065015 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m20:30:13.121577 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m20:30:13.123582 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:30:13.123582 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:30:13.124582 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:30:13.184368 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m20:30:13.189112 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:30:13.190113 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m20:30:13.260859 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:30:13.262799 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 20:30:12.790819 => 20:30:13.262799
[0m20:30:13.262799 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: Close
[0m20:30:13.263855 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0484dd1d-383e-4ca9-b880-5f9bfb8a33ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002923412EA10>]}
[0m20:30:13.264858 [info ] [Thread-3 (]: 3 of 3 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.56s]
[0m20:30:13.265856 [debug] [Thread-3 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m20:30:13.359842 [debug] [Thread-2 (]: SQL status: SELECT 121317 in 1.0 seconds
[0m20:30:13.362842 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:30:13.363946 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail" rename to "sales_order_detail__dbt_backup"
[0m20:30:13.364946 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:30:13.368345 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:30:13.368345 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp" rename to "sales_order_detail"
[0m20:30:13.370704 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:30:13.372708 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:30:13.373709 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_detail" is $dbt_comment_literal_block$Intermediate sales order detail table$dbt_comment_literal_block$;

  
[0m20:30:13.374711 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m20:30:13.375709 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:30:13.375709 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:30:13.376709 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:30:13.447235 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m20:30:13.450037 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:30:13.450206 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_detail__dbt_backup" cascade
[0m20:30:13.458982 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:30:13.460785 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (execute): 20:30:12.786668 => 20:30:13.460785
[0m20:30:13.461514 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: Close
[0m20:30:13.462516 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0484dd1d-383e-4ca9-b880-5f9bfb8a33ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029234724040>]}
[0m20:30:13.462516 [info ] [Thread-2 (]: 2 of 3 OK created sql table model warehouse.sales_order_detail ................. [[32mSELECT 121317[0m in 0.75s]
[0m20:30:13.464644 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_detail
[0m20:30:13.466555 [debug] [MainThread]: Using postgres connection "master"
[0m20:30:13.467201 [debug] [MainThread]: On master: BEGIN
[0m20:30:13.467725 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:30:13.483672 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:30:13.484671 [debug] [MainThread]: On master: COMMIT
[0m20:30:13.484671 [debug] [MainThread]: Using postgres connection "master"
[0m20:30:13.484671 [debug] [MainThread]: On master: COMMIT
[0m20:30:13.486677 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:30:13.487679 [debug] [MainThread]: On master: Close
[0m20:30:13.488968 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:30:13.490464 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m20:30:13.490464 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m20:30:13.491496 [debug] [MainThread]: Connection 'model.dbt_tutorial.dim_product' was properly closed.
[0m20:30:13.491496 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_detail' was properly closed.
[0m20:30:13.492360 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m20:30:13.493405 [info ] [MainThread]: 
[0m20:30:13.494464 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.09 seconds (1.09s).
[0m20:30:13.496049 [debug] [MainThread]: Command end result
[0m20:30:13.503414 [info ] [MainThread]: 
[0m20:30:13.503414 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:30:13.503414 [info ] [MainThread]: 
[0m20:30:13.503414 [error] [MainThread]: [33m2950[0m
[0m20:30:13.503414 [info ] [MainThread]: 
[0m20:30:13.503414 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m20:30:13.508568 [debug] [MainThread]: Command `dbt run` failed at 20:30:13.503414 after 1.36 seconds
[0m20:30:13.508831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029231C77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002923441CAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002923458BE20>]}
[0m20:30:13.509832 [debug] [MainThread]: Flushing usage events
[0m20:35:19.710535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A0C77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A31C3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A31C3100>]}


============================== 20:35:19.715222 | ecb826be-7c3b-4033-85d2-6b9b4920c20d ==============================
[0m20:35:19.715222 [info ] [MainThread]: Running with dbt=1.5.11
[0m20:35:19.716328 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m20:35:19.791171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ecb826be-7c3b-4033-85d2-6b9b4920c20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A31C39A0>]}
[0m20:35:19.811457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ecb826be-7c3b-4033-85d2-6b9b4920c20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A331CA60>]}
[0m20:35:19.812483 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m20:35:19.825833 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m20:35:19.906311 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:35:19.906311 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:35:19.911344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ecb826be-7c3b-4033-85d2-6b9b4920c20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A369DDE0>]}
[0m20:35:19.916473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ecb826be-7c3b-4033-85d2-6b9b4920c20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A366ED70>]}
[0m20:35:19.916473 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m20:35:19.916473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ecb826be-7c3b-4033-85d2-6b9b4920c20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A366C6D0>]}
[0m20:35:19.916473 [info ] [MainThread]: 
[0m20:35:19.916473 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:35:19.924457 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m20:35:19.935458 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m20:35:19.936457 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m20:35:19.936457 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:35:19.977681 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m20:35:19.978682 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m20:35:19.980684 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m20:35:19.987626 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:35:19.988149 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m20:35:19.988662 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:35:20.015178 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:35:20.015178 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:35:20.016178 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m20:35:20.025435 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m20:35:20.027435 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m20:35:20.028436 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m20:35:20.034412 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:20.034959 [debug] [MainThread]: On master: BEGIN
[0m20:35:20.035483 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:35:20.049190 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:35:20.050191 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:20.050191 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:35:20.205181 [debug] [MainThread]: SQL status: SELECT 146 in 0.0 seconds
[0m20:35:20.210179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ecb826be-7c3b-4033-85d2-6b9b4920c20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A3698520>]}
[0m20:35:20.210179 [debug] [MainThread]: On master: ROLLBACK
[0m20:35:20.212180 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:20.212180 [debug] [MainThread]: On master: BEGIN
[0m20:35:20.214308 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:35:20.214308 [debug] [MainThread]: On master: COMMIT
[0m20:35:20.215309 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:20.215309 [debug] [MainThread]: On master: COMMIT
[0m20:35:20.216333 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:35:20.216333 [debug] [MainThread]: On master: Close
[0m20:35:20.216333 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:35:20.216333 [info ] [MainThread]: 
[0m20:35:20.226808 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.dim_product
[0m20:35:20.227326 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_detail
[0m20:35:20.227847 [debug] [Thread-3 (]: Began running node model.dbt_tutorial.sales_order_header
[0m20:35:20.228369 [info ] [Thread-1 (]: 1 of 3 START sql table model warehouse.dim_product ............................. [RUN]
[0m20:35:20.228888 [info ] [Thread-2 (]: 2 of 3 START sql table model warehouse.sales_order_detail ...................... [RUN]
[0m20:35:20.229944 [info ] [Thread-3 (]: 3 of 3 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m20:35:20.230987 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.dim_product'
[0m20:35:20.230987 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_detail'
[0m20:35:20.231983 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m20:35:20.232983 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.dim_product
[0m20:35:20.232983 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_detail
[0m20:35:20.233983 [debug] [Thread-3 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m20:35:20.242071 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.dim_product"
[0m20:35:20.246268 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_detail"
[0m20:35:20.249268 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m20:35:20.250269 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (compile): 20:35:20.242268 => 20:35:20.250269
[0m20:35:20.251270 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (compile): 20:35:20.233983 => 20:35:20.251270
[0m20:35:20.252268 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_detail
[0m20:35:20.252268 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 20:35:20.246268 => 20:35:20.252268
[0m20:35:20.253269 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.dim_product
[0m20:35:20.291118 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_detail"
[0m20:35:20.291118 [debug] [Thread-3 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m20:35:20.304780 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.dim_product"
[0m20:35:20.304780 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:20.313853 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m20:35:20.313853 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.dim_product"} */
select * from (
        SELECT 
    productid, 
    "name", 
    productnumber, 
    makeflag, 
    finishedgoodsflag, 
    color, 
    safetystocklevel, 
    reorderpoint, 
    standardcost, 
    listprice, 
    "size", 
    sizeunitmeasurecode, 
    weightunitmeasurecode, 
    "weight", 
    daystomanufacture, 
    productline, 
    "class", 
    "style", 
    productsubcategoryid, 
    productmodelid, 
    sellstartdate, 
    sellenddate, 
    discontinueddate, 
    rowguid as row_id, 
    modifieddate
FROM 
    "Adventureworks"."production"."product"
    ) as __dbt_sbq
    where false
    limit 0

[0m20:35:20.313853 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: BEGIN
[0m20:35:20.313853 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:20.313853 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:35:20.313853 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:35:20.313853 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m20:35:20.313853 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:35:20.344285 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m20:35:20.344285 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m20:35:20.344285 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:20.344285 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:20.344285 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m20:35:20.344285 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid
    ,salesorderdetailid
    ,carriertrackingnumber
    ,orderqty
    ,productid
    ,specialofferid
    ,unitprice
    ,unitpricediscount
    ,rowguid as row_id
    ,modifieddate
FROM "Adventureworks"."sales"."salesorderdetail"
  );
  
[0m20:35:20.369636 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m20:35:20.369636 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (execute): 20:35:20.291118 => 20:35:20.369636
[0m20:35:20.370636 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: Close
[0m20:35:20.371636 [error] [Thread-1 (]: [31mUnhandled error while executing [0m
2950
[0m20:35:20.380635 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 388, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 337, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 436, in run
    return self.execute(compiled_node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\run.py", line 291, in execute
    result = MacroGenerator(
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 82, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 42, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 78, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 23, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 24, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 62, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 20, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 36, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 295, in get_column_schema_from_query
    columns = [
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 297, in <listcomp>
    column_name, self.connections.data_type_code_to_name(column_type_code)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\postgres\connections.py", line 197, in data_type_code_to_name
    return string_types[type_code].name
KeyError: 2950

[0m20:35:20.381636 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecb826be-7c3b-4033-85d2-6b9b4920c20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A374FF40>]}
[0m20:35:20.382643 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model warehouse.dim_product .................... [[31mERROR[0m in 0.15s]
[0m20:35:20.382643 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.dim_product
[0m20:35:20.716495 [debug] [Thread-3 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m20:35:20.724047 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:20.724047 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m20:35:20.724047 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:35:20.724047 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:20.724047 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m20:35:20.724047 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:35:20.757617 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:20.757617 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m20:35:20.760618 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m20:35:20.761618 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:35:20.761618 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:20.762618 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:35:20.850676 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m20:35:20.855674 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:20.856673 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m20:35:20.875992 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:35:20.877029 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 20:35:20.304780 => 20:35:20.877029
[0m20:35:20.878037 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: Close
[0m20:35:20.879019 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecb826be-7c3b-4033-85d2-6b9b4920c20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A36D66B0>]}
[0m20:35:20.879998 [info ] [Thread-3 (]: 3 of 3 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.65s]
[0m20:35:20.882011 [debug] [Thread-3 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m20:35:21.038153 [debug] [Thread-2 (]: SQL status: SELECT 121317 in 1.0 seconds
[0m20:35:21.041300 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:21.042301 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail" rename to "sales_order_detail__dbt_backup"
[0m20:35:21.043302 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:35:21.046302 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:21.047302 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp" rename to "sales_order_detail"
[0m20:35:21.048305 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:35:21.051304 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:21.051974 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_detail" is $dbt_comment_literal_block$Intermediate sales order detail table$dbt_comment_literal_block$;

  
[0m20:35:21.053547 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m20:35:21.054546 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:35:21.054546 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:21.055548 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:35:21.149968 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m20:35:21.151969 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:21.153019 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_detail__dbt_backup" cascade
[0m20:35:21.158763 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:35:21.160163 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (execute): 20:35:20.253269 => 20:35:21.160163
[0m20:35:21.160163 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: Close
[0m20:35:21.161658 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecb826be-7c3b-4033-85d2-6b9b4920c20d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A374EEF0>]}
[0m20:35:21.161891 [info ] [Thread-2 (]: 2 of 3 OK created sql table model warehouse.sales_order_detail ................. [[32mSELECT 121317[0m in 0.93s]
[0m20:35:21.163640 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_detail
[0m20:35:21.164887 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:21.165411 [debug] [MainThread]: On master: BEGIN
[0m20:35:21.165939 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:35:21.181999 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:35:21.182996 [debug] [MainThread]: On master: COMMIT
[0m20:35:21.182996 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:21.183997 [debug] [MainThread]: On master: COMMIT
[0m20:35:21.184997 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:35:21.184997 [debug] [MainThread]: On master: Close
[0m20:35:21.185997 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:35:21.186997 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m20:35:21.186997 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m20:35:21.186997 [debug] [MainThread]: Connection 'model.dbt_tutorial.dim_product' was properly closed.
[0m20:35:21.187998 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_detail' was properly closed.
[0m20:35:21.187998 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m20:35:21.190111 [info ] [MainThread]: 
[0m20:35:21.190826 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 1.27 seconds (1.27s).
[0m20:35:21.192072 [debug] [MainThread]: Command end result
[0m20:35:21.201491 [info ] [MainThread]: 
[0m20:35:21.203025 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:35:21.204022 [info ] [MainThread]: 
[0m20:35:21.204022 [error] [MainThread]: [33m2950[0m
[0m20:35:21.205023 [info ] [MainThread]: 
[0m20:35:21.205023 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m20:35:21.206022 [debug] [MainThread]: Command `dbt run` failed at 20:35:21.206022 after 1.51 seconds
[0m20:35:21.207023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A0C77640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A37C6530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000139A37C53F0>]}
[0m20:35:21.207023 [debug] [MainThread]: Flushing usage events
[0m20:35:54.811945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021CFD783640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021CFFCC3220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021CFFCC30D0>]}


============================== 20:35:54.816133 | 5b5a08cf-d760-46c0-8cb2-f0685bc7589c ==============================
[0m20:35:54.816133 [info ] [MainThread]: Running with dbt=1.5.11
[0m20:35:54.816133 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'fail_fast': 'False', 'debug': 'True', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m20:35:54.885063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b5a08cf-d760-46c0-8cb2-f0685bc7589c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021CFFCC3970>]}
[0m20:35:54.903493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b5a08cf-d760-46c0-8cb2-f0685bc7589c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C8001CA30>]}
[0m20:35:54.907327 [info ] [MainThread]: Registered adapter: postgres=1.5.11
[0m20:35:54.916348 [debug] [MainThread]: checksum: 007b492a958e08141e13011e4198bea48e7f359a98b57e51b7a963fca8fc83af, vars: {}, profile: , target: , version: 1.5.11
[0m20:35:54.976781 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:35:54.976781 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:35:54.982778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b5a08cf-d760-46c0-8cb2-f0685bc7589c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C801A1DB0>]}
[0m20:35:54.990943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b5a08cf-d760-46c0-8cb2-f0685bc7589c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C80172D40>]}
[0m20:35:54.992000 [info ] [MainThread]: Found 3 models, 9 tests, 0 snapshots, 0 analyses, 311 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics, 0 groups
[0m20:35:54.992225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5a08cf-d760-46c0-8cb2-f0685bc7589c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C801706A0>]}
[0m20:35:54.994259 [info ] [MainThread]: 
[0m20:35:54.995226 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:35:54.997265 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks'
[0m20:35:55.007228 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks"
[0m20:35:55.008291 [debug] [ThreadPool]: On list_Adventureworks: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks"} */

    select distinct nspname from pg_namespace
  
[0m20:35:55.009260 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:35:55.057437 [debug] [ThreadPool]: SQL status: SELECT 15 in 0.0 seconds
[0m20:35:55.059438 [debug] [ThreadPool]: On list_Adventureworks: Close
[0m20:35:55.062438 [debug] [ThreadPool]: Acquiring new postgres connection 'list_Adventureworks_warehouse'
[0m20:35:55.068893 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:35:55.069966 [debug] [ThreadPool]: On list_Adventureworks_warehouse: BEGIN
[0m20:35:55.070507 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:35:55.084467 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:35:55.085467 [debug] [ThreadPool]: Using postgres connection "list_Adventureworks_warehouse"
[0m20:35:55.086466 [debug] [ThreadPool]: On list_Adventureworks_warehouse: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "list_Adventureworks_warehouse"} */
select
      'Adventureworks' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'Adventureworks' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
[0m20:35:55.092918 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m20:35:55.093924 [debug] [ThreadPool]: On list_Adventureworks_warehouse: ROLLBACK
[0m20:35:55.094927 [debug] [ThreadPool]: On list_Adventureworks_warehouse: Close
[0m20:35:55.100925 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:55.102015 [debug] [MainThread]: On master: BEGIN
[0m20:35:55.102534 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:35:55.116632 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:35:55.116632 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:55.116632 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:35:55.283074 [debug] [MainThread]: SQL status: SELECT 146 in 0.0 seconds
[0m20:35:55.288077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5a08cf-d760-46c0-8cb2-f0685bc7589c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C801F04F0>]}
[0m20:35:55.289195 [debug] [MainThread]: On master: ROLLBACK
[0m20:35:55.291823 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:55.291858 [debug] [MainThread]: On master: BEGIN
[0m20:35:55.294860 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:35:55.294860 [debug] [MainThread]: On master: COMMIT
[0m20:35:55.295860 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:55.295860 [debug] [MainThread]: On master: COMMIT
[0m20:35:55.297860 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:35:55.297860 [debug] [MainThread]: On master: Close
[0m20:35:55.298874 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:35:55.299862 [info ] [MainThread]: 
[0m20:35:55.306212 [debug] [Thread-1 (]: Began running node model.dbt_tutorial.dim_product
[0m20:35:55.306736 [debug] [Thread-2 (]: Began running node model.dbt_tutorial.sales_order_detail
[0m20:35:55.306736 [debug] [Thread-3 (]: Began running node model.dbt_tutorial.sales_order_header
[0m20:35:55.307781 [info ] [Thread-1 (]: 1 of 3 START sql table model warehouse.dim_product ............................. [RUN]
[0m20:35:55.308307 [info ] [Thread-2 (]: 2 of 3 START sql table model warehouse.sales_order_detail ...................... [RUN]
[0m20:35:55.309348 [info ] [Thread-3 (]: 3 of 3 START sql table model warehouse.sales_order_header ...................... [RUN]
[0m20:35:55.309866 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.dbt_tutorial.dim_product'
[0m20:35:55.310932 [debug] [Thread-2 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_detail'
[0m20:35:55.311458 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.dbt_tutorial.sales_order_header'
[0m20:35:55.312510 [debug] [Thread-1 (]: Began compiling node model.dbt_tutorial.dim_product
[0m20:35:55.313038 [debug] [Thread-2 (]: Began compiling node model.dbt_tutorial.sales_order_detail
[0m20:35:55.313551 [debug] [Thread-3 (]: Began compiling node model.dbt_tutorial.sales_order_header
[0m20:35:55.322568 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_tutorial.dim_product"
[0m20:35:55.326284 [debug] [Thread-2 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_detail"
[0m20:35:55.329574 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_tutorial.sales_order_header"
[0m20:35:55.330578 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (compile): 20:35:55.314202 => 20:35:55.330578
[0m20:35:55.331575 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (compile): 20:35:55.323603 => 20:35:55.331575
[0m20:35:55.332576 [debug] [Thread-1 (]: Began executing node model.dbt_tutorial.dim_product
[0m20:35:55.333577 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (compile): 20:35:55.326574 => 20:35:55.332576
[0m20:35:55.333577 [debug] [Thread-2 (]: Began executing node model.dbt_tutorial.sales_order_detail
[0m20:35:55.385799 [debug] [Thread-1 (]: Using postgres connection "model.dbt_tutorial.dim_product"
[0m20:35:55.385799 [debug] [Thread-3 (]: Began executing node model.dbt_tutorial.sales_order_header
[0m20:35:55.393117 [debug] [Thread-2 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_detail"
[0m20:35:55.393988 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.dim_product"} */
select * from (
        SELECT 
    productid, 
    "name", 
    productnumber, 
    makeflag, 
    finishedgoodsflag, 
    color, 
    safetystocklevel, 
    reorderpoint, 
    standardcost, 
    listprice, 
    "size", 
    sizeunitmeasurecode, 
    weightunitmeasurecode, 
    "weight", 
    daystomanufacture, 
    productline, 
    "class", 
    "style", 
    productsubcategoryid, 
    productmodelid, 
    sellstartdate, 
    sellenddate, 
    discontinueddate, 
    rowguid as row_id, 
    modifieddate
FROM 
    "Adventureworks"."production"."product"
    ) as __dbt_sbq
    where false
    limit 0

[0m20:35:55.397960 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_tutorial.sales_order_header"
[0m20:35:55.398961 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:55.399964 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:35:55.400962 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: BEGIN
[0m20:35:55.400962 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:55.401963 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:35:55.402963 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: BEGIN
[0m20:35:55.403964 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:35:55.416546 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m20:35:55.416546 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m20:35:55.416546 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:55.416546 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:55.424113 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid
    ,salesorderdetailid
    ,carriertrackingnumber
    ,orderqty
    ,productid
    ,specialofferid
    ,unitprice
    ,unitpricediscount
    ,rowguid as row_id
    ,modifieddate
FROM "Adventureworks"."sales"."salesorderdetail"
  );
  
[0m20:35:55.424347 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

  
    

  create  table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp"
  
  
    as
  
  (
    SELECT 
    salesorderid,
    revisionnumber,
    orderdate,
    duedate,
    shipdate,
    status,
    onlineorderflag,
    purchaseordernumber,
    subtotal,
    taxamt,
    freight,
    totaldue,
    rowguid as row_id,
    modifieddate
FROM "Adventureworks"."sales"."salesorderheader"
  );
  
[0m20:35:55.435356 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.0 seconds
[0m20:35:55.437357 [debug] [Thread-1 (]: Timing info for model.dbt_tutorial.dim_product (execute): 20:35:55.334572 => 20:35:55.437357
[0m20:35:55.438355 [debug] [Thread-1 (]: On model.dbt_tutorial.dim_product: Close
[0m20:35:55.439550 [error] [Thread-1 (]: [31mUnhandled error while executing [0m
2950
[0m20:35:55.444743 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 388, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 337, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\base.py", line 436, in run
    return self.execute(compiled_node, manifest)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\task\run.py", line 291, in execute
    result = MacroGenerator(
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 82, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 42, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 78, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 23, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 24, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 62, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 19, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 20, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 36, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\clients\jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 768, in __call__
    return self._invoke(arguments, autoescape)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 782, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 31, in macro
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\sandbox.py", line 394, in call
    return __context.call(__obj, *args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 295, in get_column_schema_from_query
    columns = [
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\base\impl.py", line 297, in <listcomp>
    column_name, self.connections.data_type_code_to_name(column_type_code)
  File "D:\CS\dbt\.venv\lib\site-packages\dbt\adapters\postgres\connections.py", line 197, in data_type_code_to_name
    return string_types[type_code].name
KeyError: 2950

[0m20:35:55.448508 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5a08cf-d760-46c0-8cb2-f0685bc7589c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C80293490>]}
[0m20:35:55.449552 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model warehouse.dim_product .................... [[31mERROR[0m in 0.14s]
[0m20:35:55.450598 [debug] [Thread-1 (]: Finished running node model.dbt_tutorial.dim_product
[0m20:35:55.631165 [debug] [Thread-3 (]: SQL status: SELECT 31465 in 0.0 seconds
[0m20:35:55.638163 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:55.639163 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header" rename to "sales_order_header__dbt_backup"
[0m20:35:55.643042 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:35:55.647017 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:55.648005 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
alter table "Adventureworks"."warehouse"."sales_order_header__dbt_tmp" rename to "sales_order_header"
[0m20:35:55.650005 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:35:55.677285 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:55.678283 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_header" is $dbt_comment_literal_block$Sales Order Header table$dbt_comment_literal_block$;

  
[0m20:35:55.681283 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m20:35:55.682284 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:35:55.683285 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:55.683285 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: COMMIT
[0m20:35:55.770230 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m20:35:55.776292 [debug] [Thread-3 (]: Using postgres connection "model.dbt_tutorial.sales_order_header"
[0m20:35:55.777259 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_header"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_header__dbt_backup" cascade
[0m20:35:55.802579 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:35:55.806579 [debug] [Thread-3 (]: Timing info for model.dbt_tutorial.sales_order_header (execute): 20:35:55.394965 => 20:35:55.805583
[0m20:35:55.807548 [debug] [Thread-3 (]: On model.dbt_tutorial.sales_order_header: Close
[0m20:35:55.808546 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5a08cf-d760-46c0-8cb2-f0685bc7589c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C8028D360>]}
[0m20:35:55.809560 [info ] [Thread-3 (]: 3 of 3 OK created sql table model warehouse.sales_order_header ................. [[32mSELECT 31465[0m in 0.50s]
[0m20:35:55.811557 [debug] [Thread-3 (]: Finished running node model.dbt_tutorial.sales_order_header
[0m20:35:55.820943 [debug] [Thread-2 (]: SQL status: SELECT 121317 in 0.0 seconds
[0m20:35:55.824114 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:55.824114 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail" rename to "sales_order_detail__dbt_backup"
[0m20:35:55.824114 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:35:55.824114 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:55.824114 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
alter table "Adventureworks"."warehouse"."sales_order_detail__dbt_tmp" rename to "sales_order_detail"
[0m20:35:55.824114 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:35:55.836082 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:55.837081 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */

    
  
  comment on table "Adventureworks"."warehouse"."sales_order_detail" is $dbt_comment_literal_block$Intermediate sales order detail table$dbt_comment_literal_block$;

  
[0m20:35:55.839081 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m20:35:55.840253 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:35:55.841280 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:55.841427 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: COMMIT
[0m20:35:55.884999 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m20:35:55.887992 [debug] [Thread-2 (]: Using postgres connection "model.dbt_tutorial.sales_order_detail"
[0m20:35:55.887992 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: /* {"app": "dbt", "dbt_version": "1.5.11", "profile_name": "dbt_tutorial", "target_name": "dev", "node_id": "model.dbt_tutorial.sales_order_detail"} */
drop table if exists "Adventureworks"."warehouse"."sales_order_detail__dbt_backup" cascade
[0m20:35:55.894484 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:35:55.895483 [debug] [Thread-2 (]: Timing info for model.dbt_tutorial.sales_order_detail (execute): 20:35:55.386777 => 20:35:55.895483
[0m20:35:55.897484 [debug] [Thread-2 (]: On model.dbt_tutorial.sales_order_detail: Close
[0m20:35:55.898492 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5a08cf-d760-46c0-8cb2-f0685bc7589c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C801D74C0>]}
[0m20:35:55.899483 [info ] [Thread-2 (]: 2 of 3 OK created sql table model warehouse.sales_order_detail ................. [[32mSELECT 121317[0m in 0.59s]
[0m20:35:55.900482 [debug] [Thread-2 (]: Finished running node model.dbt_tutorial.sales_order_detail
[0m20:35:55.902489 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:55.903483 [debug] [MainThread]: On master: BEGIN
[0m20:35:55.903483 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:35:55.917041 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:35:55.917041 [debug] [MainThread]: On master: COMMIT
[0m20:35:55.917041 [debug] [MainThread]: Using postgres connection "master"
[0m20:35:55.917041 [debug] [MainThread]: On master: COMMIT
[0m20:35:55.917041 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:35:55.917041 [debug] [MainThread]: On master: Close
[0m20:35:55.924060 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:35:55.924060 [debug] [MainThread]: Connection 'list_Adventureworks' was properly closed.
[0m20:35:55.924060 [debug] [MainThread]: Connection 'list_Adventureworks_warehouse' was properly closed.
[0m20:35:55.924060 [debug] [MainThread]: Connection 'model.dbt_tutorial.dim_product' was properly closed.
[0m20:35:55.926295 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_detail' was properly closed.
[0m20:35:55.927034 [debug] [MainThread]: Connection 'model.dbt_tutorial.sales_order_header' was properly closed.
[0m20:35:55.927554 [info ] [MainThread]: 
[0m20:35:55.928073 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.93 seconds (0.93s).
[0m20:35:55.929114 [debug] [MainThread]: Command end result
[0m20:35:55.936921 [info ] [MainThread]: 
[0m20:35:55.938433 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:35:55.938433 [info ] [MainThread]: 
[0m20:35:55.939453 [error] [MainThread]: [33m2950[0m
[0m20:35:55.939513 [info ] [MainThread]: 
[0m20:35:55.939513 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
[0m20:35:55.940514 [debug] [MainThread]: Command `dbt run` failed at 20:35:55.940514 after 1.14 seconds
[0m20:35:55.941571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021CFD783640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C80365C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C80367550>]}
[0m20:35:55.941571 [debug] [MainThread]: Flushing usage events
[0m20:40:35.481365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001549C173640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001549E6C36D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001549E6C32B0>]}


============================== 20:40:35.485365 | f9b795ed-9206-4798-818b-7bebc327258b ==============================
[0m20:40:35.485365 [info ] [MainThread]: Running with dbt=1.5.11
[0m20:40:35.486366 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\mtri0\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'D:\\CS\\dbt\\dbt_tutorial\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m20:40:35.513501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9b795ed-9206-4798-818b-7bebc327258b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001549E6C3820>]}
[0m20:40:35.517673 [debug] [MainThread]: Command `dbt clean` succeeded at 20:40:35.517673 after 0.06 seconds
[0m20:40:35.517673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001549C173640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001549E6C3310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001549E6C38E0>]}
[0m20:40:35.517673 [debug] [MainThread]: Flushing usage events
